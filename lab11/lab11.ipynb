{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cc572964-c993-4741-b581-488033f5acc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import scikeras\n",
    "from scikeras.wrappers import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b24466e1-9232-46e1-88b2-5237ce7a86ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5dd53ac5-4bb5-4a0e-ba8b-b8faca221a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(patience=10,min_delta=1.0,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a604b986-d9ff-4c18-83d6-14d06ca2385b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callback(filename,name,value):\n",
    "    root_logdir = os.path.join(os.curdir, filename)\n",
    "    ts = int(time.time())\n",
    "    filen = str(ts)+'_'+str(name)+'_'+str(value)\n",
    "    return tf.keras.callbacks.TensorBoard(os.path.join(root_logdir, filen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "85f95b73-3077-4438-bf3b-69cb64073c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden, n_neurons, optimizer, learning_rate, momentum=0):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(keras.layers.Input(shape=13))\n",
    "    for i in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons))\n",
    "    if optimizer == 'sgd': \n",
    "        opt = keras.optimizers.SGD(lr=learning_rate,nesterov=False)\n",
    "    elif optimizer == 'nesterov':\n",
    "        opt = keras.optimizers.SGD(lr=learning_rate,nesterov=True)\n",
    "    elif optimizer == 'momentum':\n",
    "        opt = keras.optimizers.SGD(lr=learning_rate,nesterov=False,momentum=momentum)\n",
    "    elif optimizer == 'adam':\n",
    "        opt = keras.optimizers.Adam(lr=learning_rate)\n",
    "    model.compile(loss='mse',optimizer=opt,metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ade9841c-290c-455b-b266-f32fbd26ece0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7821be36-dba4-4066-85fe-bf904e71c1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1e-06, 146.8929443359375, 9.387727737426758),\n",
       " (1e-05, 91.55538177490234, 7.155919075012207),\n",
       " (0.0001, inf, 3.974670369937499e+24)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning = [0.000001,0.00001,0.0001]\n",
    "lr = []\n",
    "for rate in learning:\n",
    "    model = build_model(1,25,'sgd',rate)\n",
    "    history = model.fit(X_train,y_train,epochs=100,validation_data=(X_test,y_test),callbacks=[get_callback('tb_logs','lr',rate),es],verbose=0)\n",
    "    result = (rate, history.history['loss'][-1], history.history['mae'][-1])\n",
    "    lr.append(result)\n",
    "lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ae6968e5-8578-439d-a4d2-be6e4207b0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: early stopping\n",
      "Epoch 89: early stopping\n",
      "Epoch 76: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 23263.36328125, 72.36067199707031),\n",
       " (1, 96.52108764648438, 7.339536666870117),\n",
       " (2, 82.41569519042969, 6.707451820373535),\n",
       " (3, 78.71813201904297, 6.617793560028076)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden = [0,1,2,3]\n",
    "hl = []\n",
    "for hid in hidden:\n",
    "    model = build_model(hid,25,'sgd',1e-05)\n",
    "    history = model.fit(X_train,y_train,epochs=100,validation_data=(X_test,y_test),callbacks=[get_callback('tb_logs','hl',hid),es],verbose=0)\n",
    "    result = (hid, history.history['loss'][-1], history.history['mae'][-1])\n",
    "    hl.append(result)\n",
    "hl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "edaf6ff1-c500-42b8-99e0-58b4ee977c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78: early stopping\n",
      "Epoch 88: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(5, 86.2364730834961, 6.978971481323242),\n",
       " (25, 96.8493423461914, 7.392211437225342),\n",
       " (125, 95.11186218261719, 7.335632801055908)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neurons = [5,25,125]\n",
    "nn = []\n",
    "for neuron in neurons:\n",
    "    model = build_model(1,neuron,'sgd',1e-05)\n",
    "    history = model.fit(X_train,y_train,epochs=100,validation_data=(X_test,y_test),callbacks=[get_callback('tb_logs','nn',neuron),es],verbose=0)\n",
    "    result = (neuron, history.history['loss'][-1], history.history['mae'][-1])\n",
    "    nn.append(result)\n",
    "nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "547a394b-5c4c-4516-9551-fb495169e75f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sgd', 96.74095153808594, 7.328789234161377),\n",
       " ('nesterov', 95.3700180053711, 7.234646320343018),\n",
       " ('momentum', 81.38885498046875, 6.604732513427734),\n",
       " ('adam', 21956.6328125, 123.32284545898438)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opti = ['sgd','nesterov','momentum','adam']\n",
    "opt = []\n",
    "for optimizer in opti:\n",
    "    model = build_model(1,25,optimizer,1e-05,0.5)\n",
    "    history = model.fit(X_train,y_train,epochs=100,validation_data=(X_test,y_test),callbacks=[get_callback('tb_logs','opt',optimizer),es],verbose=0)\n",
    "    result = (optimizer, history.history['loss'][-1], history.history['mae'][-1])\n",
    "    opt.append(result)\n",
    "opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "76781afb-5280-49eb-a375-65a98a2b82fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.1, 95.25955200195312, 7.269810676574707),\n",
       " (0.5, 83.32598876953125, 6.687946796417236),\n",
       " (0.9, 72.64730072021484, 6.113651752471924)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moment = [0.1,0.5,0.9]\n",
    "mom = []\n",
    "for momentum in moment:\n",
    "    model = build_model(1,25,'momentum',1e-05,momentum)\n",
    "    history = model.fit(X_train,y_train,epochs=100,validation_data=(X_test,y_test),callbacks=[get_callback('tb_logs','mom',momentum),es],verbose=0)\n",
    "    result = (momentum, history.history['loss'][-1], history.history['mae'][-1])\n",
    "    mom.append(result)\n",
    "mom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6ea6dcdd-b76b-40bf-ab6f-8045c648223e",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distribs = {\n",
    "\"model__n_hidden\": [0,1,2,3],\n",
    "\"model__n_neurons\": [5,25,125],\n",
    "\"model__learning_rate\": [0.000001,0.00001,0.0001],\n",
    "\"model__optimizer\": ['sgd','nesterov', 'momentum','adam'],\n",
    "\"model__momentum\": [0.1,0.5,0.9]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "86721a4e-529f-4d6f-b160-82ddc10818c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg = KerasRegressor(build_model, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4fb9da51-b3e8-420d-b627-9777a1c37548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmp5zswvbj1\\assets\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmp8vndrmoq\\assets\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 20ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23399.2207 - mae: 72.8679 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.9, model__n_hidden=0, model__n_neurons=125, model__optimizer=adam; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 774, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 89, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 331, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 1755]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmpw7d3jdns\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 23112.9844 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 23112.9844 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.9, model__n_hidden=0, model__n_neurons=125, model__optimizer=adam; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 774, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 89, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 331, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 1755]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmp2_m64c83\\assets\n",
      "Epoch 1/100\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 21635.4844 - mae: 71.4221"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 28ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23041.8223 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23041.8223 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.9, model__n_hidden=0, model__n_neurons=125, model__optimizer=adam; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 774, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 89, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 331, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 1742]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmp6680oe6s\\assets\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 26ms/step - loss: 465019545111756800.0000 - mae: 171994032.0000 - val_loss: 813082480369003921408.0000 - val_mae: 23048570880.0000\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 22124513899709887688208144096296960.0000 - mae: 38560641585250304.0000 - val_loss: inf - val_mae: 4982348980336721920.0000\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: inf - mae: 8227454806284536949768192.0000 - val_loss: inf - val_mae: 1119879622835042132307214336.0000\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: inf - mae: 1887489189550983143881641415409664.0000 - val_loss: inf - val_mae: 223684257208263018779236285018013696.0000\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan   \n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.5, model__n_hidden=1, model__n_neurons=5, model__optimizer=momentum; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 774, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 89, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 331, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 675]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmpg2d2cth8\\assets\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 25ms/step - loss: 1053619386822164480.0000 - mae: 275998848.0000 - val_loss: 1577081495036692004864.0000 - val_mae: 33522630656.0000\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 29326596508504215909995169410187264.0000 - mae: 45730561204944896.0000 - val_loss: inf - val_mae: 5914436873039642624.0000\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: inf - mae: 8036145929339104403652608.0000 - val_loss: inf - val_mae: 970229009584523792896491520.0000\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: inf - mae: 1347682804798009593578794136895488.0000 - val_loss: inf - val_mae: 155865286815743431422597436092186624.0000\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan   \n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.5, model__n_hidden=1, model__n_neurons=5, model__optimizer=momentum; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 774, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 89, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 331, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 675]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmpvwb_437k\\assets\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 28ms/step - loss: 368000666301366272.0000 - mae: 159516512.0000 - val_loss: 484947185662789943296.0000 - val_mae: 17549199360.0000\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7129645785335583480381577959047168.0000 - mae: 21375764469383168.0000 - val_loss: 11230898807842225085400017162303700992.0000 - val_mae: 2667579585972928512.0000\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: inf - mae: 3436355178535497643327488.0000 - val_loss: inf - val_mae: 397708776963149844474494976.0000\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: inf - mae: 512572400229967282281471176343552.0000 - val_loss: inf - val_mae: 60981510642896375041020611660873728.0000\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan  \n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.5, model__n_hidden=1, model__n_neurons=5, model__optimizer=momentum; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 774, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 89, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 331, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 670]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmpsniw7tep\\assets\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 16ms/step - loss: 5476.2598 - mae: 58.2348 - val_loss: 4624.8667 - val_mae: 53.6069\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4243.6299 - mae: 51.2481 - val_loss: 3634.7188 - val_mae: 47.5073\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3380.8398 - mae: 45.7677 - val_loss: 2924.2593 - val_mae: 42.6192\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2755.0234 - mae: 41.3387 - val_loss: 2405.9241 - val_mae: 38.6588\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2291.2119 - mae: 37.7027 - val_loss: 2011.0076 - val_mae: 35.3510\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1935.4192 - mae: 34.6680 - val_loss: 1705.9835 - val_mae: 32.5748\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1657.8165 - mae: 32.0961 - val_loss: 1466.2911 - val_mae: 30.2047\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1438.2189 - mae: 29.8947 - val_loss: 1273.7759 - val_mae: 28.1419\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1260.8594 - mae: 27.9806 - val_loss: 1120.2013 - val_mae: 26.3676\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1117.6556 - mae: 26.3237 - val_loss: 993.6165 - val_mae: 24.8165\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 999.6306 - mae: 24.8668 - val_loss: 890.7614 - val_mae: 23.4671\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 902.2211 - mae: 23.5901 - val_loss: 803.4952 - val_mae: 22.2551\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 819.7494 - mae: 22.4621 - val_loss: 730.2947 - val_mae: 21.1751\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 750.2055 - mae: 21.4402 - val_loss: 668.7097 - val_mae: 20.2147\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 691.0216 - mae: 20.5473 - val_loss: 615.5875 - val_mae: 19.3533\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 640.1999 - mae: 19.7408 - val_loss: 570.1582 - val_mae: 18.5855\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 596.6647 - mae: 19.0226 - val_loss: 531.1051 - val_mae: 17.8902\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 558.8090 - mae: 18.3724 - val_loss: 497.5879 - val_mae: 17.2658\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 525.9696 - mae: 17.7924 - val_loss: 467.9644 - val_mae: 16.6960\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 497.2031 - mae: 17.2546 - val_loss: 442.2263 - val_mae: 16.1808\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 471.9411 - mae: 16.7614 - val_loss: 419.6291 - val_mae: 15.7100\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 449.8180 - mae: 16.3264 - val_loss: 399.6877 - val_mae: 15.2830\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 430.1305 - mae: 15.9254 - val_loss: 381.9269 - val_mae: 14.8926\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 412.6103 - mae: 15.5527 - val_loss: 366.2856 - val_mae: 14.5405\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 397.0450 - mae: 15.2209 - val_loss: 352.1102 - val_mae: 14.2144\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 383.1388 - mae: 14.9172 - val_loss: 339.3434 - val_mae: 13.9144\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 370.5811 - mae: 14.6378 - val_loss: 328.2259 - val_mae: 13.6430\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 359.3894 - mae: 14.3806 - val_loss: 317.9986 - val_mae: 13.3955\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 349.2099 - mae: 14.1522 - val_loss: 308.4138 - val_mae: 13.1638\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 339.7468 - mae: 13.9319 - val_loss: 299.8861 - val_mae: 12.9538\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 331.4150 - mae: 13.7344 - val_loss: 292.1451 - val_mae: 12.7629\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 323.7502 - mae: 13.5538 - val_loss: 285.0478 - val_mae: 12.5867\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 316.6279 - mae: 13.3845 - val_loss: 278.5738 - val_mae: 12.4234\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 310.0667 - mae: 13.2268 - val_loss: 272.5797 - val_mae: 12.2731\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 304.1570 - mae: 13.0810 - val_loss: 266.8781 - val_mae: 12.1346\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 298.5412 - mae: 12.9404 - val_loss: 261.2189 - val_mae: 12.0063\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 293.2790 - mae: 12.8229 - val_loss: 256.1646 - val_mae: 11.8873\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 288.4818 - mae: 12.7114 - val_loss: 251.4650 - val_mae: 11.7770\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 283.9834 - mae: 12.6037 - val_loss: 247.1069 - val_mae: 11.6729\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 279.7367 - mae: 12.5023 - val_loss: 242.8901 - val_mae: 11.5742\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 275.5537 - mae: 12.4011 - val_loss: 238.9339 - val_mae: 11.4824\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 271.7502 - mae: 12.3110 - val_loss: 235.0608 - val_mae: 11.3950\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 268.1261 - mae: 12.2257 - val_loss: 231.2561 - val_mae: 11.3125\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 264.7742 - mae: 12.1554 - val_loss: 227.8365 - val_mae: 11.2330\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 261.4184 - mae: 12.0715 - val_loss: 224.6001 - val_mae: 11.1575\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 258.2838 - mae: 11.9979 - val_loss: 221.4129 - val_mae: 11.0833\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 255.3734 - mae: 11.9283 - val_loss: 218.1730 - val_mae: 11.0107\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 252.3873 - mae: 11.8618 - val_loss: 215.3375 - val_mae: 10.9426\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 249.6396 - mae: 11.7963 - val_loss: 212.3866 - val_mae: 10.8773\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 246.9500 - mae: 11.7384 - val_loss: 209.6947 - val_mae: 10.8122\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 244.4286 - mae: 11.6793 - val_loss: 206.8787 - val_mae: 10.7478\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 241.9301 - mae: 11.6222 - val_loss: 204.2774 - val_mae: 10.6857\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 239.5089 - mae: 11.5664 - val_loss: 201.7258 - val_mae: 10.6255\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 237.2368 - mae: 11.5170 - val_loss: 199.0149 - val_mae: 10.5631\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 234.8954 - mae: 11.4630 - val_loss: 196.5938 - val_mae: 10.5065\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 232.7674 - mae: 11.4111 - val_loss: 194.2656 - val_mae: 10.4494\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 230.6401 - mae: 11.3598 - val_loss: 191.6700 - val_mae: 10.3914\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 228.4587 - mae: 11.3161 - val_loss: 189.5906 - val_mae: 10.3383\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 226.5150 - mae: 11.2659 - val_loss: 187.3324 - val_mae: 10.2816\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 224.4678 - mae: 11.2149 - val_loss: 185.1340 - val_mae: 10.2289\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 222.5861 - mae: 11.1708 - val_loss: 183.0312 - val_mae: 10.1762\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 220.7212 - mae: 11.1251 - val_loss: 180.9438 - val_mae: 10.1232\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 218.8944 - mae: 11.0802 - val_loss: 178.7800 - val_mae: 10.0718\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 217.0427 - mae: 11.0386 - val_loss: 176.8745 - val_mae: 10.0238\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 215.3407 - mae: 10.9942 - val_loss: 174.7288 - val_mae: 9.9734\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 213.5859 - mae: 10.9571 - val_loss: 172.7708 - val_mae: 9.9239\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 211.8867 - mae: 10.9138 - val_loss: 170.8830 - val_mae: 9.8764\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 210.2517 - mae: 10.8763 - val_loss: 169.2154 - val_mae: 9.8303\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 208.6606 - mae: 10.8302 - val_loss: 167.3981 - val_mae: 9.7844\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 207.0494 - mae: 10.7920 - val_loss: 165.6375 - val_mae: 9.7373\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 205.4949 - mae: 10.7530 - val_loss: 163.7055 - val_mae: 9.6887\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 203.9998 - mae: 10.7147 - val_loss: 162.1861 - val_mae: 9.6448\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 202.4993 - mae: 10.6740 - val_loss: 160.4122 - val_mae: 9.5991\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 201.0745 - mae: 10.6382 - val_loss: 158.8141 - val_mae: 9.5583\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 199.6366 - mae: 10.6024 - val_loss: 157.2091 - val_mae: 9.5148\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 198.2557 - mae: 10.5674 - val_loss: 155.4919 - val_mae: 9.4701\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 196.8008 - mae: 10.5307 - val_loss: 153.9825 - val_mae: 9.4286\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 195.4435 - mae: 10.4931 - val_loss: 152.4378 - val_mae: 9.3875\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 194.1261 - mae: 10.4602 - val_loss: 150.9123 - val_mae: 9.3451\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 192.8487 - mae: 10.4241 - val_loss: 149.4505 - val_mae: 9.3060\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 191.5911 - mae: 10.3951 - val_loss: 147.7103 - val_mae: 9.2630\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 190.1846 - mae: 10.3584 - val_loss: 146.3412 - val_mae: 9.2247\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 188.9319 - mae: 10.3265 - val_loss: 144.9964 - val_mae: 9.1857\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 187.7081 - mae: 10.2923 - val_loss: 143.6858 - val_mae: 9.1482\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 186.6055 - mae: 10.2602 - val_loss: 142.3410 - val_mae: 9.1098\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 185.3640 - mae: 10.2272 - val_loss: 141.0989 - val_mae: 9.0741\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 184.2011 - mae: 10.1980 - val_loss: 139.7181 - val_mae: 9.0344\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 183.0751 - mae: 10.1680 - val_loss: 138.4678 - val_mae: 8.9990\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 181.9857 - mae: 10.1390 - val_loss: 137.2295 - val_mae: 8.9621\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 180.8331 - mae: 10.1085 - val_loss: 135.9534 - val_mae: 8.9237\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 179.7734 - mae: 10.0774 - val_loss: 134.6977 - val_mae: 8.8877\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 178.7128 - mae: 10.0505 - val_loss: 133.3783 - val_mae: 8.8492\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 177.6373 - mae: 10.0173 - val_loss: 132.1772 - val_mae: 8.8128\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 176.6063 - mae: 9.9884 - val_loss: 131.0236 - val_mae: 8.7790\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 175.5753 - mae: 9.9591 - val_loss: 129.8452 - val_mae: 8.7443\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 174.5492 - mae: 9.9312 - val_loss: 128.6491 - val_mae: 8.7086\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 173.5733 - mae: 9.9033 - val_loss: 127.6092 - val_mae: 8.6765\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 172.6209 - mae: 9.8749 - val_loss: 126.4027 - val_mae: 8.6426\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 171.6767 - mae: 9.8523 - val_loss: 125.3907 - val_mae: 8.6094\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 170.7410 - mae: 9.8218 - val_loss: 124.3830 - val_mae: 8.5770\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.5, model__n_hidden=2, model__n_neurons=125, model__optimizer=nesterov; total time=   3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 774, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 89, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 331, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 16875]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmph2zqlamd\\assets\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 18ms/step - loss: 6284.3193 - mae: 62.2930 - val_loss: 5288.8228 - val_mae: 57.4050\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 4736.5879 - mae: 54.2410 - val_loss: 4042.2998 - val_mae: 50.2856\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3685.2869 - mae: 47.9263 - val_loss: 3182.8706 - val_mae: 44.6692\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2948.9646 - mae: 42.9320 - val_loss: 2567.6909 - val_mae: 40.1481\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2415.1968 - mae: 38.9123 - val_loss: 2113.6736 - val_mae: 36.4465\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2017.4078 - mae: 35.5830 - val_loss: 1770.9249 - val_mae: 33.3521\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1713.2559 - mae: 32.8002 - val_loss: 1506.4991 - val_mae: 30.7299\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1477.4294 - mae: 30.4594 - val_loss: 1301.5162 - val_mae: 28.5003\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1292.7286 - mae: 28.4641 - val_loss: 1140.0306 - val_mae: 26.5956\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1145.9026 - mae: 26.7471 - val_loss: 1009.6464 - val_mae: 24.9555\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1027.0951 - mae: 25.2675 - val_loss: 905.6397 - val_mae: 23.5491\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 931.0092 - mae: 23.9983 - val_loss: 819.3098 - val_mae: 22.3062\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 851.0808 - mae: 22.8696 - val_loss: 748.0762 - val_mae: 21.2146\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 784.7144 - mae: 21.8737 - val_loss: 688.6410 - val_mae: 20.2561\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 728.9666 - mae: 21.0045 - val_loss: 639.1066 - val_mae: 19.4103\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 681.8998 - mae: 20.2182 - val_loss: 596.8175 - val_mae: 18.6569\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 641.7888 - mae: 19.5390 - val_loss: 560.4372 - val_mae: 17.9843\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 606.9534 - mae: 18.9236 - val_loss: 528.9845 - val_mae: 17.3903\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 576.9323 - mae: 18.3825 - val_loss: 501.7849 - val_mae: 16.8640\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 550.7365 - mae: 17.8862 - val_loss: 477.9865 - val_mae: 16.3933\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 527.9041 - mae: 17.4490 - val_loss: 457.0335 - val_mae: 15.9666\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 507.6158 - mae: 17.0594 - val_loss: 438.4459 - val_mae: 15.5796\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 489.6256 - mae: 16.7015 - val_loss: 421.8857 - val_mae: 15.2279\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 473.5068 - mae: 16.3733 - val_loss: 407.5275 - val_mae: 14.9113\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 459.0653 - mae: 16.0790 - val_loss: 393.9817 - val_mae: 14.6247\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 446.0799 - mae: 15.8170 - val_loss: 381.8824 - val_mae: 14.3666\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 433.9858 - mae: 15.5733 - val_loss: 370.5103 - val_mae: 14.1273\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 423.1730 - mae: 15.3667 - val_loss: 360.5403 - val_mae: 13.9087\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 413.1585 - mae: 15.1599 - val_loss: 350.9916 - val_mae: 13.7064\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 403.8020 - mae: 14.9770 - val_loss: 342.6076 - val_mae: 13.5248\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 395.3465 - mae: 14.8034 - val_loss: 334.6035 - val_mae: 13.3561\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 387.5566 - mae: 14.6472 - val_loss: 327.3010 - val_mae: 13.2032\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 380.0031 - mae: 14.4993 - val_loss: 320.1322 - val_mae: 13.0599\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 372.9426 - mae: 14.3630 - val_loss: 313.2395 - val_mae: 12.9270\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 366.3104 - mae: 14.2490 - val_loss: 307.3166 - val_mae: 12.8025\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 360.1513 - mae: 14.1176 - val_loss: 301.3612 - val_mae: 12.6855\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 354.2916 - mae: 14.0088 - val_loss: 295.5897 - val_mae: 12.5737\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 348.6763 - mae: 13.9036 - val_loss: 290.1432 - val_mae: 12.4673\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 343.4042 - mae: 13.8044 - val_loss: 284.8214 - val_mae: 12.3661\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 338.2801 - mae: 13.7063 - val_loss: 279.7888 - val_mae: 12.2708\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 333.3047 - mae: 13.6157 - val_loss: 275.1225 - val_mae: 12.1775\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 328.6868 - mae: 13.5254 - val_loss: 270.6544 - val_mae: 12.0871\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 324.3137 - mae: 13.4389 - val_loss: 266.3479 - val_mae: 12.0018\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 320.2615 - mae: 13.3671 - val_loss: 262.2526 - val_mae: 11.9189\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 316.1350 - mae: 13.2828 - val_loss: 258.1887 - val_mae: 11.8364\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 312.1243 - mae: 13.2007 - val_loss: 254.1879 - val_mae: 11.7561\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 308.2903 - mae: 13.1222 - val_loss: 250.1443 - val_mae: 11.6778\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 304.6248 - mae: 13.0583 - val_loss: 246.5864 - val_mae: 11.6054\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 301.0094 - mae: 12.9874 - val_loss: 243.0066 - val_mae: 11.5389\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 297.3836 - mae: 12.9232 - val_loss: 239.2413 - val_mae: 11.4643\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 293.9904 - mae: 12.8591 - val_loss: 235.6096 - val_mae: 11.3928\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 290.7342 - mae: 12.7946 - val_loss: 232.2045 - val_mae: 11.3252\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 287.2664 - mae: 12.7334 - val_loss: 228.9859 - val_mae: 11.2567\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 284.2786 - mae: 12.6716 - val_loss: 225.6641 - val_mae: 11.1883\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 281.1440 - mae: 12.6087 - val_loss: 222.6892 - val_mae: 11.1244\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 278.2751 - mae: 12.5544 - val_loss: 219.8690 - val_mae: 11.0600\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 275.3845 - mae: 12.4890 - val_loss: 216.9523 - val_mae: 10.9974\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 272.5180 - mae: 12.4340 - val_loss: 214.0648 - val_mae: 10.9356\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 269.8524 - mae: 12.3782 - val_loss: 211.4763 - val_mae: 10.8758\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 267.2075 - mae: 12.3192 - val_loss: 208.8770 - val_mae: 10.8174\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 264.6487 - mae: 12.2650 - val_loss: 206.2228 - val_mae: 10.7569\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 262.0960 - mae: 12.2133 - val_loss: 203.5024 - val_mae: 10.6961\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 259.5814 - mae: 12.1595 - val_loss: 200.9265 - val_mae: 10.6370\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 257.1557 - mae: 12.1061 - val_loss: 198.3142 - val_mae: 10.5796\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 254.8090 - mae: 12.0541 - val_loss: 195.7540 - val_mae: 10.5239\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 252.3944 - mae: 12.0090 - val_loss: 193.5060 - val_mae: 10.4715\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 250.1431 - mae: 11.9573 - val_loss: 191.0763 - val_mae: 10.4152\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 247.9584 - mae: 11.9142 - val_loss: 188.8992 - val_mae: 10.3628\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 245.8244 - mae: 11.8641 - val_loss: 186.7437 - val_mae: 10.3120\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 243.7379 - mae: 11.8170 - val_loss: 184.5680 - val_mae: 10.2591\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 241.5840 - mae: 11.7735 - val_loss: 182.3028 - val_mae: 10.2047\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 239.5797 - mae: 11.7264 - val_loss: 180.3053 - val_mae: 10.1543\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 237.6190 - mae: 11.6783 - val_loss: 178.2414 - val_mae: 10.1048\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 235.5932 - mae: 11.6326 - val_loss: 176.2833 - val_mae: 10.0597\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 233.7305 - mae: 11.5938 - val_loss: 174.3149 - val_mae: 10.0122\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 231.8828 - mae: 11.5521 - val_loss: 172.3129 - val_mae: 9.9627\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 230.0069 - mae: 11.5137 - val_loss: 170.6226 - val_mae: 9.9202\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 228.1945 - mae: 11.4729 - val_loss: 168.5036 - val_mae: 9.8693\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 226.3835 - mae: 11.4307 - val_loss: 166.7513 - val_mae: 9.8241\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 224.8312 - mae: 11.3922 - val_loss: 165.0382 - val_mae: 9.7807\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 223.0831 - mae: 11.3570 - val_loss: 163.1681 - val_mae: 9.7326\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 221.3989 - mae: 11.3119 - val_loss: 161.3938 - val_mae: 9.6909\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 219.7085 - mae: 11.2762 - val_loss: 159.8325 - val_mae: 9.6512\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 218.0765 - mae: 11.2365 - val_loss: 158.1028 - val_mae: 9.6091\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 216.4777 - mae: 11.1995 - val_loss: 156.4754 - val_mae: 9.5674\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 214.9028 - mae: 11.1656 - val_loss: 154.8459 - val_mae: 9.5253\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 213.4212 - mae: 11.1326 - val_loss: 153.3781 - val_mae: 9.4846\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 211.9812 - mae: 11.0974 - val_loss: 151.9839 - val_mae: 9.4489\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 210.5247 - mae: 11.0679 - val_loss: 150.4833 - val_mae: 9.4057\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 209.1146 - mae: 11.0297 - val_loss: 148.7788 - val_mae: 9.3604\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 207.6859 - mae: 10.9931 - val_loss: 147.3405 - val_mae: 9.3220\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 206.3311 - mae: 10.9582 - val_loss: 145.9065 - val_mae: 9.2814\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 204.9298 - mae: 10.9236 - val_loss: 144.6092 - val_mae: 9.2454\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 203.6394 - mae: 10.8860 - val_loss: 143.1504 - val_mae: 9.2089\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 202.2864 - mae: 10.8598 - val_loss: 141.6966 - val_mae: 9.1696\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 200.9317 - mae: 10.8274 - val_loss: 140.3068 - val_mae: 9.1293\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 199.6741 - mae: 10.7922 - val_loss: 139.0458 - val_mae: 9.0955\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 198.4682 - mae: 10.7652 - val_loss: 137.6189 - val_mae: 9.0586\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 197.2213 - mae: 10.7349 - val_loss: 136.3540 - val_mae: 9.0205\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 196.0156 - mae: 10.7002 - val_loss: 135.0005 - val_mae: 8.9832\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.5, model__n_hidden=2, model__n_neurons=125, model__optimizer=nesterov; total time=   3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 774, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 89, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 331, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 16875]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmp58m671sw\\assets\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 19ms/step - loss: 4285.7812 - mae: 52.0060 - val_loss: 3759.9292 - val_mae: 48.8046\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3415.3003 - mae: 46.6421 - val_loss: 3003.0598 - val_mae: 43.7897\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2782.9290 - mae: 42.1972 - val_loss: 2449.6494 - val_mae: 39.6665\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2313.8931 - mae: 38.5485 - val_loss: 2032.5811 - val_mae: 36.2105\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1956.9255 - mae: 35.4575 - val_loss: 1712.9210 - val_mae: 33.2932\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1680.0054 - mae: 32.8506 - val_loss: 1463.0750 - val_mae: 30.7951\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1461.3992 - mae: 30.6165 - val_loss: 1264.4069 - val_mae: 28.6289\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1285.6058 - mae: 28.6463 - val_loss: 1104.3735 - val_mae: 26.7352\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1142.7861 - mae: 26.9522 - val_loss: 973.3752 - val_mae: 25.0650\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1024.3542 - mae: 25.4315 - val_loss: 865.9274 - val_mae: 23.5931\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 926.6938 - mae: 24.0990 - val_loss: 776.9022 - val_mae: 22.2930\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 844.5819 - mae: 22.9078 - val_loss: 701.7670 - val_mae: 21.1294\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 774.7203 - mae: 21.8335 - val_loss: 638.2734 - val_mae: 20.0888\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 714.9803 - mae: 20.8698 - val_loss: 584.4247 - val_mae: 19.1581\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 663.8589 - mae: 20.0023 - val_loss: 538.4876 - val_mae: 18.3256\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 619.6390 - mae: 19.2356 - val_loss: 498.4881 - val_mae: 17.5706\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 580.7440 - mae: 18.5175 - val_loss: 463.9670 - val_mae: 16.8915\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 546.9492 - mae: 17.8812 - val_loss: 433.9072 - val_mae: 16.2770\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 516.8234 - mae: 17.3030 - val_loss: 407.6385 - val_mae: 15.7178\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 490.1663 - mae: 16.7701 - val_loss: 384.7372 - val_mae: 15.2120\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 466.8842 - mae: 16.2941 - val_loss: 364.5219 - val_mae: 14.7500\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 445.8723 - mae: 15.8575 - val_loss: 346.6876 - val_mae: 14.3281\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 427.2093 - mae: 15.4618 - val_loss: 330.8567 - val_mae: 13.9463\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 410.3842 - mae: 15.0991 - val_loss: 316.7253 - val_mae: 13.5990\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 395.0714 - mae: 14.7677 - val_loss: 304.1826 - val_mae: 13.2866\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 381.2371 - mae: 14.4625 - val_loss: 292.8497 - val_mae: 13.0012\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 368.6054 - mae: 14.1892 - val_loss: 282.6783 - val_mae: 12.7421\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 357.2218 - mae: 13.9398 - val_loss: 273.5999 - val_mae: 12.5082\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 346.6006 - mae: 13.7006 - val_loss: 265.3623 - val_mae: 12.2925\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 337.1889 - mae: 13.4899 - val_loss: 257.8679 - val_mae: 12.0959\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 328.1942 - mae: 13.2914 - val_loss: 251.0689 - val_mae: 11.9148\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 319.8310 - mae: 13.1057 - val_loss: 244.8600 - val_mae: 11.7504\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 312.2623 - mae: 12.9364 - val_loss: 239.1959 - val_mae: 11.5972\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 305.2432 - mae: 12.7774 - val_loss: 234.0318 - val_mae: 11.4562\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 298.6362 - mae: 12.6295 - val_loss: 229.2870 - val_mae: 11.3293\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 292.5719 - mae: 12.4930 - val_loss: 224.8642 - val_mae: 11.2103\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 286.8093 - mae: 12.3656 - val_loss: 220.7785 - val_mae: 11.0990\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 281.5124 - mae: 12.2519 - val_loss: 216.9698 - val_mae: 10.9956\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 276.4366 - mae: 12.1436 - val_loss: 213.4362 - val_mae: 10.9010\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 271.4960 - mae: 12.0339 - val_loss: 210.1493 - val_mae: 10.8141\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 266.9326 - mae: 11.9320 - val_loss: 207.0605 - val_mae: 10.7313\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 262.6414 - mae: 11.8326 - val_loss: 204.1897 - val_mae: 10.6582\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 258.4424 - mae: 11.7472 - val_loss: 201.4628 - val_mae: 10.5859\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 254.5876 - mae: 11.6610 - val_loss: 198.8838 - val_mae: 10.5161\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 250.8028 - mae: 11.5769 - val_loss: 196.4765 - val_mae: 10.4534\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 247.3024 - mae: 11.4963 - val_loss: 194.1842 - val_mae: 10.3942\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 243.8851 - mae: 11.4304 - val_loss: 191.9546 - val_mae: 10.3339\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 240.6102 - mae: 11.3543 - val_loss: 189.8721 - val_mae: 10.2781\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 237.5022 - mae: 11.2858 - val_loss: 187.8825 - val_mae: 10.2270\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 234.4883 - mae: 11.2175 - val_loss: 185.9859 - val_mae: 10.1771\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 231.5298 - mae: 11.1560 - val_loss: 184.1412 - val_mae: 10.1271\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 228.8512 - mae: 11.0953 - val_loss: 182.3803 - val_mae: 10.0803\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 226.0238 - mae: 11.0344 - val_loss: 180.6728 - val_mae: 10.0369\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 223.2772 - mae: 10.9772 - val_loss: 179.0445 - val_mae: 9.9940\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 220.6947 - mae: 10.9190 - val_loss: 177.4661 - val_mae: 9.9514\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 218.2815 - mae: 10.8691 - val_loss: 175.9160 - val_mae: 9.9082\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 215.9337 - mae: 10.8114 - val_loss: 174.4520 - val_mae: 9.8687\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 213.6818 - mae: 10.7604 - val_loss: 173.0451 - val_mae: 9.8299\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 211.4276 - mae: 10.7049 - val_loss: 171.6674 - val_mae: 9.7936\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 209.2347 - mae: 10.6564 - val_loss: 170.2966 - val_mae: 9.7563\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 207.1465 - mae: 10.6119 - val_loss: 169.0195 - val_mae: 9.7205\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 205.0518 - mae: 10.5579 - val_loss: 167.7252 - val_mae: 9.6863\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 203.0029 - mae: 10.5117 - val_loss: 166.4425 - val_mae: 9.6511\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 201.0391 - mae: 10.4691 - val_loss: 165.2245 - val_mae: 9.6179\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 199.1070 - mae: 10.4237 - val_loss: 164.0323 - val_mae: 9.5855\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 197.1972 - mae: 10.3787 - val_loss: 162.8862 - val_mae: 9.5542\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 195.4314 - mae: 10.3355 - val_loss: 161.7878 - val_mae: 9.5252\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 193.5868 - mae: 10.2955 - val_loss: 160.6393 - val_mae: 9.4913\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 191.9115 - mae: 10.2514 - val_loss: 159.6020 - val_mae: 9.4626\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 190.2025 - mae: 10.2122 - val_loss: 158.5409 - val_mae: 9.4322\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 188.5476 - mae: 10.1699 - val_loss: 157.5457 - val_mae: 9.4038\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 186.8919 - mae: 10.1302 - val_loss: 156.5315 - val_mae: 9.3741\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 185.3783 - mae: 10.0896 - val_loss: 155.5542 - val_mae: 9.3482\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 183.7601 - mae: 10.0548 - val_loss: 154.5884 - val_mae: 9.3199\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 182.2501 - mae: 10.0201 - val_loss: 153.6431 - val_mae: 9.2914\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 180.8067 - mae: 9.9788 - val_loss: 152.7274 - val_mae: 9.2664\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 179.3250 - mae: 9.9448 - val_loss: 151.8023 - val_mae: 9.2390\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 177.8954 - mae: 9.9097 - val_loss: 150.9286 - val_mae: 9.2137\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 176.4699 - mae: 9.8757 - val_loss: 149.9730 - val_mae: 9.1841\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 175.0721 - mae: 9.8397 - val_loss: 149.0767 - val_mae: 9.1561\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 173.7626 - mae: 9.8067 - val_loss: 148.2868 - val_mae: 9.1336\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 172.4709 - mae: 9.7719 - val_loss: 147.4801 - val_mae: 9.1110\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 171.1829 - mae: 9.7374 - val_loss: 146.7153 - val_mae: 9.0883\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 169.9129 - mae: 9.7054 - val_loss: 145.9153 - val_mae: 9.0635\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 168.7323 - mae: 9.6738 - val_loss: 145.0782 - val_mae: 9.0363\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 167.4970 - mae: 9.6408 - val_loss: 144.2431 - val_mae: 9.0088\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 166.3017 - mae: 9.6046 - val_loss: 143.4832 - val_mae: 8.9853\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 165.0970 - mae: 9.5730 - val_loss: 142.7053 - val_mae: 8.9605\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 163.9697 - mae: 9.5435 - val_loss: 141.9735 - val_mae: 8.9391\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 162.9096 - mae: 9.5152 - val_loss: 141.2894 - val_mae: 8.9203\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 161.6803 - mae: 9.4864 - val_loss: 140.6146 - val_mae: 8.8998\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 160.6368 - mae: 9.4588 - val_loss: 139.9818 - val_mae: 8.8817\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 159.5681 - mae: 9.4307 - val_loss: 139.2908 - val_mae: 8.8592\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 158.5809 - mae: 9.4016 - val_loss: 138.5463 - val_mae: 8.8345\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 157.5368 - mae: 9.3725 - val_loss: 137.8956 - val_mae: 8.8145\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 156.5253 - mae: 9.3414 - val_loss: 137.2374 - val_mae: 8.7944\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 155.5084 - mae: 9.3203 - val_loss: 136.5804 - val_mae: 8.7724\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 154.5577 - mae: 9.2888 - val_loss: 135.9484 - val_mae: 8.7524\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 153.6187 - mae: 9.2598 - val_loss: 135.3354 - val_mae: 8.7322\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 152.7133 - mae: 9.2347 - val_loss: 134.6916 - val_mae: 8.7107\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.5, model__n_hidden=2, model__n_neurons=125, model__optimizer=nesterov; total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 774, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 89, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 331, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 16750]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmp37a7mj4_\\assets\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 13ms/step - loss: 3713.8210 - mae: 48.7034 - val_loss: 1462.5565 - val_mae: 31.5432\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 948.2074 - mae: 24.7672 - val_loss: 517.8402 - val_mae: 17.7830\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 442.7099 - mae: 16.1561 - val_loss: 366.7993 - val_mae: 13.9291\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 349.7742 - mae: 13.8275 - val_loss: 319.8470 - val_mae: 12.8886\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 314.4920 - mae: 13.0339 - val_loss: 292.1136 - val_mae: 12.3315\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 291.6436 - mae: 12.5627 - val_loss: 266.3597 - val_mae: 11.8386\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 271.2805 - mae: 12.1551 - val_loss: 242.4072 - val_mae: 11.3793\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 253.4955 - mae: 11.8015 - val_loss: 221.1557 - val_mae: 10.9402\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 237.0859 - mae: 11.4337 - val_loss: 202.9668 - val_mae: 10.5628\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 222.5589 - mae: 11.1292 - val_loss: 187.1566 - val_mae: 10.1980\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 209.7062 - mae: 10.8423 - val_loss: 171.4784 - val_mae: 9.8326\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 198.1269 - mae: 10.5371 - val_loss: 158.9116 - val_mae: 9.4983\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 187.5782 - mae: 10.2575 - val_loss: 146.7464 - val_mae: 9.1802\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 178.8076 - mae: 10.0792 - val_loss: 135.9532 - val_mae: 8.8879\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 170.2633 - mae: 9.7987 - val_loss: 126.6523 - val_mae: 8.6031\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 163.2648 - mae: 9.5873 - val_loss: 117.7552 - val_mae: 8.3365\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 156.4466 - mae: 9.4072 - val_loss: 109.5406 - val_mae: 8.0848\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 150.1200 - mae: 9.2113 - val_loss: 103.2024 - val_mae: 7.8782\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 144.8051 - mae: 9.0290 - val_loss: 97.6863 - val_mae: 7.6937\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 140.0503 - mae: 8.9247 - val_loss: 91.8963 - val_mae: 7.5030\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 135.7842 - mae: 8.8139 - val_loss: 86.6652 - val_mae: 7.3013\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 131.6846 - mae: 8.6329 - val_loss: 82.0578 - val_mae: 7.1159\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 128.3204 - mae: 8.4925 - val_loss: 78.2559 - val_mae: 6.9741\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 125.0720 - mae: 8.4246 - val_loss: 74.7954 - val_mae: 6.8320\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 122.2887 - mae: 8.3314 - val_loss: 71.5011 - val_mae: 6.6850\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 119.6284 - mae: 8.2069 - val_loss: 68.5553 - val_mae: 6.5659\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 117.5081 - mae: 8.1336 - val_loss: 66.1307 - val_mae: 6.4618\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 115.5166 - mae: 8.0729 - val_loss: 63.6240 - val_mae: 6.3374\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 113.8906 - mae: 7.9579 - val_loss: 61.7164 - val_mae: 6.2487\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 112.0032 - mae: 7.9601 - val_loss: 59.8121 - val_mae: 6.1609\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 110.4888 - mae: 7.8662 - val_loss: 57.7039 - val_mae: 6.0503\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.1914 - mae: 7.7700 - val_loss: 56.0567 - val_mae: 5.9597\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.9309 - mae: 7.7457 - val_loss: 55.2428 - val_mae: 5.9248\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.8928 - mae: 7.7335 - val_loss: 54.1869 - val_mae: 5.8683\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.0516 - mae: 7.6978 - val_loss: 52.9959 - val_mae: 5.8013\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.1639 - mae: 7.6618 - val_loss: 51.8526 - val_mae: 5.7370\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.4621 - mae: 7.6033 - val_loss: 50.7834 - val_mae: 5.6763\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.6079 - mae: 7.5858 - val_loss: 49.9055 - val_mae: 5.6236\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.0089 - mae: 7.5204 - val_loss: 49.1795 - val_mae: 5.5797\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.6782 - mae: 7.5211 - val_loss: 48.8832 - val_mae: 5.5654\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.8050 - mae: 7.5605 - val_loss: 48.4876 - val_mae: 5.5422\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.2268 - mae: 7.5095 - val_loss: 47.6232 - val_mae: 5.4893\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.8833 - mae: 7.5012 - val_loss: 46.9692 - val_mae: 5.4508\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.3625 - mae: 7.4614 - val_loss: 46.3668 - val_mae: 5.4134\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.2916 - mae: 7.4857 - val_loss: 46.0337 - val_mae: 5.3929\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.6921 - mae: 7.4286 - val_loss: 45.5769 - val_mae: 5.3631\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.8691 - mae: 7.4125 - val_loss: 45.1364 - val_mae: 5.3348\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.3243 - mae: 7.4246 - val_loss: 45.2041 - val_mae: 5.3409\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.8762 - mae: 7.4053 - val_loss: 45.1262 - val_mae: 5.3364\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.6032 - mae: 7.4239 - val_loss: 45.0892 - val_mae: 5.3336\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.4240 - mae: 7.4071 - val_loss: 44.6385 - val_mae: 5.3058\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.2692 - mae: 7.4079 - val_loss: 44.5171 - val_mae: 5.2974\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.1399 - mae: 7.3861 - val_loss: 44.2588 - val_mae: 5.2814\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.3414 - mae: 7.4491 - val_loss: 43.9867 - val_mae: 5.2643\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.0116 - mae: 7.3404 - val_loss: 43.5413 - val_mae: 5.2375\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.5494 - mae: 7.3693 - val_loss: 43.6017 - val_mae: 5.2430\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.4193 - mae: 7.3463 - val_loss: 43.4157 - val_mae: 5.2291\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.3761 - mae: 7.3634 - val_loss: 43.3973 - val_mae: 5.2284\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.3705 - mae: 7.3994 - val_loss: 43.2300 - val_mae: 5.2189\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.2239 - mae: 7.3175 - val_loss: 42.8929 - val_mae: 5.1980\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.0770 - mae: 7.3321 - val_loss: 42.8985 - val_mae: 5.1971\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.9992 - mae: 7.3704 - val_loss: 42.6705 - val_mae: 5.1813\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.8631 - mae: 7.3260 - val_loss: 42.3596 - val_mae: 5.1628\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.7464 - mae: 7.3225 - val_loss: 42.4370 - val_mae: 5.1701\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.7725 - mae: 7.3102 - val_loss: 42.6715 - val_mae: 5.1861\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.5707 - mae: 7.3326 - val_loss: 42.3920 - val_mae: 5.1667\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 96.5124 - mae: 7.3066 - val_loss: 42.3379 - val_mae: 5.1648\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.4284 - mae: 7.3416 - val_loss: 42.3039 - val_mae: 5.1622\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.3899 - mae: 7.3382 - val_loss: 42.3559 - val_mae: 5.1673\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.1249 - mae: 7.3195 - val_loss: 42.2659 - val_mae: 5.1632\n",
      "Epoch 70: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.5, model__n_hidden=1, model__n_neurons=125, model__optimizer=momentum; total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 774, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 89, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 331, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 16875]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmp42zkbjgz\\assets\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 17ms/step - loss: 3201.0095 - mae: 45.5096 - val_loss: 1283.4233 - val_mae: 29.0938\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 919.0462 - mae: 23.9037 - val_loss: 478.1333 - val_mae: 16.8482\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 472.8455 - mae: 16.5628 - val_loss: 333.3196 - val_mae: 13.5438\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 376.7401 - mae: 14.5604 - val_loss: 287.8464 - val_mae: 12.6178\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 337.6594 - mae: 13.8203 - val_loss: 258.8398 - val_mae: 12.0290\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 309.1544 - mae: 13.3049 - val_loss: 231.4854 - val_mae: 11.4629\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 284.9902 - mae: 12.8136 - val_loss: 207.6994 - val_mae: 10.9421\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 264.2438 - mae: 12.4125 - val_loss: 188.0130 - val_mae: 10.4808\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 245.3413 - mae: 11.9719 - val_loss: 171.3478 - val_mae: 10.0573\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 229.0607 - mae: 11.6087 - val_loss: 156.4949 - val_mae: 9.6623\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 215.0816 - mae: 11.2987 - val_loss: 142.5148 - val_mae: 9.2789\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 202.6884 - mae: 10.9592 - val_loss: 130.8424 - val_mae: 8.9260\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 191.8002 - mae: 10.6880 - val_loss: 120.9317 - val_mae: 8.6218\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 182.7254 - mae: 10.4669 - val_loss: 111.7001 - val_mae: 8.3168\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 174.0912 - mae: 10.1980 - val_loss: 104.0939 - val_mae: 8.0497\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 166.8407 - mae: 10.0123 - val_loss: 96.8571 - val_mae: 7.7781\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 160.4283 - mae: 9.7947 - val_loss: 90.6361 - val_mae: 7.5502\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 154.5770 - mae: 9.6212 - val_loss: 85.5328 - val_mae: 7.3557\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 149.7614 - mae: 9.4587 - val_loss: 81.1045 - val_mae: 7.1805\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 145.2632 - mae: 9.3509 - val_loss: 76.5006 - val_mae: 6.9866\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 141.5277 - mae: 9.2438 - val_loss: 71.9068 - val_mae: 6.7768\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 137.9210 - mae: 9.0549 - val_loss: 68.3334 - val_mae: 6.6054\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 134.8315 - mae: 8.9443 - val_loss: 65.8963 - val_mae: 6.4875\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 132.4228 - mae: 8.8962 - val_loss: 63.6255 - val_mae: 6.3700\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 130.1071 - mae: 8.8263 - val_loss: 61.3817 - val_mae: 6.2499\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 127.8674 - mae: 8.7225 - val_loss: 59.4221 - val_mae: 6.1503\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 126.0925 - mae: 8.6637 - val_loss: 57.7174 - val_mae: 6.0538\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 124.7151 - mae: 8.5886 - val_loss: 55.8589 - val_mae: 5.9481\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 123.0001 - mae: 8.5168 - val_loss: 54.6389 - val_mae: 5.8748\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 121.7781 - mae: 8.4758 - val_loss: 53.9341 - val_mae: 5.8302\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 120.8201 - mae: 8.4693 - val_loss: 52.6710 - val_mae: 5.7537\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 119.9376 - mae: 8.3992 - val_loss: 51.4335 - val_mae: 5.6790\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 118.7304 - mae: 8.4025 - val_loss: 51.5043 - val_mae: 5.6777\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 118.1233 - mae: 8.3846 - val_loss: 50.7381 - val_mae: 5.6300\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 117.2325 - mae: 8.3513 - val_loss: 50.1577 - val_mae: 5.5931\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 116.7091 - mae: 8.3631 - val_loss: 49.2185 - val_mae: 5.5347\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 116.2038 - mae: 8.2982 - val_loss: 48.3240 - val_mae: 5.4781\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 115.5826 - mae: 8.2731 - val_loss: 47.8208 - val_mae: 5.4463\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 115.1125 - mae: 8.2677 - val_loss: 47.2695 - val_mae: 5.4137\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 114.8275 - mae: 8.2250 - val_loss: 47.2669 - val_mae: 5.4094\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 114.5908 - mae: 8.3159 - val_loss: 47.2119 - val_mae: 5.4027\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 113.8453 - mae: 8.2455 - val_loss: 45.9977 - val_mae: 5.3330\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 113.6354 - mae: 8.1976 - val_loss: 45.6470 - val_mae: 5.3100\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 113.3658 - mae: 8.2104 - val_loss: 45.6024 - val_mae: 5.3033\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 114.1760 - mae: 8.3213 - val_loss: 45.1685 - val_mae: 5.2775\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 113.3138 - mae: 8.1632 - val_loss: 44.7521 - val_mae: 5.2520\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 112.7998 - mae: 8.1680 - val_loss: 44.6004 - val_mae: 5.2405\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 112.6589 - mae: 8.1870 - val_loss: 44.7744 - val_mae: 5.2503\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 112.5431 - mae: 8.1618 - val_loss: 45.3141 - val_mae: 5.2788\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 112.0896 - mae: 8.2352 - val_loss: 46.0353 - val_mae: 5.3176\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.9668 - mae: 8.2138 - val_loss: 44.6212 - val_mae: 5.2384\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.9937 - mae: 8.1802 - val_loss: 44.6418 - val_mae: 5.2378\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.6396 - mae: 8.1915 - val_loss: 44.6405 - val_mae: 5.2370\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.9278 - mae: 8.2092 - val_loss: 44.3209 - val_mae: 5.2187\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.3319 - mae: 8.1407 - val_loss: 43.8436 - val_mae: 5.1917\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.3714 - mae: 8.1656 - val_loss: 44.3686 - val_mae: 5.2218\n",
      "Epoch 56: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.5, model__n_hidden=1, model__n_neurons=125, model__optimizer=momentum; total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 774, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 89, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 331, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 16875]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmparm1yu99\\assets\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 16ms/step - loss: 3012.4775 - mae: 43.5322 - val_loss: 1267.6464 - val_mae: 28.7913\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 971.6588 - mae: 24.7981 - val_loss: 501.7090 - val_mae: 17.8100\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 551.9998 - mae: 17.9267 - val_loss: 354.6204 - val_mae: 14.3642\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 444.5149 - mae: 15.7097 - val_loss: 309.5024 - val_mae: 13.2748\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 393.3804 - mae: 14.7348 - val_loss: 281.3016 - val_mae: 12.6575\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 353.6714 - mae: 13.9583 - val_loss: 258.4153 - val_mae: 12.1424\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 320.7148 - mae: 13.3247 - val_loss: 238.9001 - val_mae: 11.7094\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 291.7236 - mae: 12.8267 - val_loss: 221.3158 - val_mae: 11.2901\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 266.4481 - mae: 12.2256 - val_loss: 206.0094 - val_mae: 10.8942\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 243.7371 - mae: 11.7803 - val_loss: 192.4022 - val_mae: 10.5478\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 224.9124 - mae: 11.3115 - val_loss: 180.9060 - val_mae: 10.2316\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 207.9612 - mae: 10.9187 - val_loss: 170.3670 - val_mae: 9.9353\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 193.6391 - mae: 10.5706 - val_loss: 160.9032 - val_mae: 9.6569\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 180.5059 - mae: 10.2023 - val_loss: 153.0063 - val_mae: 9.4205\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 169.3497 - mae: 9.8949 - val_loss: 145.7522 - val_mae: 9.1891\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 159.6572 - mae: 9.6011 - val_loss: 139.2363 - val_mae: 8.9689\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 151.4124 - mae: 9.3726 - val_loss: 133.2612 - val_mae: 8.7590\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 143.5761 - mae: 9.0897 - val_loss: 127.8821 - val_mae: 8.5566\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 137.1301 - mae: 8.8683 - val_loss: 123.8091 - val_mae: 8.4218\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 131.2010 - mae: 8.7008 - val_loss: 119.6779 - val_mae: 8.2642\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 126.2348 - mae: 8.4870 - val_loss: 116.2509 - val_mae: 8.1297\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 121.8350 - mae: 8.3310 - val_loss: 113.0142 - val_mae: 7.9985\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 118.2605 - mae: 8.1796 - val_loss: 110.6522 - val_mae: 7.9099\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 114.7305 - mae: 8.0566 - val_loss: 108.1644 - val_mae: 7.8055\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 111.8323 - mae: 7.9533 - val_loss: 105.9652 - val_mae: 7.7105\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 109.2150 - mae: 7.8260 - val_loss: 103.7201 - val_mae: 7.6056\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 107.0541 - mae: 7.7567 - val_loss: 102.0662 - val_mae: 7.5351\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 105.0352 - mae: 7.6484 - val_loss: 100.1342 - val_mae: 7.4421\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 103.2768 - mae: 7.5624 - val_loss: 98.8218 - val_mae: 7.3855\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.9046 - mae: 7.5215 - val_loss: 97.1808 - val_mae: 7.3003\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 100.5201 - mae: 7.4482 - val_loss: 95.9626 - val_mae: 7.2420\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 99.3240 - mae: 7.3761 - val_loss: 95.2520 - val_mae: 7.2189\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 98.2682 - mae: 7.3717 - val_loss: 94.4283 - val_mae: 7.1865\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.3020 - mae: 7.3206 - val_loss: 93.0528 - val_mae: 7.1044\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.4438 - mae: 7.2608 - val_loss: 92.4025 - val_mae: 7.0769\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.8754 - mae: 7.2449 - val_loss: 91.6060 - val_mae: 7.0441\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 95.3341 - mae: 7.2505 - val_loss: 90.6677 - val_mae: 6.9862\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.7528 - mae: 7.1898 - val_loss: 89.8131 - val_mae: 6.9388\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.5813 - mae: 7.1766 - val_loss: 89.2449 - val_mae: 6.9148\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.6307 - mae: 7.1475 - val_loss: 89.1696 - val_mae: 6.9294\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.4874 - mae: 7.1582 - val_loss: 89.0005 - val_mae: 6.9304\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.0843 - mae: 7.1307 - val_loss: 88.4957 - val_mae: 6.9047\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.5257 - mae: 7.1526 - val_loss: 88.6754 - val_mae: 6.9369\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.4633 - mae: 7.1435 - val_loss: 87.6444 - val_mae: 6.8721\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.9839 - mae: 7.1031 - val_loss: 87.1680 - val_mae: 6.8463\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 91.6603 - mae: 7.1016 - val_loss: 86.9079 - val_mae: 6.8418\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 91.8805 - mae: 7.1448 - val_loss: 86.4534 - val_mae: 6.8118\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 91.4195 - mae: 7.0669 - val_loss: 85.9263 - val_mae: 6.7798\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.2016 - mae: 7.0709 - val_loss: 85.6080 - val_mae: 6.7715\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 91.1323 - mae: 7.0835 - val_loss: 85.7140 - val_mae: 6.7903\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.0010 - mae: 7.0906 - val_loss: 85.4793 - val_mae: 6.7728\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.7291 - mae: 7.0632 - val_loss: 85.0718 - val_mae: 6.7502\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.5865 - mae: 7.0447 - val_loss: 85.0834 - val_mae: 6.7638\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 90.5028 - mae: 7.0862 - val_loss: 85.2200 - val_mae: 6.7858\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 90.3255 - mae: 7.0749 - val_loss: 85.0621 - val_mae: 6.7809\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.2166 - mae: 7.0780 - val_loss: 84.5908 - val_mae: 6.7505\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 90.0585 - mae: 7.0409 - val_loss: 83.9869 - val_mae: 6.7136\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 90.0184 - mae: 7.0519 - val_loss: 83.7117 - val_mae: 6.7033\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 89.8409 - mae: 7.0336 - val_loss: 83.8867 - val_mae: 6.7231\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 89.6878 - mae: 7.0545 - val_loss: 83.7523 - val_mae: 6.7255\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 89.6801 - mae: 7.0448 - val_loss: 83.2715 - val_mae: 6.6875\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 89.5466 - mae: 7.0485 - val_loss: 83.3017 - val_mae: 6.6983\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 89.5919 - mae: 7.0493 - val_loss: 83.1423 - val_mae: 6.6916\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.4283 - mae: 7.0125 - val_loss: 82.7793 - val_mae: 6.6672\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 89.4655 - mae: 7.0567 - val_loss: 82.7558 - val_mae: 6.6719\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.2190 - mae: 7.0198 - val_loss: 82.5070 - val_mae: 6.6532\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.2004 - mae: 7.0192 - val_loss: 82.6819 - val_mae: 6.6769\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.1591 - mae: 7.0441 - val_loss: 82.6492 - val_mae: 6.6779\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 89.4256 - mae: 7.0104 - val_loss: 82.2723 - val_mae: 6.6535\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.8686 - mae: 7.0232 - val_loss: 82.2280 - val_mae: 6.6589\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.7831 - mae: 7.0001 - val_loss: 82.0285 - val_mae: 6.6454\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.6509 - mae: 7.0168 - val_loss: 82.1874 - val_mae: 6.6597\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.9332 - mae: 6.9920 - val_loss: 81.9399 - val_mae: 6.6446\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.5986 - mae: 7.0123 - val_loss: 82.2977 - val_mae: 6.6741\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 88.4641 - mae: 7.0085 - val_loss: 82.0188 - val_mae: 6.6520\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.5542 - mae: 6.9861 - val_loss: 81.7729 - val_mae: 6.6373\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.3393 - mae: 7.0092 - val_loss: 81.9418 - val_mae: 6.6561\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.3313 - mae: 7.0038 - val_loss: 81.5656 - val_mae: 6.6320\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.4480 - mae: 7.0342 - val_loss: 81.2143 - val_mae: 6.6090\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.1876 - mae: 6.9734 - val_loss: 80.7720 - val_mae: 6.5764\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 88.0596 - mae: 6.9564 - val_loss: 80.7176 - val_mae: 6.5750\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.1112 - mae: 6.9909 - val_loss: 80.9187 - val_mae: 6.6002\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.0566 - mae: 6.9853 - val_loss: 81.0572 - val_mae: 6.6150\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 87.7645 - mae: 6.9889 - val_loss: 81.1002 - val_mae: 6.6222\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.8946 - mae: 7.0134 - val_loss: 80.4187 - val_mae: 6.5739\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.8886 - mae: 6.9768 - val_loss: 79.9932 - val_mae: 6.5430\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.7018 - mae: 6.9338 - val_loss: 79.7394 - val_mae: 6.5305\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.5136 - mae: 6.9473 - val_loss: 80.1374 - val_mae: 6.5584\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.4145 - mae: 6.9491 - val_loss: 79.9773 - val_mae: 6.5542\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.6783 - mae: 6.9609 - val_loss: 80.0776 - val_mae: 6.5630\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 87.3224 - mae: 6.9577 - val_loss: 80.6348 - val_mae: 6.6000\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 87.2946 - mae: 6.9608 - val_loss: 80.5431 - val_mae: 6.5962\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 87.2448 - mae: 6.9799 - val_loss: 80.5019 - val_mae: 6.6006\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.1817 - mae: 6.9815 - val_loss: 79.7379 - val_mae: 6.5436\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.0352 - mae: 6.9272 - val_loss: 79.2435 - val_mae: 6.5064\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.0321 - mae: 6.9318 - val_loss: 79.4080 - val_mae: 6.5289\n",
      "Epoch 96: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.5, model__n_hidden=1, model__n_neurons=125, model__optimizer=momentum; total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 774, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 89, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 331, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 16750]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmp5yvn7tlv\\assets\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23399.2207 - mae: 72.8679 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.5, model__n_hidden=0, model__n_neurons=125, model__optimizer=adam; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 774, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 89, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 331, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 1755]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmpctfgb2r5\\assets\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 24ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23112.9844 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 23112.9844 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.5, model__n_hidden=0, model__n_neurons=125, model__optimizer=adam; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 774, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 89, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 331, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 1755]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmp_bu9uhl5\\assets\n",
      "Epoch 1/100\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 21635.4844 - mae: 71.4221"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 14ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23041.8223 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23041.8223 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.5, model__n_hidden=0, model__n_neurons=125, model__optimizer=adam; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 774, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 89, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 331, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 1742]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmpb184mevg\\assets\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 20ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 10: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.1, model__n_hidden=3, model__n_neurons=5, model__optimizer=sgd; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 774, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 89, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 331, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 675]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmp5h3egic3\\assets\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 17ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 10: early stopping\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.1, model__n_hidden=3, model__n_neurons=5, model__optimizer=sgd; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 774, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 89, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 331, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 675]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmpbsi8qzuz\\assets\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 24ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 10: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.1, model__n_hidden=3, model__n_neurons=5, model__optimizer=sgd; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 774, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 89, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 331, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 670]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmp8ivjn821\\assets\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 21ms/step - loss: 43379.8750 - mae: 188.7462 - val_loss: 42265.0000 - val_mae: 186.6472\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43377.1250 - mae: 188.7392 - val_loss: 42262.3047 - val_mae: 186.6404\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43374.3672 - mae: 188.7322 - val_loss: 42259.6250 - val_mae: 186.6337\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43371.6133 - mae: 188.7253 - val_loss: 42256.9492 - val_mae: 186.6270\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43368.8828 - mae: 188.7183 - val_loss: 42254.2656 - val_mae: 186.6203\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43366.1133 - mae: 188.7113 - val_loss: 42251.5938 - val_mae: 186.6136\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43363.3711 - mae: 188.7044 - val_loss: 42248.9062 - val_mae: 186.6068\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43360.5977 - mae: 188.6973 - val_loss: 42246.2461 - val_mae: 186.6002\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43357.8828 - mae: 188.6904 - val_loss: 42243.5547 - val_mae: 186.5934\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43355.1250 - mae: 188.6835 - val_loss: 42240.8828 - val_mae: 186.5867\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43352.3867 - mae: 188.6765 - val_loss: 42238.2031 - val_mae: 186.5800\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 43349.6328 - mae: 188.6696 - val_loss: 42235.5508 - val_mae: 186.5734\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 43346.8906 - mae: 188.6626 - val_loss: 42232.8828 - val_mae: 186.5667\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 43344.1602 - mae: 188.6557 - val_loss: 42230.1992 - val_mae: 186.5600\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 43341.3828 - mae: 188.6487 - val_loss: 42227.5273 - val_mae: 186.5533\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 43338.6367 - mae: 188.6417 - val_loss: 42224.8477 - val_mae: 186.5466\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 43335.8984 - mae: 188.6347 - val_loss: 42222.1484 - val_mae: 186.5398\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 43333.1484 - mae: 188.6277 - val_loss: 42219.4648 - val_mae: 186.5331\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 43330.3906 - mae: 188.6208 - val_loss: 42216.8047 - val_mae: 186.5264\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 43327.6484 - mae: 188.6138 - val_loss: 42214.1523 - val_mae: 186.5198\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 43324.9102 - mae: 188.6069 - val_loss: 42211.4805 - val_mae: 186.5131\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 43322.1680 - mae: 188.5999 - val_loss: 42208.7852 - val_mae: 186.5063\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 43319.4336 - mae: 188.5929 - val_loss: 42206.1016 - val_mae: 186.4996\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43316.6641 - mae: 188.5859 - val_loss: 42203.4414 - val_mae: 186.4929\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 43313.9297 - mae: 188.5790 - val_loss: 42200.7695 - val_mae: 186.4862\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43311.1914 - mae: 188.5721 - val_loss: 42198.1016 - val_mae: 186.4795\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43308.4375 - mae: 188.5651 - val_loss: 42195.4297 - val_mae: 186.4728\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43305.6953 - mae: 188.5581 - val_loss: 42192.7656 - val_mae: 186.4661\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 43302.9883 - mae: 188.5512 - val_loss: 42190.0664 - val_mae: 186.4594\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 43300.1875 - mae: 188.5441 - val_loss: 42187.4062 - val_mae: 186.4527\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43297.4570 - mae: 188.5372 - val_loss: 42184.7344 - val_mae: 186.4460\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43294.7266 - mae: 188.5303 - val_loss: 42182.0469 - val_mae: 186.4392\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43291.9805 - mae: 188.5233 - val_loss: 42179.3477 - val_mae: 186.4325\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43289.1992 - mae: 188.5163 - val_loss: 42176.6992 - val_mae: 186.4258\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43286.4727 - mae: 188.5093 - val_loss: 42174.0469 - val_mae: 186.4192\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 43283.7383 - mae: 188.5024 - val_loss: 42171.3789 - val_mae: 186.4125\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43281.0117 - mae: 188.4955 - val_loss: 42168.6758 - val_mae: 186.4057\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43278.2266 - mae: 188.4884 - val_loss: 42166.0078 - val_mae: 186.3990\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43275.5039 - mae: 188.4815 - val_loss: 42163.3203 - val_mae: 186.3923\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43272.7383 - mae: 188.4745 - val_loss: 42160.6484 - val_mae: 186.3856\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43269.9961 - mae: 188.4675 - val_loss: 42157.9805 - val_mae: 186.3789\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43267.2383 - mae: 188.4605 - val_loss: 42155.3242 - val_mae: 186.3722\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43264.5000 - mae: 188.4536 - val_loss: 42152.6680 - val_mae: 186.3656\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43261.7891 - mae: 188.4467 - val_loss: 42149.9766 - val_mae: 186.3588\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43259.0117 - mae: 188.4397 - val_loss: 42147.3086 - val_mae: 186.3521\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43256.2930 - mae: 188.4327 - val_loss: 42144.6445 - val_mae: 186.3454\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43253.5586 - mae: 188.4258 - val_loss: 42141.9570 - val_mae: 186.3387\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43250.7891 - mae: 188.4187 - val_loss: 42139.3047 - val_mae: 186.3320\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 43248.0703 - mae: 188.4118 - val_loss: 42136.6406 - val_mae: 186.3254\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43245.3320 - mae: 188.4049 - val_loss: 42133.9727 - val_mae: 186.3187\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43242.5898 - mae: 188.3979 - val_loss: 42131.3164 - val_mae: 186.3120\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43239.8594 - mae: 188.3910 - val_loss: 42128.6406 - val_mae: 186.3053\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43237.1172 - mae: 188.3840 - val_loss: 42125.9727 - val_mae: 186.2986\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 43234.3672 - mae: 188.3770 - val_loss: 42123.3008 - val_mae: 186.2919\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43231.6484 - mae: 188.3701 - val_loss: 42120.6211 - val_mae: 186.2852\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43228.8711 - mae: 188.3631 - val_loss: 42117.9531 - val_mae: 186.2785\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43226.1406 - mae: 188.3562 - val_loss: 42115.2773 - val_mae: 186.2717\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43223.3867 - mae: 188.3492 - val_loss: 42112.6094 - val_mae: 186.2651\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 43220.6367 - mae: 188.3422 - val_loss: 42109.9336 - val_mae: 186.2584\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43217.9180 - mae: 188.3353 - val_loss: 42107.2305 - val_mae: 186.2516\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43215.1406 - mae: 188.3282 - val_loss: 42104.5781 - val_mae: 186.2449\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43212.4102 - mae: 188.3213 - val_loss: 42101.9180 - val_mae: 186.2382\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 43209.6641 - mae: 188.3143 - val_loss: 42099.2422 - val_mae: 186.2315\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43206.9141 - mae: 188.3073 - val_loss: 42096.5664 - val_mae: 186.2248\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43204.1680 - mae: 188.3004 - val_loss: 42093.8906 - val_mae: 186.2181\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 43201.4258 - mae: 188.2934 - val_loss: 42091.2031 - val_mae: 186.2113\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43198.6836 - mae: 188.2865 - val_loss: 42088.5078 - val_mae: 186.2046\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 43195.9141 - mae: 188.2794 - val_loss: 42085.8438 - val_mae: 186.1979\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 43193.2031 - mae: 188.2726 - val_loss: 42083.1680 - val_mae: 186.1912\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43190.4336 - mae: 188.2655 - val_loss: 42080.5039 - val_mae: 186.1845\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 43187.6875 - mae: 188.2585 - val_loss: 42077.8477 - val_mae: 186.1778\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43184.9570 - mae: 188.2516 - val_loss: 42075.1602 - val_mae: 186.1711\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43182.2109 - mae: 188.2446 - val_loss: 42072.4961 - val_mae: 186.1644\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43179.4531 - mae: 188.2376 - val_loss: 42069.8320 - val_mae: 186.1577\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43176.7422 - mae: 188.2307 - val_loss: 42067.1445 - val_mae: 186.1510\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43173.9766 - mae: 188.2237 - val_loss: 42064.4766 - val_mae: 186.1442\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 43171.2227 - mae: 188.2167 - val_loss: 42061.8242 - val_mae: 186.1376\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43168.5039 - mae: 188.2098 - val_loss: 42059.1445 - val_mae: 186.1308\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43165.7461 - mae: 188.2028 - val_loss: 42056.4570 - val_mae: 186.1241\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 43163.0039 - mae: 188.1958 - val_loss: 42053.7812 - val_mae: 186.1174\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 43160.2539 - mae: 188.1889 - val_loss: 42051.1055 - val_mae: 186.1107\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 43157.5039 - mae: 188.1819 - val_loss: 42048.4414 - val_mae: 186.1040\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 43154.7773 - mae: 188.1750 - val_loss: 42045.7500 - val_mae: 186.0972\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 43152.0234 - mae: 188.1680 - val_loss: 42043.1016 - val_mae: 186.0906\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43149.2969 - mae: 188.1610 - val_loss: 42040.4414 - val_mae: 186.0839\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 43146.5586 - mae: 188.1541 - val_loss: 42037.7852 - val_mae: 186.0772\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 43143.8281 - mae: 188.1471 - val_loss: 42035.1250 - val_mae: 186.0705\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 43141.1016 - mae: 188.1402 - val_loss: 42032.4492 - val_mae: 186.0638\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 43138.3672 - mae: 188.1332 - val_loss: 42029.7734 - val_mae: 186.0571\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 43135.6250 - mae: 188.1263 - val_loss: 42027.1250 - val_mae: 186.0504\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 43132.9062 - mae: 188.1193 - val_loss: 42024.4492 - val_mae: 186.0437\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 43130.1367 - mae: 188.1123 - val_loss: 42021.8086 - val_mae: 186.0371\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 43127.4102 - mae: 188.1054 - val_loss: 42019.1445 - val_mae: 186.0304\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 43124.6836 - mae: 188.0984 - val_loss: 42016.4688 - val_mae: 186.0237\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 43121.9531 - mae: 188.0915 - val_loss: 42013.7969 - val_mae: 186.0169\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 43119.1992 - mae: 188.0845 - val_loss: 42011.1445 - val_mae: 186.0103\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 43116.4766 - mae: 188.0776 - val_loss: 42008.4648 - val_mae: 186.0035\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 43113.7344 - mae: 188.0706 - val_loss: 42005.7852 - val_mae: 185.9968\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 43110.9805 - mae: 188.0636 - val_loss: 42003.1211 - val_mae: 185.9901\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 43108.2461 - mae: 188.0567 - val_loss: 42000.4531 - val_mae: 185.9834\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.1, model__n_hidden=1, model__n_neurons=5, model__optimizer=adam; total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 774, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 89, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 331, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 675]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmpz7vqb1ik\\assets\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 15ms/step - loss: 25002.0723 - mae: 128.8776 - val_loss: 26071.1758 - val_mae: 131.7783\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 25000.3379 - mae: 128.8727 - val_loss: 26069.3770 - val_mae: 131.7733\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24998.6191 - mae: 128.8679 - val_loss: 26067.5723 - val_mae: 131.7683\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24996.8965 - mae: 128.8630 - val_loss: 26065.7734 - val_mae: 131.7633\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24995.1641 - mae: 128.8580 - val_loss: 26063.9844 - val_mae: 131.7584\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24993.4355 - mae: 128.8531 - val_loss: 26062.1973 - val_mae: 131.7534\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24991.7207 - mae: 128.8483 - val_loss: 26060.4082 - val_mae: 131.7485\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24990.0078 - mae: 128.8434 - val_loss: 26058.6074 - val_mae: 131.7435\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24988.2695 - mae: 128.8386 - val_loss: 26056.8223 - val_mae: 131.7386\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24986.5645 - mae: 128.8338 - val_loss: 26055.0215 - val_mae: 131.7336\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24984.8340 - mae: 128.8288 - val_loss: 26053.2266 - val_mae: 131.7287\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24983.1133 - mae: 128.8240 - val_loss: 26051.4512 - val_mae: 131.7237\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24981.4023 - mae: 128.8191 - val_loss: 26049.6621 - val_mae: 131.7188\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24979.7070 - mae: 128.8143 - val_loss: 26047.8535 - val_mae: 131.7138\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24977.9727 - mae: 128.8094 - val_loss: 26046.0703 - val_mae: 131.7089\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24976.2402 - mae: 128.8046 - val_loss: 26044.2949 - val_mae: 131.7040\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24974.5449 - mae: 128.7997 - val_loss: 26042.5000 - val_mae: 131.6990\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24972.8320 - mae: 128.7948 - val_loss: 26040.7012 - val_mae: 131.6940\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24971.1016 - mae: 128.7900 - val_loss: 26038.9258 - val_mae: 131.6891\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24969.3789 - mae: 128.7851 - val_loss: 26037.1465 - val_mae: 131.6842\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24967.6738 - mae: 128.7802 - val_loss: 26035.3418 - val_mae: 131.6792\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24965.9453 - mae: 128.7754 - val_loss: 26033.5352 - val_mae: 131.6742\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24964.2070 - mae: 128.7705 - val_loss: 26031.7402 - val_mae: 131.6692\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24962.4883 - mae: 128.7656 - val_loss: 26029.9512 - val_mae: 131.6642\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24960.7793 - mae: 128.7608 - val_loss: 26028.1582 - val_mae: 131.6593\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24959.0586 - mae: 128.7559 - val_loss: 26026.3711 - val_mae: 131.6543\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24957.3301 - mae: 128.7510 - val_loss: 26024.5918 - val_mae: 131.6494\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24955.6387 - mae: 128.7462 - val_loss: 26022.7871 - val_mae: 131.6444\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24953.9062 - mae: 128.7414 - val_loss: 26020.9922 - val_mae: 131.6394\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24952.1953 - mae: 128.7365 - val_loss: 26019.2012 - val_mae: 131.6345\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24950.4668 - mae: 128.7316 - val_loss: 26017.4336 - val_mae: 131.6296\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24948.7617 - mae: 128.7268 - val_loss: 26015.6465 - val_mae: 131.6246\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24947.0508 - mae: 128.7219 - val_loss: 26013.8672 - val_mae: 131.6196\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24945.3301 - mae: 128.7171 - val_loss: 26012.0957 - val_mae: 131.6147\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24943.6426 - mae: 128.7122 - val_loss: 26010.3008 - val_mae: 131.6098\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24941.9062 - mae: 128.7074 - val_loss: 26008.5352 - val_mae: 131.6049\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24940.2148 - mae: 128.7026 - val_loss: 26006.7383 - val_mae: 131.5999\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24938.4922 - mae: 128.6977 - val_loss: 26004.9473 - val_mae: 131.5949\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24936.7910 - mae: 128.6929 - val_loss: 26003.1582 - val_mae: 131.5900\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24935.0625 - mae: 128.6880 - val_loss: 26001.3750 - val_mae: 131.5850\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24933.3340 - mae: 128.6831 - val_loss: 25999.6035 - val_mae: 131.5801\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24931.6426 - mae: 128.6783 - val_loss: 25997.8281 - val_mae: 131.5752\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 24929.9297 - mae: 128.6734 - val_loss: 25996.0410 - val_mae: 131.5703\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24928.2305 - mae: 128.6686 - val_loss: 25994.2363 - val_mae: 131.5654\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 24926.4785 - mae: 128.6637 - val_loss: 25992.4629 - val_mae: 131.5605\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 24924.7891 - mae: 128.6589 - val_loss: 25990.6758 - val_mae: 131.5556\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 24923.0684 - mae: 128.6540 - val_loss: 25988.8926 - val_mae: 131.5508\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 24921.3594 - mae: 128.6492 - val_loss: 25987.1035 - val_mae: 131.5459\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 24919.6523 - mae: 128.6443 - val_loss: 25985.3223 - val_mae: 131.5410\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24917.9297 - mae: 128.6395 - val_loss: 25983.5352 - val_mae: 131.5362\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 24916.2109 - mae: 128.6346 - val_loss: 25981.7500 - val_mae: 131.5313\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 24914.4922 - mae: 128.6298 - val_loss: 25979.9414 - val_mae: 131.5264\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 24912.7637 - mae: 128.6248 - val_loss: 25978.1543 - val_mae: 131.5216\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24911.0371 - mae: 128.6200 - val_loss: 25976.3711 - val_mae: 131.5167\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 24909.3301 - mae: 128.6152 - val_loss: 25974.5742 - val_mae: 131.5118\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 24907.6191 - mae: 128.6104 - val_loss: 25972.7734 - val_mae: 131.5070\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 24905.8965 - mae: 128.6055 - val_loss: 25970.9980 - val_mae: 131.5021\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24904.1992 - mae: 128.6007 - val_loss: 25969.2109 - val_mae: 131.4973\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24902.4746 - mae: 128.5958 - val_loss: 25967.4297 - val_mae: 131.4924\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24900.7695 - mae: 128.5910 - val_loss: 25965.6426 - val_mae: 131.4875\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24899.0430 - mae: 128.5861 - val_loss: 25963.8730 - val_mae: 131.4827\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24897.3477 - mae: 128.5812 - val_loss: 25962.0977 - val_mae: 131.4778\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24895.6328 - mae: 128.5764 - val_loss: 25960.3145 - val_mae: 131.4730\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24893.9160 - mae: 128.5715 - val_loss: 25958.5371 - val_mae: 131.4681\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24892.2070 - mae: 128.5667 - val_loss: 25956.7324 - val_mae: 131.4632\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24890.4980 - mae: 128.5618 - val_loss: 25954.9355 - val_mae: 131.4583\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24888.7617 - mae: 128.5570 - val_loss: 25953.1641 - val_mae: 131.4535\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24887.0762 - mae: 128.5522 - val_loss: 25951.3633 - val_mae: 131.4486\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24885.3477 - mae: 128.5473 - val_loss: 25949.5840 - val_mae: 131.4437\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24883.6387 - mae: 128.5425 - val_loss: 25947.8086 - val_mae: 131.4389\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24881.9355 - mae: 128.5376 - val_loss: 25946.0293 - val_mae: 131.4340\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 24880.2266 - mae: 128.5328 - val_loss: 25944.2480 - val_mae: 131.4292\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24878.5078 - mae: 128.5280 - val_loss: 25942.4824 - val_mae: 131.4243\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24876.7949 - mae: 128.5231 - val_loss: 25940.7129 - val_mae: 131.4195\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24875.1016 - mae: 128.5183 - val_loss: 25938.9160 - val_mae: 131.4146\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24873.3828 - mae: 128.5134 - val_loss: 25937.1289 - val_mae: 131.4097\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24871.6855 - mae: 128.5086 - val_loss: 25935.3457 - val_mae: 131.4048\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 24869.9492 - mae: 128.5037 - val_loss: 25933.5762 - val_mae: 131.4000\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24868.2598 - mae: 128.4989 - val_loss: 25931.7715 - val_mae: 131.3951\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24866.5391 - mae: 128.4940 - val_loss: 25929.9824 - val_mae: 131.3902\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 24864.8223 - mae: 128.4892 - val_loss: 25928.2012 - val_mae: 131.3854\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24863.1133 - mae: 128.4843 - val_loss: 25926.4277 - val_mae: 131.3805\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 24861.4023 - mae: 128.4795 - val_loss: 25924.6484 - val_mae: 131.3757\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 24859.6875 - mae: 128.4747 - val_loss: 25922.8828 - val_mae: 131.3708\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24858.0000 - mae: 128.4699 - val_loss: 25921.1016 - val_mae: 131.3660\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24856.2988 - mae: 128.4650 - val_loss: 25919.3105 - val_mae: 131.3611\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24854.5781 - mae: 128.4602 - val_loss: 25917.5332 - val_mae: 131.3562\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24852.8672 - mae: 128.4553 - val_loss: 25915.7598 - val_mae: 131.3514\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24851.1660 - mae: 128.4505 - val_loss: 25913.9766 - val_mae: 131.3465\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24849.4551 - mae: 128.4457 - val_loss: 25912.1992 - val_mae: 131.3417\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24847.7637 - mae: 128.4408 - val_loss: 25910.3984 - val_mae: 131.3367\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24846.0098 - mae: 128.4359 - val_loss: 25908.6426 - val_mae: 131.3319\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24844.3281 - mae: 128.4311 - val_loss: 25906.8613 - val_mae: 131.3271\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24842.6230 - mae: 128.4263 - val_loss: 25905.0840 - val_mae: 131.3222\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24840.9004 - mae: 128.4214 - val_loss: 25903.3125 - val_mae: 131.3174\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24839.2090 - mae: 128.4165 - val_loss: 25901.5332 - val_mae: 131.3125\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 24837.4883 - mae: 128.4117 - val_loss: 25899.7715 - val_mae: 131.3077\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24835.8047 - mae: 128.4070 - val_loss: 25897.9707 - val_mae: 131.3028\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24834.0684 - mae: 128.4020 - val_loss: 25896.1895 - val_mae: 131.2979\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 24832.3730 - mae: 128.3972 - val_loss: 25894.4043 - val_mae: 131.2930\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.1, model__n_hidden=1, model__n_neurons=5, model__optimizer=adam; total time=   3.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 774, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 89, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 331, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 675]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmpcubqdaz2\\assets\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 16ms/step - loss: 27217.1699 - mae: 143.6412 - val_loss: 28530.0332 - val_mae: 148.7076\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 27215.0781 - mae: 143.6355 - val_loss: 28527.8027 - val_mae: 148.7013\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 27213.0352 - mae: 143.6298 - val_loss: 28525.5547 - val_mae: 148.6948\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 27210.9512 - mae: 143.6241 - val_loss: 28523.3301 - val_mae: 148.6885\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 27208.8906 - mae: 143.6184 - val_loss: 28521.0918 - val_mae: 148.6821\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 27206.8066 - mae: 143.6126 - val_loss: 28518.8633 - val_mae: 148.6757\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 27204.7402 - mae: 143.6069 - val_loss: 28516.6348 - val_mae: 148.6694\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 27202.6719 - mae: 143.6012 - val_loss: 28514.4102 - val_mae: 148.6630\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 27200.6055 - mae: 143.5955 - val_loss: 28512.1738 - val_mae: 148.6566\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 27198.5371 - mae: 143.5898 - val_loss: 28509.9453 - val_mae: 148.6503\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 27196.4727 - mae: 143.5841 - val_loss: 28507.7031 - val_mae: 148.6439\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 27194.3965 - mae: 143.5784 - val_loss: 28505.4766 - val_mae: 148.6376\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 27192.3535 - mae: 143.5727 - val_loss: 28503.2363 - val_mae: 148.6312\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 27190.2656 - mae: 143.5669 - val_loss: 28501.0039 - val_mae: 148.6248\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 27188.1973 - mae: 143.5612 - val_loss: 28498.7656 - val_mae: 148.6184\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 27186.1211 - mae: 143.5555 - val_loss: 28496.5547 - val_mae: 148.6121\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 27184.0488 - mae: 143.5498 - val_loss: 28494.3379 - val_mae: 148.6059\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 27182.0078 - mae: 143.5441 - val_loss: 28492.0898 - val_mae: 148.5996\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 27179.9395 - mae: 143.5384 - val_loss: 28489.8379 - val_mae: 148.5932\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 27177.8457 - mae: 143.5326 - val_loss: 28487.6152 - val_mae: 148.5870\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 27175.7949 - mae: 143.5269 - val_loss: 28485.3750 - val_mae: 148.5807\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 27173.7168 - mae: 143.5212 - val_loss: 28483.1504 - val_mae: 148.5744\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 27171.6484 - mae: 143.5155 - val_loss: 28480.9375 - val_mae: 148.5682\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 27169.6055 - mae: 143.5098 - val_loss: 28478.6992 - val_mae: 148.5619\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 27167.5234 - mae: 143.5041 - val_loss: 28476.4844 - val_mae: 148.5557\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 27165.4570 - mae: 143.4984 - val_loss: 28474.2715 - val_mae: 148.5494\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 27163.4023 - mae: 143.4928 - val_loss: 28472.0488 - val_mae: 148.5432\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 27161.3711 - mae: 143.4871 - val_loss: 28469.8047 - val_mae: 148.5368\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 27159.2754 - mae: 143.4814 - val_loss: 28467.5879 - val_mae: 148.5306\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 27157.2012 - mae: 143.4757 - val_loss: 28465.3730 - val_mae: 148.5244\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 27155.1680 - mae: 143.4701 - val_loss: 28463.1328 - val_mae: 148.5181\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 27153.1016 - mae: 143.4644 - val_loss: 28460.8965 - val_mae: 148.5118\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 27151.0293 - mae: 143.4586 - val_loss: 28458.6738 - val_mae: 148.5055\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 27148.9570 - mae: 143.4529 - val_loss: 28456.4551 - val_mae: 148.4993\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 27146.9082 - mae: 143.4473 - val_loss: 28454.2402 - val_mae: 148.4930\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 27144.8438 - mae: 143.4417 - val_loss: 28452.0137 - val_mae: 148.4868\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 27142.7656 - mae: 143.4359 - val_loss: 28449.8047 - val_mae: 148.4806\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 27140.7227 - mae: 143.4303 - val_loss: 28447.5586 - val_mae: 148.4742\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 27138.6660 - mae: 143.4246 - val_loss: 28445.3047 - val_mae: 148.4679\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 27136.5820 - mae: 143.4189 - val_loss: 28443.0801 - val_mae: 148.4616\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 27134.5059 - mae: 143.4132 - val_loss: 28440.8750 - val_mae: 148.4554\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 27132.4434 - mae: 143.4075 - val_loss: 28438.6602 - val_mae: 148.4492\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 27130.3984 - mae: 143.4018 - val_loss: 28436.4336 - val_mae: 148.4429\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 27128.3242 - mae: 143.3961 - val_loss: 28434.2129 - val_mae: 148.4367\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 27126.2695 - mae: 143.3905 - val_loss: 28431.9746 - val_mae: 148.4304\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 27124.1895 - mae: 143.3847 - val_loss: 28429.7539 - val_mae: 148.4241\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 27122.1367 - mae: 143.3791 - val_loss: 28427.5234 - val_mae: 148.4178\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 27120.0762 - mae: 143.3734 - val_loss: 28425.2910 - val_mae: 148.4115\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 27118.0312 - mae: 143.3677 - val_loss: 28423.0410 - val_mae: 148.4052\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 27115.9258 - mae: 143.3620 - val_loss: 28420.8301 - val_mae: 148.3990\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 27113.8789 - mae: 143.3563 - val_loss: 28418.6035 - val_mae: 148.3927\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 27111.8008 - mae: 143.3506 - val_loss: 28416.3828 - val_mae: 148.3864\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 27109.7637 - mae: 143.3450 - val_loss: 28414.1289 - val_mae: 148.3801\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 27107.6855 - mae: 143.3392 - val_loss: 28411.9238 - val_mae: 148.3739\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 27105.6191 - mae: 143.3335 - val_loss: 28409.7207 - val_mae: 148.3677\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 27103.5820 - mae: 143.3279 - val_loss: 28407.5039 - val_mae: 148.3615\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 27101.5215 - mae: 143.3222 - val_loss: 28405.2676 - val_mae: 148.3552\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 27099.4512 - mae: 143.3166 - val_loss: 28403.0449 - val_mae: 148.3489\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 27097.3770 - mae: 143.3108 - val_loss: 28400.8242 - val_mae: 148.3427\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 27095.3242 - mae: 143.3052 - val_loss: 28398.5957 - val_mae: 148.3364\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 27093.2754 - mae: 143.2995 - val_loss: 28396.3613 - val_mae: 148.3301\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 27091.2012 - mae: 143.2938 - val_loss: 28394.1406 - val_mae: 148.3238\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 27089.1328 - mae: 143.2881 - val_loss: 28391.9355 - val_mae: 148.3176\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 27087.1016 - mae: 143.2825 - val_loss: 28389.6895 - val_mae: 148.3113\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 27084.9980 - mae: 143.2768 - val_loss: 28387.4922 - val_mae: 148.3051\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 27082.9688 - mae: 143.2712 - val_loss: 28385.2676 - val_mae: 148.2988\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 27080.9121 - mae: 143.2655 - val_loss: 28383.0410 - val_mae: 148.2926\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 27078.8457 - mae: 143.2598 - val_loss: 28380.8223 - val_mae: 148.2863\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 27076.7812 - mae: 143.2541 - val_loss: 28378.5918 - val_mae: 148.2801\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 27074.7207 - mae: 143.2484 - val_loss: 28376.3672 - val_mae: 148.2738\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 27072.6680 - mae: 143.2428 - val_loss: 28374.1387 - val_mae: 148.2676\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 27070.5918 - mae: 143.2371 - val_loss: 28371.9277 - val_mae: 148.2614\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 27068.5547 - mae: 143.2314 - val_loss: 28369.7051 - val_mae: 148.2553\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 27066.4844 - mae: 143.2258 - val_loss: 28367.4961 - val_mae: 148.2491\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 27064.4336 - mae: 143.2202 - val_loss: 28365.2734 - val_mae: 148.2430\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 27062.3789 - mae: 143.2145 - val_loss: 28363.0391 - val_mae: 148.2367\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 27060.3027 - mae: 143.2088 - val_loss: 28360.8242 - val_mae: 148.2306\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 27058.2461 - mae: 143.2032 - val_loss: 28358.6074 - val_mae: 148.2244\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 27056.2012 - mae: 143.1976 - val_loss: 28356.3906 - val_mae: 148.2182\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 27054.1504 - mae: 143.1919 - val_loss: 28354.1641 - val_mae: 148.2120\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 27052.0938 - mae: 143.1862 - val_loss: 28351.9375 - val_mae: 148.2058\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 27050.0254 - mae: 143.1806 - val_loss: 28349.7090 - val_mae: 148.1996\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 27047.9570 - mae: 143.1749 - val_loss: 28347.5039 - val_mae: 148.1935\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 27045.8984 - mae: 143.1693 - val_loss: 28345.2988 - val_mae: 148.1874\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 27043.8359 - mae: 143.1637 - val_loss: 28343.0879 - val_mae: 148.1812\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 27041.7852 - mae: 143.1582 - val_loss: 28340.8652 - val_mae: 148.1750\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27039.7520 - mae: 143.1526 - val_loss: 28338.6133 - val_mae: 148.1687\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27037.6621 - mae: 143.1469 - val_loss: 28336.3984 - val_mae: 148.1626\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27035.6035 - mae: 143.1413 - val_loss: 28334.1797 - val_mae: 148.1564\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 27033.5469 - mae: 143.1357 - val_loss: 28331.9668 - val_mae: 148.1503\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 27031.4961 - mae: 143.1301 - val_loss: 28329.7461 - val_mae: 148.1441\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27029.4434 - mae: 143.1245 - val_loss: 28327.5332 - val_mae: 148.1379\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 27027.3945 - mae: 143.1190 - val_loss: 28325.3027 - val_mae: 148.1317\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27025.3125 - mae: 143.1133 - val_loss: 28323.1016 - val_mae: 148.1256\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 27023.2793 - mae: 143.1078 - val_loss: 28320.8652 - val_mae: 148.1194\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 27021.2090 - mae: 143.1022 - val_loss: 28318.6367 - val_mae: 148.1131\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 27019.1523 - mae: 143.0965 - val_loss: 28316.4160 - val_mae: 148.1070\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27017.0820 - mae: 143.0909 - val_loss: 28314.2129 - val_mae: 148.1008\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27015.0449 - mae: 143.0854 - val_loss: 28311.9844 - val_mae: 148.0946\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 27012.9766 - mae: 143.0797 - val_loss: 28309.7832 - val_mae: 148.0885\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.1, model__n_hidden=1, model__n_neurons=5, model__optimizer=adam; total time=   4.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 774, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 89, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 331, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 670]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmpclh8luog\\assets\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 15ms/step - loss: 5865.7676 - mae: 61.1391 - val_loss: 5816.3506 - val_mae: 60.9286\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5848.2266 - mae: 61.0353 - val_loss: 5798.7842 - val_mae: 60.8243\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5830.6060 - mae: 60.9315 - val_loss: 5781.3135 - val_mae: 60.7205\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5813.0825 - mae: 60.8277 - val_loss: 5763.8911 - val_mae: 60.6167\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5795.8120 - mae: 60.7248 - val_loss: 5746.5190 - val_mae: 60.5131\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5778.2671 - mae: 60.6213 - val_loss: 5729.3052 - val_mae: 60.4105\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5761.0806 - mae: 60.5191 - val_loss: 5712.0449 - val_mae: 60.3074\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5743.6704 - mae: 60.4158 - val_loss: 5694.9180 - val_mae: 60.2051\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5726.5825 - mae: 60.3141 - val_loss: 5677.7676 - val_mae: 60.1025\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5709.4165 - mae: 60.2119 - val_loss: 5660.7793 - val_mae: 60.0007\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5692.4824 - mae: 60.1104 - val_loss: 5643.7627 - val_mae: 59.8987\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5675.4395 - mae: 60.0088 - val_loss: 5626.9824 - val_mae: 59.7978\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5658.5220 - mae: 59.9079 - val_loss: 5610.2310 - val_mae: 59.6969\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5641.8374 - mae: 59.8070 - val_loss: 5593.3970 - val_mae: 59.5954\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5624.8193 - mae: 59.7058 - val_loss: 5576.7808 - val_mae: 59.4950\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5608.0986 - mae: 59.6052 - val_loss: 5560.1001 - val_mae: 59.3942\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5591.5049 - mae: 59.5050 - val_loss: 5543.3589 - val_mae: 59.2929\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5574.8862 - mae: 59.4047 - val_loss: 5526.7310 - val_mae: 59.1922\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5558.2251 - mae: 59.3046 - val_loss: 5510.3721 - val_mae: 59.0929\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5541.7388 - mae: 59.2051 - val_loss: 5494.0615 - val_mae: 58.9938\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5525.3252 - mae: 59.1057 - val_loss: 5477.7378 - val_mae: 58.8945\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5509.0176 - mae: 59.0070 - val_loss: 5461.4009 - val_mae: 58.7950\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5492.7861 - mae: 58.9080 - val_loss: 5445.0566 - val_mae: 58.6953\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5476.3643 - mae: 58.8085 - val_loss: 5428.9263 - val_mae: 58.5967\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5460.2329 - mae: 58.7103 - val_loss: 5412.8184 - val_mae: 58.4982\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5444.0708 - mae: 58.6121 - val_loss: 5396.7925 - val_mae: 58.4000\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5427.9541 - mae: 58.5136 - val_loss: 5380.7749 - val_mae: 58.3017\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5411.9233 - mae: 58.4158 - val_loss: 5364.8628 - val_mae: 58.2038\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5396.1533 - mae: 58.3189 - val_loss: 5348.8501 - val_mae: 58.1052\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5379.9263 - mae: 58.2202 - val_loss: 5333.0913 - val_mae: 58.0080\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5364.1416 - mae: 58.1231 - val_loss: 5317.2837 - val_mae: 57.9106\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5348.3569 - mae: 58.0261 - val_loss: 5301.4531 - val_mae: 57.8127\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5332.6592 - mae: 57.9292 - val_loss: 5285.6646 - val_mae: 57.7151\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5316.7324 - mae: 57.8319 - val_loss: 5270.1978 - val_mae: 57.6193\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5301.2026 - mae: 57.7361 - val_loss: 5254.7373 - val_mae: 57.5234\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5285.5835 - mae: 57.6404 - val_loss: 5239.3599 - val_mae: 57.4279\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5270.2476 - mae: 57.5448 - val_loss: 5223.6558 - val_mae: 57.3303\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5254.4883 - mae: 57.4479 - val_loss: 5208.1943 - val_mae: 57.2342\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5239.1519 - mae: 57.3524 - val_loss: 5192.7056 - val_mae: 57.1377\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5223.6182 - mae: 57.2566 - val_loss: 5177.4165 - val_mae: 57.0424\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5208.2642 - mae: 57.1612 - val_loss: 5162.1816 - val_mae: 56.9473\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5192.9180 - mae: 57.0663 - val_loss: 5147.0669 - val_mae: 56.8528\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5177.6826 - mae: 56.9717 - val_loss: 5131.9775 - val_mae: 56.7584\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5162.6885 - mae: 56.8778 - val_loss: 5116.7207 - val_mae: 56.6629\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5147.3291 - mae: 56.7827 - val_loss: 5101.7563 - val_mae: 56.5691\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5132.4111 - mae: 56.6893 - val_loss: 5086.7314 - val_mae: 56.4749\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5117.4258 - mae: 56.5958 - val_loss: 5071.7505 - val_mae: 56.3807\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5102.3325 - mae: 56.5017 - val_loss: 5056.9199 - val_mae: 56.2874\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5087.5000 - mae: 56.4089 - val_loss: 5042.1060 - val_mae: 56.1941\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5072.6533 - mae: 56.3158 - val_loss: 5027.2681 - val_mae: 56.1005\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5057.7856 - mae: 56.2229 - val_loss: 5012.5571 - val_mae: 56.0077\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5043.0566 - mae: 56.1302 - val_loss: 4997.8062 - val_mae: 55.9145\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5028.2930 - mae: 56.0376 - val_loss: 4983.1562 - val_mae: 55.8218\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5013.5684 - mae: 55.9451 - val_loss: 4968.5288 - val_mae: 55.7292\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4999.0356 - mae: 55.8531 - val_loss: 4953.8325 - val_mae: 55.6361\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4984.2124 - mae: 55.7605 - val_loss: 4939.3657 - val_mae: 55.5442\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4969.7666 - mae: 55.6690 - val_loss: 4924.8525 - val_mae: 55.4519\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4955.2476 - mae: 55.5769 - val_loss: 4910.3438 - val_mae: 55.3595\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4940.6401 - mae: 55.4852 - val_loss: 4896.0312 - val_mae: 55.2681\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4926.4717 - mae: 55.3944 - val_loss: 4881.5522 - val_mae: 55.1756\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4911.8960 - mae: 55.3024 - val_loss: 4867.2969 - val_mae: 55.0843\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4897.5947 - mae: 55.2117 - val_loss: 4853.0938 - val_mae: 54.9932\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4883.3418 - mae: 55.1209 - val_loss: 4838.8809 - val_mae: 54.9020\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4869.0908 - mae: 55.0302 - val_loss: 4824.6865 - val_mae: 54.8109\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4854.8716 - mae: 54.9399 - val_loss: 4810.5542 - val_mae: 54.7201\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4840.7764 - mae: 54.8494 - val_loss: 4796.3462 - val_mae: 54.6286\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4826.6387 - mae: 54.7588 - val_loss: 4782.1992 - val_mae: 54.5375\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4812.4951 - mae: 54.6683 - val_loss: 4768.1777 - val_mae: 54.4471\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4798.5728 - mae: 54.5789 - val_loss: 4754.2285 - val_mae: 54.3569\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4784.5098 - mae: 54.4889 - val_loss: 4740.3838 - val_mae: 54.2673\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4770.5698 - mae: 54.3993 - val_loss: 4726.6445 - val_mae: 54.1783\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4756.8374 - mae: 54.3108 - val_loss: 4712.7197 - val_mae: 54.0880\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4742.9370 - mae: 54.2214 - val_loss: 4699.0376 - val_mae: 53.9990\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4729.1533 - mae: 54.1323 - val_loss: 4685.3149 - val_mae: 53.9097\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4715.5527 - mae: 54.0441 - val_loss: 4671.5479 - val_mae: 53.8200\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4701.7388 - mae: 53.9552 - val_loss: 4657.9443 - val_mae: 53.7311\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4688.0171 - mae: 53.8662 - val_loss: 4644.3765 - val_mae: 53.6424\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4674.4849 - mae: 53.7785 - val_loss: 4630.8145 - val_mae: 53.5536\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4660.9058 - mae: 53.6903 - val_loss: 4617.2583 - val_mae: 53.4648\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4647.3218 - mae: 53.6021 - val_loss: 4603.7935 - val_mae: 53.3765\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4633.8833 - mae: 53.5146 - val_loss: 4590.3394 - val_mae: 53.2882\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4620.3857 - mae: 53.4270 - val_loss: 4576.9150 - val_mae: 53.2001\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 4607.0674 - mae: 53.3400 - val_loss: 4563.5166 - val_mae: 53.1120\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 4593.6670 - mae: 53.2528 - val_loss: 4550.2715 - val_mae: 53.0248\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 4580.4253 - mae: 53.1662 - val_loss: 4537.0796 - val_mae: 52.9378\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 4567.1660 - mae: 53.0796 - val_loss: 4523.9551 - val_mae: 52.8512\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 4553.9595 - mae: 52.9933 - val_loss: 4510.8760 - val_mae: 52.7647\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 4540.9917 - mae: 52.9077 - val_loss: 4497.6753 - val_mae: 52.6775\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 4527.8364 - mae: 52.8210 - val_loss: 4484.5483 - val_mae: 52.5907\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 4514.6777 - mae: 52.7350 - val_loss: 4471.6162 - val_mae: 52.5050\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4501.7754 - mae: 52.6499 - val_loss: 4458.5859 - val_mae: 52.4185\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 4488.6021 - mae: 52.5636 - val_loss: 4445.7524 - val_mae: 52.3333\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 4475.6870 - mae: 52.4787 - val_loss: 4432.8242 - val_mae: 52.2473\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 4462.8159 - mae: 52.3935 - val_loss: 4419.9102 - val_mae: 52.1613\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 4449.9380 - mae: 52.3084 - val_loss: 4407.0498 - val_mae: 52.0756\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 4437.0176 - mae: 52.2230 - val_loss: 4394.2656 - val_mae: 51.9903\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 4424.2974 - mae: 52.1386 - val_loss: 4381.4209 - val_mae: 51.9046\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 4411.4497 - mae: 52.0536 - val_loss: 4368.7070 - val_mae: 51.8197\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 4398.6655 - mae: 51.9687 - val_loss: 4355.9824 - val_mae: 51.7348\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4386.0112 - mae: 51.8847 - val_loss: 4343.3398 - val_mae: 51.6503\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.9, model__n_hidden=3, model__n_neurons=125, model__optimizer=adam; total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 774, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 89, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 331, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 16875]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmptw7lpyu5\\assets\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 17ms/step - loss: 5795.1348 - mae: 58.2132 - val_loss: 5685.4814 - val_mae: 57.5924\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 5778.7944 - mae: 58.1197 - val_loss: 5669.0488 - val_mae: 57.4964\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 5762.6099 - mae: 58.0270 - val_loss: 5652.6240 - val_mae: 57.4003\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 5746.4360 - mae: 57.9341 - val_loss: 5636.2876 - val_mae: 57.3046\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 5730.2236 - mae: 57.8414 - val_loss: 5620.0811 - val_mae: 57.2097\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 5714.1489 - mae: 57.7491 - val_loss: 5603.9551 - val_mae: 57.1151\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 5698.1401 - mae: 57.6572 - val_loss: 5587.8433 - val_mae: 57.0206\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 5682.2158 - mae: 57.5659 - val_loss: 5571.7334 - val_mae: 56.9259\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 5666.2383 - mae: 57.4743 - val_loss: 5555.7466 - val_mae: 56.8320\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 5650.5205 - mae: 57.3835 - val_loss: 5539.7427 - val_mae: 56.7379\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 5634.6714 - mae: 57.2925 - val_loss: 5523.8320 - val_mae: 56.6446\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 5618.9224 - mae: 57.2022 - val_loss: 5508.0552 - val_mae: 56.5518\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 5603.2471 - mae: 57.1121 - val_loss: 5492.2856 - val_mae: 56.4590\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 5587.7817 - mae: 57.0221 - val_loss: 5476.4468 - val_mae: 56.3657\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 5572.1250 - mae: 56.9322 - val_loss: 5460.7700 - val_mae: 56.2733\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 5556.5137 - mae: 56.8423 - val_loss: 5445.2300 - val_mae: 56.1817\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 5541.1929 - mae: 56.7535 - val_loss: 5429.6367 - val_mae: 56.0898\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 5525.8550 - mae: 56.6646 - val_loss: 5414.0542 - val_mae: 55.9981\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 5510.3804 - mae: 56.5755 - val_loss: 5398.6685 - val_mae: 55.9074\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 5495.0308 - mae: 56.4869 - val_loss: 5383.3325 - val_mae: 55.8169\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 5479.8853 - mae: 56.3985 - val_loss: 5367.8843 - val_mae: 55.7257\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 5464.6543 - mae: 56.3104 - val_loss: 5352.4814 - val_mae: 55.6347\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 5449.3970 - mae: 56.2221 - val_loss: 5337.1802 - val_mae: 55.5442\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 5434.2646 - mae: 56.1340 - val_loss: 5321.9746 - val_mae: 55.4541\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 5419.3179 - mae: 56.0470 - val_loss: 5306.7979 - val_mae: 55.3642\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 5404.2734 - mae: 55.9595 - val_loss: 5291.6929 - val_mae: 55.2746\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 5389.2534 - mae: 55.8724 - val_loss: 5276.6948 - val_mae: 55.1855\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 5374.4854 - mae: 55.7859 - val_loss: 5261.6367 - val_mae: 55.0960\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 5359.6528 - mae: 55.6995 - val_loss: 5246.6675 - val_mae: 55.0068\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 5344.9097 - mae: 55.6134 - val_loss: 5231.7461 - val_mae: 54.9179\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 5330.0444 - mae: 55.5268 - val_loss: 5217.0190 - val_mae: 54.8302\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 5315.4678 - mae: 55.4416 - val_loss: 5202.2612 - val_mae: 54.7422\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 5300.9009 - mae: 55.3564 - val_loss: 5187.5503 - val_mae: 54.6544\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 5286.2534 - mae: 55.2709 - val_loss: 5172.9712 - val_mae: 54.5673\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 5271.8608 - mae: 55.1862 - val_loss: 5158.3066 - val_mae: 54.4797\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 5257.2920 - mae: 55.1012 - val_loss: 5143.8135 - val_mae: 54.3931\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 5242.9624 - mae: 55.0168 - val_loss: 5129.1929 - val_mae: 54.3056\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 5228.5107 - mae: 54.9320 - val_loss: 5114.6899 - val_mae: 54.2188\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 5214.2666 - mae: 54.8479 - val_loss: 5100.1851 - val_mae: 54.1320\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 5199.8481 - mae: 54.7636 - val_loss: 5085.8125 - val_mae: 54.0460\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 5185.4971 - mae: 54.6794 - val_loss: 5071.5493 - val_mae: 53.9608\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 5171.3760 - mae: 54.5960 - val_loss: 5057.2378 - val_mae: 53.8752\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 5157.1626 - mae: 54.5124 - val_loss: 5042.9741 - val_mae: 53.7898\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 5143.1348 - mae: 54.4291 - val_loss: 5028.6582 - val_mae: 53.7042\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 5128.8765 - mae: 54.3453 - val_loss: 5014.5635 - val_mae: 53.6200\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5114.9912 - mae: 54.2631 - val_loss: 5000.3838 - val_mae: 53.5351\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 5100.9551 - mae: 54.1802 - val_loss: 4986.2847 - val_mae: 53.4506\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 5086.9902 - mae: 54.0975 - val_loss: 4972.2495 - val_mae: 53.3665\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 5073.1484 - mae: 54.0156 - val_loss: 4958.2505 - val_mae: 53.2826\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 5059.2178 - mae: 53.9331 - val_loss: 4944.3188 - val_mae: 53.1990\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 5045.3589 - mae: 53.8510 - val_loss: 4930.3843 - val_mae: 53.1153\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 5031.5767 - mae: 53.7690 - val_loss: 4916.4258 - val_mae: 53.0313\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 5017.7334 - mae: 53.6867 - val_loss: 4902.5918 - val_mae: 52.9480\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 5003.9849 - mae: 53.6052 - val_loss: 4888.7979 - val_mae: 52.8648\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4990.3716 - mae: 53.5239 - val_loss: 4874.9927 - val_mae: 52.7815\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4976.8159 - mae: 53.4428 - val_loss: 4861.2227 - val_mae: 52.6983\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4963.1714 - mae: 53.3616 - val_loss: 4847.6162 - val_mae: 52.6160\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4949.7300 - mae: 53.2811 - val_loss: 4833.9775 - val_mae: 52.5333\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4936.1333 - mae: 53.2002 - val_loss: 4820.4243 - val_mae: 52.4510\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4922.7793 - mae: 53.1198 - val_loss: 4806.8687 - val_mae: 52.3687\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4909.2715 - mae: 53.0392 - val_loss: 4793.4585 - val_mae: 52.2872\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4896.0020 - mae: 52.9594 - val_loss: 4780.0605 - val_mae: 52.2057\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4882.6499 - mae: 52.8795 - val_loss: 4766.7241 - val_mae: 52.1245\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4869.4097 - mae: 52.8001 - val_loss: 4753.3892 - val_mae: 52.0432\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 4856.2324 - mae: 52.7206 - val_loss: 4739.9941 - val_mae: 51.9614\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 4843.0713 - mae: 52.6411 - val_loss: 4726.6621 - val_mae: 51.8800\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 4829.8086 - mae: 52.5613 - val_loss: 4713.4927 - val_mae: 51.7996\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 4816.8359 - mae: 52.4827 - val_loss: 4700.2300 - val_mae: 51.7184\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 4803.7070 - mae: 52.4034 - val_loss: 4687.0781 - val_mae: 51.6379\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4790.6416 - mae: 52.3249 - val_loss: 4674.0112 - val_mae: 51.5576\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 4777.7285 - mae: 52.2460 - val_loss: 4660.9585 - val_mae: 51.4775\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4764.7480 - mae: 52.1679 - val_loss: 4647.9487 - val_mae: 51.3974\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4751.8154 - mae: 52.0897 - val_loss: 4635.0483 - val_mae: 51.3179\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 4738.9170 - mae: 52.0116 - val_loss: 4622.1709 - val_mae: 51.2385\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4726.2046 - mae: 51.9340 - val_loss: 4609.1748 - val_mae: 51.1585\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 4713.3159 - mae: 51.8560 - val_loss: 4596.2930 - val_mae: 51.0789\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4700.6406 - mae: 51.7783 - val_loss: 4583.4395 - val_mae: 50.9995\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 4687.8296 - mae: 51.7003 - val_loss: 4570.7251 - val_mae: 50.9209\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 4675.2603 - mae: 51.6233 - val_loss: 4557.8667 - val_mae: 50.8413\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 4662.5898 - mae: 51.5457 - val_loss: 4545.0957 - val_mae: 50.7620\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 4649.9224 - mae: 51.4685 - val_loss: 4532.4365 - val_mae: 50.6834\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4637.3311 - mae: 51.3916 - val_loss: 4519.8521 - val_mae: 50.6051\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4624.8511 - mae: 51.3152 - val_loss: 4507.2554 - val_mae: 50.5267\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4612.3335 - mae: 51.2384 - val_loss: 4494.7837 - val_mae: 50.4490\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4599.9863 - mae: 51.1624 - val_loss: 4482.2437 - val_mae: 50.3707\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4587.6411 - mae: 51.0862 - val_loss: 4469.7539 - val_mae: 50.2927\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4575.1704 - mae: 51.0096 - val_loss: 4457.3389 - val_mae: 50.2150\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4562.8359 - mae: 50.9338 - val_loss: 4444.9497 - val_mae: 50.1374\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4550.5498 - mae: 50.8576 - val_loss: 4432.5933 - val_mae: 50.0601\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4538.3008 - mae: 50.7819 - val_loss: 4420.2603 - val_mae: 49.9827\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4526.1763 - mae: 50.7066 - val_loss: 4407.8306 - val_mae: 49.9046\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4513.7192 - mae: 50.6301 - val_loss: 4395.7026 - val_mae: 49.8282\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4501.6528 - mae: 50.5554 - val_loss: 4383.5098 - val_mae: 49.7514\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 4489.6323 - mae: 50.4805 - val_loss: 4371.2891 - val_mae: 49.6744\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 4477.4707 - mae: 50.4050 - val_loss: 4359.1973 - val_mae: 49.5982\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 4465.4780 - mae: 50.3304 - val_loss: 4347.1025 - val_mae: 49.5218\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 4453.3950 - mae: 50.2555 - val_loss: 4335.0923 - val_mae: 49.4459\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 4441.5771 - mae: 50.1812 - val_loss: 4322.9551 - val_mae: 49.3691\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 4429.4844 - mae: 50.1061 - val_loss: 4310.9395 - val_mae: 49.2929\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 4417.6221 - mae: 50.0320 - val_loss: 4298.9380 - val_mae: 49.2168\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.9, model__n_hidden=3, model__n_neurons=125, model__optimizer=adam; total time=   6.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 774, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 89, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 331, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 16875]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmpzzrlk0am\\assets\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 29ms/step - loss: 5302.0195 - mae: 59.4499 - val_loss: 5411.1152 - val_mae: 60.2215\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 5285.6426 - mae: 59.3458 - val_loss: 5394.0962 - val_mae: 60.1139\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 5269.7344 - mae: 59.2430 - val_loss: 5377.0088 - val_mae: 60.0059\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 5253.5869 - mae: 59.1395 - val_loss: 5360.0479 - val_mae: 59.8986\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 5237.6182 - mae: 59.0364 - val_loss: 5343.1333 - val_mae: 59.7914\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5221.5122 - mae: 58.9331 - val_loss: 5326.3745 - val_mae: 59.6850\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 5205.6426 - mae: 58.8311 - val_loss: 5309.6597 - val_mae: 59.5786\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 5189.8740 - mae: 58.7287 - val_loss: 5292.9863 - val_mae: 59.4725\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 5174.0356 - mae: 58.6267 - val_loss: 5276.3994 - val_mae: 59.3667\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 5158.3955 - mae: 58.5251 - val_loss: 5259.8130 - val_mae: 59.2611\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 5142.7129 - mae: 58.4238 - val_loss: 5243.3091 - val_mae: 59.1555\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 5127.1284 - mae: 58.3224 - val_loss: 5226.9121 - val_mae: 59.0505\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 5111.8086 - mae: 58.2221 - val_loss: 5210.4316 - val_mae: 58.9450\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 5096.1670 - mae: 58.1205 - val_loss: 5194.1401 - val_mae: 58.8404\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 5080.7520 - mae: 58.0201 - val_loss: 5177.9312 - val_mae: 58.7362\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 5065.3257 - mae: 57.9201 - val_loss: 5161.8994 - val_mae: 58.6330\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 5050.0298 - mae: 57.8199 - val_loss: 5145.8774 - val_mae: 58.5297\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 5034.9780 - mae: 57.7211 - val_loss: 5129.7246 - val_mae: 58.4255\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 5019.8013 - mae: 57.6217 - val_loss: 5113.6401 - val_mae: 58.3217\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5004.5454 - mae: 57.5219 - val_loss: 5097.7529 - val_mae: 58.2191\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4989.5420 - mae: 57.4236 - val_loss: 5081.8657 - val_mae: 58.1160\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4974.5215 - mae: 57.3248 - val_loss: 5066.0991 - val_mae: 58.0137\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4959.5229 - mae: 57.2268 - val_loss: 5050.4595 - val_mae: 57.9122\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4944.7979 - mae: 57.1293 - val_loss: 5034.7837 - val_mae: 57.8102\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4929.8965 - mae: 57.0314 - val_loss: 5019.2759 - val_mae: 57.7092\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 4915.0869 - mae: 56.9341 - val_loss: 5003.8936 - val_mae: 57.6089\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 4900.5571 - mae: 56.8375 - val_loss: 4988.4165 - val_mae: 57.5081\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 4886.0796 - mae: 56.7414 - val_loss: 4972.8774 - val_mae: 57.4066\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4871.2822 - mae: 56.6441 - val_loss: 4957.6440 - val_mae: 57.3068\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4856.7324 - mae: 56.5479 - val_loss: 4942.4800 - val_mae: 57.2075\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4842.4727 - mae: 56.4529 - val_loss: 4927.1597 - val_mae: 57.1070\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4828.0835 - mae: 56.3572 - val_loss: 4911.9321 - val_mae: 57.0072\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 4813.6353 - mae: 56.2614 - val_loss: 4896.8535 - val_mae: 56.9080\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4799.3037 - mae: 56.1661 - val_loss: 4881.8564 - val_mae: 56.8094\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 4785.1094 - mae: 56.0718 - val_loss: 4866.9023 - val_mae: 56.7110\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 4770.8813 - mae: 55.9773 - val_loss: 4852.0146 - val_mae: 56.6125\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 4756.6416 - mae: 55.8824 - val_loss: 4837.2144 - val_mae: 56.5147\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 4742.6577 - mae: 55.7892 - val_loss: 4822.2959 - val_mae: 56.4160\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 4728.7148 - mae: 55.6956 - val_loss: 4807.3281 - val_mae: 56.3169\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 4714.5449 - mae: 55.6012 - val_loss: 4792.6064 - val_mae: 56.2194\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4700.4995 - mae: 55.5078 - val_loss: 4778.0498 - val_mae: 56.1226\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4686.5947 - mae: 55.4151 - val_loss: 4763.5337 - val_mae: 56.0260\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4672.8955 - mae: 55.3228 - val_loss: 4748.9351 - val_mae: 55.9289\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4659.0244 - mae: 55.2300 - val_loss: 4734.4399 - val_mae: 55.8324\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4645.3403 - mae: 55.1377 - val_loss: 4719.9458 - val_mae: 55.7359\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4631.4912 - mae: 55.0452 - val_loss: 4705.6274 - val_mae: 55.6402\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4617.9756 - mae: 54.9537 - val_loss: 4691.2412 - val_mae: 55.5443\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 4604.3745 - mae: 54.8620 - val_loss: 4676.9014 - val_mae: 55.4487\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4590.9424 - mae: 54.7710 - val_loss: 4662.5312 - val_mae: 55.3525\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4577.1665 - mae: 54.6788 - val_loss: 4648.4570 - val_mae: 55.2580\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 4563.8271 - mae: 54.5884 - val_loss: 4634.3281 - val_mae: 55.1632\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 4550.3389 - mae: 54.4976 - val_loss: 4620.2544 - val_mae: 55.0687\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4537.1558 - mae: 54.4079 - val_loss: 4606.0884 - val_mae: 54.9735\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4523.7656 - mae: 54.3170 - val_loss: 4592.1484 - val_mae: 54.8797\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4510.4453 - mae: 54.2271 - val_loss: 4578.3818 - val_mae: 54.7869\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4497.4043 - mae: 54.1382 - val_loss: 4564.5195 - val_mae: 54.6935\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4484.2383 - mae: 54.0487 - val_loss: 4550.6787 - val_mae: 54.6000\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4471.1182 - mae: 53.9592 - val_loss: 4536.9019 - val_mae: 54.5067\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4458.0195 - mae: 53.8700 - val_loss: 4523.2588 - val_mae: 54.4141\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4445.0806 - mae: 53.7816 - val_loss: 4509.6060 - val_mae: 54.3213\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4432.2622 - mae: 53.6932 - val_loss: 4495.9238 - val_mae: 54.2284\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4419.2090 - mae: 53.6045 - val_loss: 4482.4385 - val_mae: 54.1363\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4406.3447 - mae: 53.5165 - val_loss: 4469.0200 - val_mae: 54.0448\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 4393.7305 - mae: 53.4295 - val_loss: 4455.4355 - val_mae: 53.9525\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 4380.6606 - mae: 53.3406 - val_loss: 4442.1494 - val_mae: 53.8617\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 4368.0747 - mae: 53.2539 - val_loss: 4428.7749 - val_mae: 53.7704\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4355.4106 - mae: 53.1670 - val_loss: 4415.4253 - val_mae: 53.6791\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4342.7471 - mae: 53.0797 - val_loss: 4402.1416 - val_mae: 53.5881\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 4330.0986 - mae: 52.9929 - val_loss: 4388.8784 - val_mae: 53.4971\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4317.5513 - mae: 52.9063 - val_loss: 4375.7090 - val_mae: 53.4066\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4305.1182 - mae: 52.8202 - val_loss: 4362.5420 - val_mae: 53.3161\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4292.5581 - mae: 52.7338 - val_loss: 4349.5415 - val_mae: 53.2265\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4280.2676 - mae: 52.6485 - val_loss: 4336.5024 - val_mae: 53.1367\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4267.7764 - mae: 52.5623 - val_loss: 4323.5723 - val_mae: 53.0477\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4255.5122 - mae: 52.4771 - val_loss: 4310.5693 - val_mae: 52.9582\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 4243.1963 - mae: 52.3918 - val_loss: 4297.6177 - val_mae: 52.8687\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4230.8564 - mae: 52.3062 - val_loss: 4284.8071 - val_mae: 52.7802\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4218.6772 - mae: 52.2217 - val_loss: 4272.0151 - val_mae: 52.6918\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4206.5552 - mae: 52.1371 - val_loss: 4259.2739 - val_mae: 52.6035\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4194.4868 - mae: 52.0530 - val_loss: 4246.4927 - val_mae: 52.5151\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 4182.4189 - mae: 51.9690 - val_loss: 4233.7300 - val_mae: 52.4267\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4170.2456 - mae: 51.8845 - val_loss: 4221.1226 - val_mae: 52.3388\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 4158.2363 - mae: 51.8008 - val_loss: 4208.6191 - val_mae: 52.2517\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4146.3135 - mae: 51.7174 - val_loss: 4196.1699 - val_mae: 52.1648\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4134.3530 - mae: 51.6341 - val_loss: 4183.7832 - val_mae: 52.0780\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4122.5767 - mae: 51.5512 - val_loss: 4171.3257 - val_mae: 51.9907\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4110.8555 - mae: 51.4686 - val_loss: 4158.7729 - val_mae: 51.9027\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4098.9258 - mae: 51.3853 - val_loss: 4146.4102 - val_mae: 51.8160\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4087.1472 - mae: 51.3028 - val_loss: 4134.1221 - val_mae: 51.7297\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4075.4316 - mae: 51.2206 - val_loss: 4121.8599 - val_mae: 51.6435\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4063.8008 - mae: 51.1389 - val_loss: 4109.6050 - val_mae: 51.5575\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4052.1858 - mae: 51.0573 - val_loss: 4097.4224 - val_mae: 51.4718\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4040.6270 - mae: 50.9756 - val_loss: 4085.2744 - val_mae: 51.3862\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4028.9380 - mae: 50.8935 - val_loss: 4073.2830 - val_mae: 51.3014\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4017.6030 - mae: 50.8131 - val_loss: 4061.0872 - val_mae: 51.2157\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4005.9968 - mae: 50.7314 - val_loss: 4049.0347 - val_mae: 51.1306\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3994.6519 - mae: 50.6510 - val_loss: 4037.0208 - val_mae: 51.0461\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3983.0808 - mae: 50.5697 - val_loss: 4025.1753 - val_mae: 50.9622\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3971.8950 - mae: 50.4897 - val_loss: 4013.2424 - val_mae: 50.8777\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3960.4810 - mae: 50.4093 - val_loss: 4001.4854 - val_mae: 50.7941\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.9, model__n_hidden=3, model__n_neurons=125, model__optimizer=adam; total time=   5.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 774, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 89, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 331, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 16750]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmp91rfseo9\\assets\n",
      "Epoch 1/100\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 24492.2461 - mae: 74.6546"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 16ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23399.2207 - mae: 72.8679 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.5, model__n_hidden=0, model__n_neurons=5, model__optimizer=nesterov; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 774, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 89, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 331, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 1755]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmp0zv6ja_b\\assets\n",
      "Epoch 1/100\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 23560.8262 - mae: 73.5918"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 13ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23112.9844 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9844 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.5, model__n_hidden=0, model__n_neurons=5, model__optimizer=nesterov; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 774, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 89, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 331, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 1755]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmpswsisbr8\\assets\n",
      "Epoch 1/100\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 21635.4844 - mae: 71.4221"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 13ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23041.8223 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8223 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.5, model__n_hidden=0, model__n_neurons=5, model__optimizer=nesterov; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 774, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 89, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 331, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 1742]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmph2b1noob\\assets\n",
      "Epoch 1/100\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 24492.2461 - mae: 74.6546"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 19ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23399.2207 - mae: 72.8679 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 889us/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.9, model__n_hidden=0, model__n_neurons=5, model__optimizer=nesterov; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 774, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 89, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 331, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 1755]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmpzdnl93a8\\assets\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 14ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23112.9844 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23112.9844 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.9, model__n_hidden=0, model__n_neurons=5, model__optimizer=nesterov; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 774, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 89, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 331, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 1755]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmphzwh9x62\\assets\n",
      "Epoch 1/100\n",
      "1/8 [==>...........................] - ETA: 1s - loss: 21635.4844 - mae: 71.4221"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 21ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23041.8223 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23041.8223 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.9, model__n_hidden=0, model__n_neurons=5, model__optimizer=nesterov; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 774, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 89, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 331, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 1742]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmpf4g26cuz\\assets\n",
      "Epoch 1/100\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 24492.2461 - mae: 74.6546"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 16ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23399.2207 - mae: 72.8679 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.1, model__n_hidden=0, model__n_neurons=25, model__optimizer=sgd; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 774, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 89, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 331, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 1755]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmpenxa3h05\\assets\n",
      "Epoch 1/100\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 23560.8262 - mae: 73.5918"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 17ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23112.9844 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23112.9844 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.1, model__n_hidden=0, model__n_neurons=25, model__optimizer=sgd; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 774, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 89, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 331, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 1755]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmplxv61onz\\assets\n",
      "Epoch 1/100\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 21635.4844 - mae: 71.4221"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 17ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8223 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23041.8223 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.1, model__n_hidden=0, model__n_neurons=25, model__optimizer=sgd; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 774, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 89, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 331, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 1742]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmpaiftnari\\assets\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 15ms/step - loss: 7090.7769 - mae: 63.9704 - val_loss: 3527.8979 - val_mae: 46.7693\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1701.6682 - mae: 31.7684 - val_loss: 813.6032 - val_mae: 23.5037\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 854.6706 - mae: 23.3445 - val_loss: 560.8578 - val_mae: 18.8869\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 428.9440 - mae: 15.9684 - val_loss: 211.1714 - val_mae: 11.7871\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 231.1501 - mae: 11.9709 - val_loss: 109.4422 - val_mae: 8.5257\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 157.9971 - mae: 9.6024 - val_loss: 72.3416 - val_mae: 6.6303\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 120.0699 - mae: 8.2138 - val_loss: 60.4579 - val_mae: 6.0460\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.3727 - mae: 7.5879 - val_loss: 49.1201 - val_mae: 5.5417\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.5269 - mae: 7.4722 - val_loss: 55.9614 - val_mae: 6.0177\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 98.9954 - mae: 7.4554 - val_loss: 48.5033 - val_mae: 5.4462\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 95.2935 - mae: 7.1590 - val_loss: 46.3753 - val_mae: 5.2376\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.4041 - mae: 7.1658 - val_loss: 37.7334 - val_mae: 4.7318\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 91.3677 - mae: 6.9677 - val_loss: 38.7588 - val_mae: 4.8767\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 88.7224 - mae: 7.0123 - val_loss: 32.5755 - val_mae: 4.4947\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 86.8501 - mae: 6.8147 - val_loss: 34.4550 - val_mae: 4.5493\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 90.8578 - mae: 7.0522 - val_loss: 41.6199 - val_mae: 5.1214\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.1376 - mae: 7.0688 - val_loss: 38.0378 - val_mae: 4.9661\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.5947 - mae: 6.7784 - val_loss: 32.5369 - val_mae: 4.4881\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 84.2053 - mae: 6.6288 - val_loss: 43.2210 - val_mae: 5.0638\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 89.8665 - mae: 6.9548 - val_loss: 43.4917 - val_mae: 5.1395\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 89.6121 - mae: 7.0886 - val_loss: 35.9459 - val_mae: 4.7485\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 87.0236 - mae: 6.8470 - val_loss: 35.1220 - val_mae: 4.5816\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.8535 - mae: 6.6616 - val_loss: 37.5326 - val_mae: 4.7179\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.7588 - mae: 6.6731 - val_loss: 30.1434 - val_mae: 4.2807\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.9030 - mae: 6.6047 - val_loss: 29.1347 - val_mae: 4.3477\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.8391 - mae: 6.4755 - val_loss: 29.9705 - val_mae: 4.2706\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.4640 - mae: 6.4309 - val_loss: 29.9856 - val_mae: 4.2133\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 78.1473 - mae: 6.4220 - val_loss: 27.7299 - val_mae: 4.1279\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.6216 - mae: 6.5570 - val_loss: 35.1312 - val_mae: 4.5160\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 77.5388 - mae: 6.4462 - val_loss: 25.5967 - val_mae: 4.1240\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.7980 - mae: 6.3341 - val_loss: 26.2982 - val_mae: 4.1410\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 76.2496 - mae: 6.1790 - val_loss: 28.7690 - val_mae: 4.1562\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.7805 - mae: 6.4087 - val_loss: 28.8151 - val_mae: 4.1622\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.1531 - mae: 6.4966 - val_loss: 35.1091 - val_mae: 4.5608\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.9183 - mae: 6.6853 - val_loss: 42.6054 - val_mae: 5.0268\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.7560 - mae: 6.9377 - val_loss: 34.3915 - val_mae: 4.5154\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.2038 - mae: 6.6804 - val_loss: 40.5133 - val_mae: 4.8656\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.9783 - mae: 6.4624 - val_loss: 29.4093 - val_mae: 4.2351\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 76.5578 - mae: 6.3321 - val_loss: 28.2832 - val_mae: 4.0579\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 76.8901 - mae: 6.3775 - val_loss: 49.1934 - val_mae: 5.3469\n",
      "Epoch 40: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.9, model__n_hidden=2, model__n_neurons=25, model__optimizer=momentum; total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 774, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 89, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 331, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 3375]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmp027upur9\\assets\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 18ms/step - loss: 5504.1177 - mae: 54.3572 - val_loss: 4171.5215 - val_mae: 51.7503\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1982.7090 - mae: 34.4474 - val_loss: 1343.7677 - val_mae: 30.7361\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 853.1821 - mae: 22.9378 - val_loss: 482.2744 - val_mae: 17.1866\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 402.3867 - mae: 15.5010 - val_loss: 240.2767 - val_mae: 12.4352\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 246.1847 - mae: 12.2427 - val_loss: 107.7284 - val_mae: 8.2459\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 171.5097 - mae: 10.1727 - val_loss: 70.2380 - val_mae: 6.5731\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 134.7499 - mae: 8.9776 - val_loss: 54.2742 - val_mae: 5.9101\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 120.9304 - mae: 8.3971 - val_loss: 52.5666 - val_mae: 5.7366\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 113.1199 - mae: 8.2532 - val_loss: 48.8113 - val_mae: 5.4836\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.6067 - mae: 8.1239 - val_loss: 43.4008 - val_mae: 5.1844\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.9559 - mae: 8.0584 - val_loss: 38.8441 - val_mae: 4.9638\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.4711 - mae: 7.7643 - val_loss: 39.9677 - val_mae: 4.9929\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.2978 - mae: 7.7309 - val_loss: 43.0953 - val_mae: 5.1611\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.1908 - mae: 7.6641 - val_loss: 36.6001 - val_mae: 4.7586\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 98.9160 - mae: 7.5972 - val_loss: 42.0430 - val_mae: 5.0378\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.9697 - mae: 7.5051 - val_loss: 29.7736 - val_mae: 4.4394\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.3146 - mae: 7.3965 - val_loss: 31.4876 - val_mae: 4.5155\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.0687 - mae: 7.3747 - val_loss: 34.1223 - val_mae: 4.5404\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.9760 - mae: 7.3884 - val_loss: 41.3599 - val_mae: 4.9485\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.4509 - mae: 7.4592 - val_loss: 37.3239 - val_mae: 4.6930\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.7032 - mae: 7.4353 - val_loss: 30.2559 - val_mae: 4.5828\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.4597 - mae: 7.3823 - val_loss: 31.4072 - val_mae: 4.3864\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 91.0376 - mae: 7.2427 - val_loss: 34.0208 - val_mae: 4.4844\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 92.3172 - mae: 7.4690 - val_loss: 27.3752 - val_mae: 4.2636\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.7163 - mae: 7.4846 - val_loss: 29.5286 - val_mae: 4.4464\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.6891 - mae: 7.4404 - val_loss: 33.0013 - val_mae: 4.4900\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.6146 - mae: 7.3354 - val_loss: 34.2886 - val_mae: 4.4932\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.7653 - mae: 7.3072 - val_loss: 29.0023 - val_mae: 4.2289\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 89.4066 - mae: 7.1505 - val_loss: 36.1200 - val_mae: 4.6107\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.4164 - mae: 7.2661 - val_loss: 40.6684 - val_mae: 4.7993\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.8649 - mae: 7.2905 - val_loss: 34.1736 - val_mae: 4.4496\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.4200 - mae: 7.0685 - val_loss: 61.8283 - val_mae: 5.8426\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.6364 - mae: 7.5016 - val_loss: 37.4829 - val_mae: 4.6251\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 93.2570 - mae: 7.4197 - val_loss: 47.3383 - val_mae: 5.1662\n",
      "Epoch 34: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.9, model__n_hidden=2, model__n_neurons=25, model__optimizer=momentum; total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 774, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 89, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 331, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 3375]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmpdof63fur\\assets\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 20ms/step - loss: 3848.7134 - mae: 45.2010 - val_loss: 3700.9880 - val_mae: 51.4375\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1834.2275 - mae: 33.5610 - val_loss: 1160.5096 - val_mae: 25.6316\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 754.4294 - mae: 21.4938 - val_loss: 437.8996 - val_mae: 16.6427\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 356.4418 - mae: 14.7500 - val_loss: 224.1321 - val_mae: 11.9020\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 193.2786 - mae: 10.7999 - val_loss: 180.2178 - val_mae: 10.6697\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 138.7241 - mae: 9.0050 - val_loss: 121.8957 - val_mae: 8.3259\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 115.2096 - mae: 8.1218 - val_loss: 114.4528 - val_mae: 8.2926\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.9974 - mae: 7.5987 - val_loss: 82.8539 - val_mae: 6.6133\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.3611 - mae: 7.0817 - val_loss: 82.1381 - val_mae: 6.9016\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.9903 - mae: 6.9865 - val_loss: 74.7260 - val_mae: 6.3528\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.3861 - mae: 6.8044 - val_loss: 76.5258 - val_mae: 6.5693\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 83.6095 - mae: 6.9248 - val_loss: 71.2438 - val_mae: 6.2743\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 84.9817 - mae: 6.9827 - val_loss: 78.3503 - val_mae: 6.7073\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 91.5823 - mae: 7.2028 - val_loss: 78.2947 - val_mae: 6.6319\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 82.3352 - mae: 6.8186 - val_loss: 65.0123 - val_mae: 5.9980\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 78.2564 - mae: 6.7033 - val_loss: 60.1870 - val_mae: 5.7030\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 74.9340 - mae: 6.5977 - val_loss: 69.7435 - val_mae: 6.4049\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 82.9709 - mae: 6.9945 - val_loss: 60.1232 - val_mae: 5.8248\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 77.0854 - mae: 6.5557 - val_loss: 76.5383 - val_mae: 6.5586\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 74.1045 - mae: 6.4612 - val_loss: 66.7362 - val_mae: 5.9889\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 72.9038 - mae: 6.4458 - val_loss: 59.4262 - val_mae: 5.7323\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 70.5735 - mae: 6.3794 - val_loss: 64.3216 - val_mae: 5.9404\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 74.7473 - mae: 6.5063 - val_loss: 70.6494 - val_mae: 6.3564\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 72.9672 - mae: 6.4333 - val_loss: 78.8580 - val_mae: 6.8219\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 73.0410 - mae: 6.4323 - val_loss: 56.7244 - val_mae: 5.5485\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.7642 - mae: 6.1981 - val_loss: 57.4266 - val_mae: 5.5590\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 66.1656 - mae: 6.1447 - val_loss: 52.2340 - val_mae: 5.3363\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.7135 - mae: 6.1532 - val_loss: 51.7652 - val_mae: 5.1991\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.5159 - mae: 6.0041 - val_loss: 50.7275 - val_mae: 5.1497\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 63.0936 - mae: 5.9533 - val_loss: 48.2629 - val_mae: 5.0027\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.7343 - mae: 6.1634 - val_loss: 47.2689 - val_mae: 5.0373\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 62.9655 - mae: 5.9577 - val_loss: 55.3799 - val_mae: 5.4067\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 63.4701 - mae: 5.9171 - val_loss: 47.2841 - val_mae: 4.9144\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.1130 - mae: 5.9283 - val_loss: 46.3978 - val_mae: 4.9183\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 61.2356 - mae: 5.8509 - val_loss: 48.1868 - val_mae: 4.9538\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 61.6934 - mae: 5.8541 - val_loss: 52.5108 - val_mae: 5.2490\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 60.0516 - mae: 5.8350 - val_loss: 48.5947 - val_mae: 5.1964\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 66.4964 - mae: 6.1097 - val_loss: 48.9564 - val_mae: 5.2293\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 70.4351 - mae: 6.2015 - val_loss: 49.7602 - val_mae: 5.1435\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 62.1243 - mae: 5.8956 - val_loss: 53.8805 - val_mae: 5.3811\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 67.3144 - mae: 6.1688 - val_loss: 59.2865 - val_mae: 5.7213\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 63.5103 - mae: 6.0065 - val_loss: 63.8275 - val_mae: 6.0074\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 66.2365 - mae: 6.1776 - val_loss: 49.0912 - val_mae: 5.1545\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 65.7771 - mae: 6.0674 - val_loss: 51.4993 - val_mae: 5.2674\n",
      "Epoch 44: early stopping\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.9, model__n_hidden=2, model__n_neurons=25, model__optimizer=momentum; total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 774, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 89, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 331, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 3350]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmpm8wb4c9u\\assets\n",
      "Epoch 1/100\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 24492.2461 - mae: 74.6546"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 15ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23399.2207 - mae: 72.8679 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.5, model__n_hidden=0, model__n_neurons=5, model__optimizer=momentum; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 774, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 89, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 331, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 1755]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmpl0_qdlfp\\assets\n",
      "Epoch 1/100\n",
      "1/8 [==>...........................] - ETA: 1s - loss: 23560.8262 - mae: 73.5918"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 25ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23112.9844 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23112.9844 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.5, model__n_hidden=0, model__n_neurons=5, model__optimizer=momentum; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 774, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 89, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 331, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 1755]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmpxdw54vt9\\assets\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23041.8223 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 23041.8223 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.5, model__n_hidden=0, model__n_neurons=5, model__optimizer=momentum; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 774, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 89, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 331, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 1742]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmp1wq_r2cn\\assets\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 22ms/step - loss: 37362.3438 - mae: 158.7415 - val_loss: 37072.3633 - val_mae: 158.8884\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 37339.8633 - mae: 158.6836 - val_loss: 37049.6680 - val_mae: 158.8305\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 37317.2148 - mae: 158.6260 - val_loss: 37027.0469 - val_mae: 158.7727\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 37294.6836 - mae: 158.5684 - val_loss: 37004.4297 - val_mae: 158.7156\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 37272.3867 - mae: 158.5109 - val_loss: 36981.7969 - val_mae: 158.6584\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 37249.6445 - mae: 158.4529 - val_loss: 36959.3125 - val_mae: 158.6015\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 37227.3359 - mae: 158.3958 - val_loss: 36936.6836 - val_mae: 158.5443\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 37204.6602 - mae: 158.3376 - val_loss: 36914.1797 - val_mae: 158.4874\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 37182.3086 - mae: 158.2804 - val_loss: 36891.5781 - val_mae: 158.4303\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 37159.7930 - mae: 158.2231 - val_loss: 36869.1367 - val_mae: 158.3736\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 37137.6211 - mae: 158.1661 - val_loss: 36846.5430 - val_mae: 158.3165\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 37115.1094 - mae: 158.1087 - val_loss: 36824.2500 - val_mae: 158.2600\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 37092.7305 - mae: 158.0513 - val_loss: 36801.9414 - val_mae: 158.2033\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 37070.6758 - mae: 157.9947 - val_loss: 36779.4023 - val_mae: 158.1464\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 37047.9922 - mae: 157.9371 - val_loss: 36757.1367 - val_mae: 158.0897\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 37025.6445 - mae: 157.8796 - val_loss: 36734.7188 - val_mae: 158.0336\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 37003.5273 - mae: 157.8228 - val_loss: 36712.0898 - val_mae: 157.9776\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 36981.2070 - mae: 157.7655 - val_loss: 36689.5781 - val_mae: 157.9219\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 36958.7422 - mae: 157.7080 - val_loss: 36667.3906 - val_mae: 157.8666\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36936.5000 - mae: 157.6506 - val_loss: 36645.1992 - val_mae: 157.8113\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36914.2773 - mae: 157.5936 - val_loss: 36622.9141 - val_mae: 157.7559\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36892.1250 - mae: 157.5368 - val_loss: 36600.5586 - val_mae: 157.7003\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36870.0703 - mae: 157.4798 - val_loss: 36578.1055 - val_mae: 157.6444\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36847.6406 - mae: 157.4224 - val_loss: 36555.8828 - val_mae: 157.5890\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36825.5156 - mae: 157.3655 - val_loss: 36533.6758 - val_mae: 157.5338\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 36803.3477 - mae: 157.3087 - val_loss: 36511.4922 - val_mae: 157.4784\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 36781.2031 - mae: 157.2515 - val_loss: 36489.2344 - val_mae: 157.4229\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 36759.0547 - mae: 157.1945 - val_loss: 36467.0898 - val_mae: 157.3677\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36737.2305 - mae: 157.1385 - val_loss: 36444.7344 - val_mae: 157.3119\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36714.6445 - mae: 157.0805 - val_loss: 36422.7031 - val_mae: 157.2568\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36692.7344 - mae: 157.0241 - val_loss: 36400.4922 - val_mae: 157.2014\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36670.6523 - mae: 156.9669 - val_loss: 36378.2188 - val_mae: 157.1457\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36648.7148 - mae: 156.9105 - val_loss: 36355.9180 - val_mae: 157.0901\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36626.3477 - mae: 156.8533 - val_loss: 36334.0352 - val_mae: 157.0352\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 36604.4727 - mae: 156.7969 - val_loss: 36312.1055 - val_mae: 156.9802\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36582.3633 - mae: 156.7402 - val_loss: 36290.2344 - val_mae: 156.9251\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36560.7188 - mae: 156.6844 - val_loss: 36267.7773 - val_mae: 156.8691\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 36538.3242 - mae: 156.6268 - val_loss: 36245.6289 - val_mae: 156.8138\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36516.4570 - mae: 156.5709 - val_loss: 36223.3945 - val_mae: 156.7584\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 36494.2891 - mae: 156.5141 - val_loss: 36201.3789 - val_mae: 156.7031\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 36472.2656 - mae: 156.4576 - val_loss: 36179.4023 - val_mae: 156.6480\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 36450.2422 - mae: 156.4012 - val_loss: 36157.5234 - val_mae: 156.5931\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 36428.2734 - mae: 156.3448 - val_loss: 36135.6406 - val_mae: 156.5381\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 36406.6758 - mae: 156.2892 - val_loss: 36113.3945 - val_mae: 156.4826\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 36384.3750 - mae: 156.2324 - val_loss: 36091.5586 - val_mae: 156.4276\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 36362.7344 - mae: 156.1764 - val_loss: 36069.5703 - val_mae: 156.3723\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 36340.8984 - mae: 156.1203 - val_loss: 36047.5898 - val_mae: 156.3170\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 36318.8516 - mae: 156.0636 - val_loss: 36025.7852 - val_mae: 156.2622\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 36297.1523 - mae: 156.0078 - val_loss: 36003.9336 - val_mae: 156.2072\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 36275.3594 - mae: 155.9517 - val_loss: 35981.9727 - val_mae: 156.1522\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 36253.4766 - mae: 155.8954 - val_loss: 35960.1484 - val_mae: 156.0973\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 36231.7148 - mae: 155.8396 - val_loss: 35938.2031 - val_mae: 156.0421\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 36209.8750 - mae: 155.7832 - val_loss: 35916.3438 - val_mae: 155.9870\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 36187.9883 - mae: 155.7270 - val_loss: 35894.4648 - val_mae: 155.9320\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36166.3750 - mae: 155.6711 - val_loss: 35872.4141 - val_mae: 155.8766\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 36144.2305 - mae: 155.6145 - val_loss: 35850.6562 - val_mae: 155.8217\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 36122.6133 - mae: 155.5590 - val_loss: 35828.7812 - val_mae: 155.7665\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 36100.8320 - mae: 155.5027 - val_loss: 35806.8359 - val_mae: 155.7115\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 36078.7891 - mae: 155.4468 - val_loss: 35785.1680 - val_mae: 155.6568\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 36057.4883 - mae: 155.3915 - val_loss: 35763.1289 - val_mae: 155.6011\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 36035.3750 - mae: 155.3349 - val_loss: 35741.4297 - val_mae: 155.5463\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 36013.6914 - mae: 155.2788 - val_loss: 35719.7344 - val_mae: 155.4915\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35992.0273 - mae: 155.2227 - val_loss: 35697.9609 - val_mae: 155.4364\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35970.2969 - mae: 155.1667 - val_loss: 35676.1680 - val_mae: 155.3814\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35948.5781 - mae: 155.1110 - val_loss: 35654.3867 - val_mae: 155.3262\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35926.9492 - mae: 155.0556 - val_loss: 35632.4453 - val_mae: 155.2712\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35905.2070 - mae: 154.9997 - val_loss: 35610.5352 - val_mae: 155.2159\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35883.4062 - mae: 154.9438 - val_loss: 35588.7578 - val_mae: 155.1609\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35861.8672 - mae: 154.8887 - val_loss: 35567.0547 - val_mae: 155.1059\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35840.0938 - mae: 154.8328 - val_loss: 35545.4648 - val_mae: 155.0512\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 35818.4492 - mae: 154.7771 - val_loss: 35523.9727 - val_mae: 154.9965\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 35797.0547 - mae: 154.7219 - val_loss: 35502.1289 - val_mae: 154.9412\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 35775.3242 - mae: 154.6662 - val_loss: 35480.6211 - val_mae: 154.8864\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35753.7617 - mae: 154.6107 - val_loss: 35458.9805 - val_mae: 154.8315\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35732.4102 - mae: 154.5556 - val_loss: 35437.2188 - val_mae: 154.7764\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 35710.6680 - mae: 154.4998 - val_loss: 35415.6680 - val_mae: 154.7217\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 35689.0234 - mae: 154.4441 - val_loss: 35394.0938 - val_mae: 154.6669\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35667.5703 - mae: 154.3893 - val_loss: 35372.5039 - val_mae: 154.6120\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35646.0547 - mae: 154.3340 - val_loss: 35350.8594 - val_mae: 154.5571\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35624.4531 - mae: 154.2785 - val_loss: 35329.2930 - val_mae: 154.5022\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35603.0234 - mae: 154.2233 - val_loss: 35307.6953 - val_mae: 154.4474\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35581.4375 - mae: 154.1682 - val_loss: 35286.0898 - val_mae: 154.3927\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35560.0977 - mae: 154.1135 - val_loss: 35264.4570 - val_mae: 154.3377\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35538.5469 - mae: 154.0585 - val_loss: 35243.0352 - val_mae: 154.2831\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35517.2266 - mae: 154.0036 - val_loss: 35221.6406 - val_mae: 154.2285\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 35495.7930 - mae: 153.9483 - val_loss: 35200.3164 - val_mae: 154.1740\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35474.3984 - mae: 153.8934 - val_loss: 35179.0156 - val_mae: 154.1197\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35453.4062 - mae: 153.8396 - val_loss: 35157.4141 - val_mae: 154.0648\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35431.9727 - mae: 153.7849 - val_loss: 35135.8984 - val_mae: 154.0100\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35410.4609 - mae: 153.7297 - val_loss: 35114.6562 - val_mae: 153.9558\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35389.3750 - mae: 153.6750 - val_loss: 35093.2070 - val_mae: 153.9011\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 35367.7656 - mae: 153.6197 - val_loss: 35072.0312 - val_mae: 153.8469\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35346.5234 - mae: 153.5651 - val_loss: 35050.6523 - val_mae: 153.7923\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35325.3125 - mae: 153.5103 - val_loss: 35029.2305 - val_mae: 153.7376\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35304.0117 - mae: 153.4557 - val_loss: 35007.8398 - val_mae: 153.6828\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35282.6211 - mae: 153.4005 - val_loss: 34986.5273 - val_mae: 153.6283\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35261.5078 - mae: 153.3464 - val_loss: 34965.0352 - val_mae: 153.5734\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 35240.0547 - mae: 153.2912 - val_loss: 34943.7305 - val_mae: 153.5188\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 35218.7422 - mae: 153.2363 - val_loss: 34922.3555 - val_mae: 153.4643\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 35197.5859 - mae: 153.1818 - val_loss: 34901.0586 - val_mae: 153.4096\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.9, model__n_hidden=1, model__n_neurons=5, model__optimizer=adam; total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 774, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 89, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 331, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 675]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmpv5kep90w\\assets\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 36ms/step - loss: 22139.2637 - mae: 122.8355 - val_loss: 22786.3418 - val_mae: 124.8345\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 22121.0742 - mae: 122.7760 - val_loss: 22767.6738 - val_mae: 124.7741\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 22103.0566 - mae: 122.7168 - val_loss: 22748.9766 - val_mae: 124.7138\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 22084.9512 - mae: 122.6576 - val_loss: 22730.3477 - val_mae: 124.6535\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 22066.7695 - mae: 122.5985 - val_loss: 22711.8203 - val_mae: 124.5935\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 22048.7051 - mae: 122.5393 - val_loss: 22693.2910 - val_mae: 124.5336\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 22030.6699 - mae: 122.4806 - val_loss: 22674.7168 - val_mae: 124.4735\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 22012.7129 - mae: 122.4217 - val_loss: 22656.0488 - val_mae: 124.4131\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 21994.4688 - mae: 122.3623 - val_loss: 22637.5352 - val_mae: 124.3532\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 21976.5938 - mae: 122.3037 - val_loss: 22618.9648 - val_mae: 124.2932\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 21958.5488 - mae: 122.2445 - val_loss: 22600.4004 - val_mae: 124.2329\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 21940.5000 - mae: 122.1857 - val_loss: 22581.9844 - val_mae: 124.1732\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 21922.5332 - mae: 122.1271 - val_loss: 22563.5176 - val_mae: 124.1134\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 21904.8301 - mae: 122.0688 - val_loss: 22544.8730 - val_mae: 124.0536\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 21886.7246 - mae: 122.0097 - val_loss: 22526.4082 - val_mae: 123.9940\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 21868.6406 - mae: 121.9508 - val_loss: 22508.0898 - val_mae: 123.9347\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 21850.9668 - mae: 121.8926 - val_loss: 22489.6289 - val_mae: 123.8750\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 21833.1133 - mae: 121.8342 - val_loss: 22471.1523 - val_mae: 123.8154\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 21815.1074 - mae: 121.7754 - val_loss: 22452.8301 - val_mae: 123.7561\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 21797.1641 - mae: 121.7170 - val_loss: 22434.5215 - val_mae: 123.6968\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 21779.4258 - mae: 121.6588 - val_loss: 22416.0332 - val_mae: 123.6372\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 21761.5312 - mae: 121.6001 - val_loss: 22397.5254 - val_mae: 123.5772\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 21743.5234 - mae: 121.5411 - val_loss: 22379.1172 - val_mae: 123.5174\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 21725.6992 - mae: 121.4830 - val_loss: 22360.7422 - val_mae: 123.4579\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 21707.9648 - mae: 121.4244 - val_loss: 22342.4238 - val_mae: 123.3982\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 21690.1582 - mae: 121.3658 - val_loss: 22324.0918 - val_mae: 123.3385\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 21672.2539 - mae: 121.3074 - val_loss: 22305.8652 - val_mae: 123.2793\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 21654.7227 - mae: 121.2497 - val_loss: 22287.4492 - val_mae: 123.2196\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 21636.8613 - mae: 121.1910 - val_loss: 22269.1660 - val_mae: 123.1601\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 21619.2012 - mae: 121.1327 - val_loss: 22250.8594 - val_mae: 123.1004\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 21601.3262 - mae: 121.0745 - val_loss: 22232.7539 - val_mae: 123.0414\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 21583.7559 - mae: 121.0167 - val_loss: 22214.5723 - val_mae: 122.9820\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 21566.1348 - mae: 120.9586 - val_loss: 22196.4238 - val_mae: 122.9227\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 21548.4023 - mae: 120.9004 - val_loss: 22178.3633 - val_mae: 122.8637\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 21531.0078 - mae: 120.8427 - val_loss: 22160.0957 - val_mae: 122.8042\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 21513.1465 - mae: 120.7845 - val_loss: 22142.0703 - val_mae: 122.7453\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 21495.7266 - mae: 120.7269 - val_loss: 22123.8105 - val_mae: 122.6856\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 21478.0098 - mae: 120.6684 - val_loss: 22105.6641 - val_mae: 122.6261\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 21460.5430 - mae: 120.6107 - val_loss: 22087.4707 - val_mae: 122.5665\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 21442.7852 - mae: 120.5523 - val_loss: 22069.3867 - val_mae: 122.5071\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 21425.0723 - mae: 120.4944 - val_loss: 22051.3789 - val_mae: 122.4480\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 21407.6211 - mae: 120.4366 - val_loss: 22033.2793 - val_mae: 122.3887\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 21390.0039 - mae: 120.3786 - val_loss: 22015.2012 - val_mae: 122.3293\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 21372.6113 - mae: 120.3206 - val_loss: 21996.9863 - val_mae: 122.2694\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 21354.7598 - mae: 120.2623 - val_loss: 21979.0391 - val_mae: 122.2102\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 21337.4668 - mae: 120.2046 - val_loss: 21960.9297 - val_mae: 122.1505\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 21319.8691 - mae: 120.1464 - val_loss: 21942.8672 - val_mae: 122.0907\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 21302.3711 - mae: 120.0882 - val_loss: 21924.8262 - val_mae: 122.0313\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 21284.9590 - mae: 120.0304 - val_loss: 21906.7832 - val_mae: 121.9717\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 21267.3516 - mae: 119.9721 - val_loss: 21888.7891 - val_mae: 121.9124\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 21249.7832 - mae: 119.9141 - val_loss: 21870.7461 - val_mae: 121.8529\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 21232.2852 - mae: 119.8563 - val_loss: 21852.6172 - val_mae: 121.7933\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 21214.6816 - mae: 119.7979 - val_loss: 21834.5977 - val_mae: 121.7337\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 21197.0996 - mae: 119.7400 - val_loss: 21816.6172 - val_mae: 121.6744\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 21179.7109 - mae: 119.6820 - val_loss: 21798.5527 - val_mae: 121.6146\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 21162.3594 - mae: 119.6241 - val_loss: 21780.5000 - val_mae: 121.5550\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 21144.8320 - mae: 119.5662 - val_loss: 21762.6250 - val_mae: 121.4957\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 21127.5352 - mae: 119.5084 - val_loss: 21744.6660 - val_mae: 121.4362\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 21109.9863 - mae: 119.4504 - val_loss: 21726.7773 - val_mae: 121.3770\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 21092.7148 - mae: 119.3926 - val_loss: 21708.8496 - val_mae: 121.3174\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 21075.2051 - mae: 119.3347 - val_loss: 21691.0859 - val_mae: 121.2584\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 21058.0215 - mae: 119.2772 - val_loss: 21673.2773 - val_mae: 121.1993\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 21040.6328 - mae: 119.2195 - val_loss: 21655.4961 - val_mae: 121.1401\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 21023.3125 - mae: 119.1619 - val_loss: 21637.6914 - val_mae: 121.0808\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 21006.1191 - mae: 119.1042 - val_loss: 21619.7207 - val_mae: 121.0210\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 20988.8379 - mae: 119.0464 - val_loss: 21601.8125 - val_mae: 120.9615\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 20971.3320 - mae: 118.9883 - val_loss: 21584.0918 - val_mae: 120.9023\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 20954.3066 - mae: 118.9310 - val_loss: 21566.1699 - val_mae: 120.8426\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 20936.9062 - mae: 118.8731 - val_loss: 21548.3965 - val_mae: 120.7832\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 20919.6328 - mae: 118.8156 - val_loss: 21530.6855 - val_mae: 120.7243\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 20902.5000 - mae: 118.7582 - val_loss: 21512.9473 - val_mae: 120.6650\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 20885.2656 - mae: 118.7005 - val_loss: 21495.2051 - val_mae: 120.6057\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 20867.9590 - mae: 118.6430 - val_loss: 21477.6152 - val_mae: 120.5467\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 20850.7305 - mae: 118.5855 - val_loss: 21460.0020 - val_mae: 120.4876\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 20833.7266 - mae: 118.5281 - val_loss: 21442.1797 - val_mae: 120.4279\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 20816.4668 - mae: 118.4705 - val_loss: 21424.4590 - val_mae: 120.3687\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 20799.4238 - mae: 118.4132 - val_loss: 21406.7266 - val_mae: 120.3095\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 20782.0410 - mae: 118.3556 - val_loss: 21389.1914 - val_mae: 120.2507\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 20765.1309 - mae: 118.2983 - val_loss: 21371.3652 - val_mae: 120.1910\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 20747.9121 - mae: 118.2406 - val_loss: 21353.6426 - val_mae: 120.1316\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 20730.7402 - mae: 118.1831 - val_loss: 21336.0234 - val_mae: 120.0724\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 20713.5977 - mae: 118.1257 - val_loss: 21318.4531 - val_mae: 120.0133\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 20696.5254 - mae: 118.0683 - val_loss: 21300.8398 - val_mae: 119.9540\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 20679.3574 - mae: 118.0110 - val_loss: 21283.3848 - val_mae: 119.8954\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 20662.4668 - mae: 117.9541 - val_loss: 21265.7617 - val_mae: 119.8362\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 20645.5156 - mae: 117.8969 - val_loss: 21248.1641 - val_mae: 119.7771\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 20628.3516 - mae: 117.8396 - val_loss: 21230.6289 - val_mae: 119.7182\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 20611.2891 - mae: 117.7824 - val_loss: 21213.1211 - val_mae: 119.6590\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 20594.3418 - mae: 117.7254 - val_loss: 21195.5918 - val_mae: 119.6002\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 20577.3340 - mae: 117.6684 - val_loss: 21178.0879 - val_mae: 119.5412\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 20560.5293 - mae: 117.6111 - val_loss: 21160.3828 - val_mae: 119.4815\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 20543.0879 - mae: 117.5533 - val_loss: 21143.1035 - val_mae: 119.4230\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 20526.3652 - mae: 117.4965 - val_loss: 21125.6484 - val_mae: 119.3641\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 20509.4531 - mae: 117.4394 - val_loss: 21108.1699 - val_mae: 119.3048\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 20492.4043 - mae: 117.3821 - val_loss: 21090.7969 - val_mae: 119.2460\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 20475.6328 - mae: 117.3250 - val_loss: 21073.3477 - val_mae: 119.1869\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 20458.5469 - mae: 117.2677 - val_loss: 21056.0098 - val_mae: 119.1282\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 20441.8613 - mae: 117.2110 - val_loss: 21038.4473 - val_mae: 119.0689\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 20424.7266 - mae: 117.1535 - val_loss: 21021.0215 - val_mae: 119.0100\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 20407.9570 - mae: 117.0966 - val_loss: 21003.5410 - val_mae: 118.9507\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.9, model__n_hidden=1, model__n_neurons=5, model__optimizer=adam; total time=   5.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 774, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 89, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 331, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 675]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmpjlq2qnrk\\assets\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 23ms/step - loss: 36093.9961 - mae: 161.2510 - val_loss: 37727.2695 - val_mae: 163.9985\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 36070.7188 - mae: 161.1909 - val_loss: 37702.9023 - val_mae: 163.9366\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 36048.0156 - mae: 161.1318 - val_loss: 37678.3516 - val_mae: 163.8742\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 36024.9375 - mae: 161.0723 - val_loss: 37653.9062 - val_mae: 163.8121\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 36001.9961 - mae: 161.0132 - val_loss: 37629.4531 - val_mae: 163.7499\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 35978.8438 - mae: 160.9534 - val_loss: 37605.1445 - val_mae: 163.6881\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35955.9648 - mae: 160.8938 - val_loss: 37580.8164 - val_mae: 163.6263\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 35933.0625 - mae: 160.8346 - val_loss: 37556.4805 - val_mae: 163.5643\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35910.0898 - mae: 160.7749 - val_loss: 37532.1680 - val_mae: 163.5024\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 35887.2578 - mae: 160.7156 - val_loss: 37507.7734 - val_mae: 163.4402\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35864.3398 - mae: 160.6560 - val_loss: 37483.4102 - val_mae: 163.3783\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 35841.4336 - mae: 160.5966 - val_loss: 37459.1523 - val_mae: 163.3164\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35818.8867 - mae: 160.5376 - val_loss: 37434.6641 - val_mae: 163.2540\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35795.7773 - mae: 160.4778 - val_loss: 37410.3828 - val_mae: 163.1921\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35772.9141 - mae: 160.4183 - val_loss: 37386.1602 - val_mae: 163.1303\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 35749.9648 - mae: 160.3590 - val_loss: 37362.1250 - val_mae: 163.0690\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35727.1133 - mae: 160.2999 - val_loss: 37338.0273 - val_mae: 163.0073\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35704.6211 - mae: 160.2408 - val_loss: 37313.6289 - val_mae: 162.9451\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35681.8320 - mae: 160.1812 - val_loss: 37289.2422 - val_mae: 162.8827\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 35658.7969 - mae: 160.1219 - val_loss: 37265.0781 - val_mae: 162.8208\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35636.1562 - mae: 160.0626 - val_loss: 37240.8438 - val_mae: 162.7589\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35613.3438 - mae: 160.0034 - val_loss: 37216.6992 - val_mae: 162.6971\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35590.5391 - mae: 159.9440 - val_loss: 37192.6836 - val_mae: 162.6356\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35568.0430 - mae: 159.8850 - val_loss: 37168.5273 - val_mae: 162.5738\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35545.1992 - mae: 159.8255 - val_loss: 37144.5703 - val_mae: 162.5124\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35522.4531 - mae: 159.7665 - val_loss: 37120.7070 - val_mae: 162.4513\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35500.0117 - mae: 159.7077 - val_loss: 37096.6289 - val_mae: 162.3895\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35477.6406 - mae: 159.6488 - val_loss: 37072.3672 - val_mae: 162.3273\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35454.6875 - mae: 159.5892 - val_loss: 37048.4961 - val_mae: 162.2662\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35431.9805 - mae: 159.5302 - val_loss: 37024.6484 - val_mae: 162.2050\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35409.7148 - mae: 159.4714 - val_loss: 37000.4844 - val_mae: 162.1430\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 35387.1758 - mae: 159.4123 - val_loss: 36976.3789 - val_mae: 162.0813\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35364.4258 - mae: 159.3530 - val_loss: 36952.4531 - val_mae: 162.0201\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35341.8047 - mae: 159.2941 - val_loss: 36928.5586 - val_mae: 161.9590\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 35319.3711 - mae: 159.2352 - val_loss: 36904.6406 - val_mae: 161.8979\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35296.7734 - mae: 159.1760 - val_loss: 36880.7695 - val_mae: 161.8369\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35274.0430 - mae: 159.1168 - val_loss: 36856.9727 - val_mae: 161.7759\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35251.7188 - mae: 159.0580 - val_loss: 36832.8828 - val_mae: 161.7143\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35229.3398 - mae: 158.9991 - val_loss: 36808.6328 - val_mae: 161.6523\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 35206.5586 - mae: 158.9401 - val_loss: 36784.6914 - val_mae: 161.5911\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 35183.8750 - mae: 158.8809 - val_loss: 36760.9688 - val_mae: 161.5302\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35161.3984 - mae: 158.8219 - val_loss: 36737.2070 - val_mae: 161.4693\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35139.1016 - mae: 158.7634 - val_loss: 36713.2812 - val_mae: 161.4080\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35116.5234 - mae: 158.7044 - val_loss: 36689.4453 - val_mae: 161.3468\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35094.1836 - mae: 158.6456 - val_loss: 36665.5039 - val_mae: 161.2854\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35071.4727 - mae: 158.5862 - val_loss: 36641.7969 - val_mae: 161.2245\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35049.2031 - mae: 158.5277 - val_loss: 36617.9180 - val_mae: 161.1633\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35026.8281 - mae: 158.4688 - val_loss: 36593.9961 - val_mae: 161.1018\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35004.5938 - mae: 158.4102 - val_loss: 36569.9609 - val_mae: 161.0402\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 34981.7188 - mae: 158.3504 - val_loss: 36546.3555 - val_mae: 160.9794\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 34959.4883 - mae: 158.2919 - val_loss: 36522.5977 - val_mae: 160.9183\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 34936.9688 - mae: 158.2328 - val_loss: 36498.8320 - val_mae: 160.8572\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 34914.9023 - mae: 158.1745 - val_loss: 36474.8438 - val_mae: 160.7955\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 34892.3867 - mae: 158.1155 - val_loss: 36451.1719 - val_mae: 160.7346\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 34869.9531 - mae: 158.0567 - val_loss: 36427.7148 - val_mae: 160.6741\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 34847.8711 - mae: 157.9985 - val_loss: 36404.0273 - val_mae: 160.6131\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 34825.5820 - mae: 157.9397 - val_loss: 36380.2852 - val_mae: 160.5519\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 34803.2383 - mae: 157.8809 - val_loss: 36356.5938 - val_mae: 160.4909\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 34780.8984 - mae: 157.8220 - val_loss: 36333.0391 - val_mae: 160.4301\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 34758.7188 - mae: 157.7633 - val_loss: 36309.4180 - val_mae: 160.3692\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 34736.6875 - mae: 157.7050 - val_loss: 36285.6680 - val_mae: 160.3079\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 34714.2266 - mae: 157.6457 - val_loss: 36262.1914 - val_mae: 160.2473\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 34691.9961 - mae: 157.5869 - val_loss: 36238.7578 - val_mae: 160.1867\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 34670.1445 - mae: 157.5288 - val_loss: 36214.9336 - val_mae: 160.1252\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 34647.3945 - mae: 157.4695 - val_loss: 36191.5977 - val_mae: 160.0648\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 34625.4844 - mae: 157.4112 - val_loss: 36168.0039 - val_mae: 160.0038\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 34603.3516 - mae: 157.3524 - val_loss: 36144.3828 - val_mae: 159.9427\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 34581.1055 - mae: 157.2936 - val_loss: 36120.8281 - val_mae: 159.8818\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 34558.8906 - mae: 157.2348 - val_loss: 36097.2109 - val_mae: 159.8206\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 34536.7109 - mae: 157.1762 - val_loss: 36073.7070 - val_mae: 159.7598\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 34514.7266 - mae: 157.1176 - val_loss: 36050.1133 - val_mae: 159.6987\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 34492.4062 - mae: 157.0585 - val_loss: 36026.7734 - val_mae: 159.6382\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 34470.5469 - mae: 157.0002 - val_loss: 36003.2695 - val_mae: 159.5772\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 34448.2031 - mae: 156.9413 - val_loss: 35979.9141 - val_mae: 159.5167\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 34426.2266 - mae: 156.8831 - val_loss: 35956.3438 - val_mae: 159.4555\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 34404.1406 - mae: 156.8241 - val_loss: 35932.7930 - val_mae: 159.3945\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 34381.8789 - mae: 156.7652 - val_loss: 35909.4453 - val_mae: 159.3338\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 34359.8711 - mae: 156.7068 - val_loss: 35886.0586 - val_mae: 159.2731\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 34337.8867 - mae: 156.6484 - val_loss: 35862.7070 - val_mae: 159.2124\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 34315.9805 - mae: 156.5899 - val_loss: 35839.1758 - val_mae: 159.1513\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 34293.9688 - mae: 156.5316 - val_loss: 35815.5977 - val_mae: 159.0900\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 34271.7031 - mae: 156.4725 - val_loss: 35792.2695 - val_mae: 159.0294\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 34249.7031 - mae: 156.4139 - val_loss: 35769.0547 - val_mae: 158.9689\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 34227.7539 - mae: 156.3555 - val_loss: 35745.8828 - val_mae: 158.9086\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 34205.6719 - mae: 156.2969 - val_loss: 35722.7695 - val_mae: 158.8484\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 34183.8867 - mae: 156.2386 - val_loss: 35699.4297 - val_mae: 158.7876\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 34162.1562 - mae: 156.1802 - val_loss: 35675.8164 - val_mae: 158.7262\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 34139.9336 - mae: 156.1210 - val_loss: 35652.5039 - val_mae: 158.6654\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 34117.9180 - mae: 156.0625 - val_loss: 35629.2695 - val_mae: 158.6048\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 34096.0078 - mae: 156.0040 - val_loss: 35606.0156 - val_mae: 158.5442\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 34074.1641 - mae: 155.9457 - val_loss: 35582.7070 - val_mae: 158.4834\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 34052.3125 - mae: 155.8875 - val_loss: 35559.4727 - val_mae: 158.4228\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 34030.4805 - mae: 155.8292 - val_loss: 35536.2578 - val_mae: 158.3622\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 34008.3359 - mae: 155.7704 - val_loss: 35513.2695 - val_mae: 158.3021\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 33986.8320 - mae: 155.7125 - val_loss: 35489.7930 - val_mae: 158.2409\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 33964.7344 - mae: 155.6534 - val_loss: 35466.5312 - val_mae: 158.1801\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 33943.0117 - mae: 155.5954 - val_loss: 35443.2891 - val_mae: 158.1193\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 33920.8789 - mae: 155.5366 - val_loss: 35420.2969 - val_mae: 158.0592\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 33899.4023 - mae: 155.4785 - val_loss: 35397.0703 - val_mae: 157.9984\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 33877.3906 - mae: 155.4197 - val_loss: 35374.1250 - val_mae: 157.9384\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.9, model__n_hidden=1, model__n_neurons=5, model__optimizer=adam; total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 774, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 89, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 331, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 670]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmpwuu4bpfy\\assets\n",
      "Epoch 1/100\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 24492.2461 - mae: 74.6546"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 20ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 23399.2207 - mae: 72.8679 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 996us/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.5, model__n_hidden=0, model__n_neurons=125, model__optimizer=sgd; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 774, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 89, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 331, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 1755]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmp9zlulnrp\\assets\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 13ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 23112.9844 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23112.9844 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.5, model__n_hidden=0, model__n_neurons=125, model__optimizer=sgd; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 774, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 89, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 331, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 1755]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmp6susf3kx\\assets\n",
      "Epoch 1/100\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 21635.4844 - mae: 71.4221"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 14ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 23041.8223 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 23041.8223 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.5, model__n_hidden=0, model__n_neurons=125, model__optimizer=sgd; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 774, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 89, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 331, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 1742]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmp8crhn9ty\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23399.2207 - mae: 72.8679 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.9, model__n_hidden=0, model__n_neurons=5, model__optimizer=adam; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 774, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 89, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 331, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 1755]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmpb4p5ucka\\assets\n",
      "Epoch 1/100\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 23560.8262 - mae: 73.5918"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 27ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23112.9844 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9844 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 999us/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.9, model__n_hidden=0, model__n_neurons=5, model__optimizer=adam; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 774, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 89, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 331, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 1755]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmppjp0e4vh\\assets\n",
      "Epoch 1/100\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 21635.4844 - mae: 71.4221"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 22ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23041.8223 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23041.8223 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 952us/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.9, model__n_hidden=0, model__n_neurons=5, model__optimizer=adam; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 774, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 89, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 331, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 1742]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmpukk85sf4\\assets\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 14ms/step - loss: 408010.3750 - mae: 376.3181 - val_loss: 7266032.0000 - val_mae: 2065.8442\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 368411360.0000 - mae: 11308.4775 - val_loss: 5019391488.0000 - val_mae: 54158.3516\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 235952865280.0000 - mae: 285064.9062 - val_loss: 4138005168128.0000 - val_mae: 1554822.3750\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 216624023994368.0000 - mae: 8303905.0000 - val_loss: 2360125331341312.0000 - val_mae: 37490732.0000\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 148013197314490368.0000 - mae: 231536608.0000 - val_loss: 1770915484015788032.0000 - val_mae: 1019570880.0000\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 72900189380711284736.0000 - mae: 4966104064.0000 - val_loss: 1150114987982809202688.0000 - val_mae: 26044336128.0000\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 71833774143646877089792.0000 - mae: 157056630784.0000 - val_loss: 895004028884634604404736.0000 - val_mae: 723004620800.0000\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 42425648248380524052086784.0000 - mae: 3765896216576.0000 - val_loss: 751583367640682924664160256.0000 - val_mae: 20905006727168.0000\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 43532639573853123089709137920.0000 - mae: 118164557922304.0000 - val_loss: 433801609714343382632621932544.0000 - val_mae: 504479174623232.0000\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 21445437345598810587406532608000.0000 - mae: 2669617721901056.0000 - val_loss: 319258894602139195008311957127168.0000 - val_mae: 13643704497602560.0000\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23720273079710471419285210782498816.0000 - mae: 87019585059946496.0000 - val_loss: 121912602463872735114205131790352384.0000 - val_mae: 269408403531497472.0000\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.1, model__n_hidden=1, model__n_neurons=25, model__optimizer=sgd; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 774, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 89, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 331, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 3375]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmp3ro6qm_k\\assets\n",
      "Epoch 1/100\n",
      "1/8 [==>...........................] - ETA: 1s - loss: 25121.0352 - mae: 134.4916"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 16ms/step - loss: 791959.2500 - mae: 599.5830 - val_loss: 8187466.0000 - val_mae: 2454.7761\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 249093616.0000 - mae: 10640.9580 - val_loss: 3356415232.0000 - val_mae: 49659.8047\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 104600469504.0000 - mae: 222596.6406 - val_loss: 1037824032768.0000 - val_mae: 873930.3125\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36643264266240.0000 - mae: 4142752.7500 - val_loss: 310807623630848.0000 - val_mae: 15111799.0000\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 10089830587301888.0000 - mae: 67490096.0000 - val_loss: 108762393139478528.0000 - val_mae: 282704448.0000\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2602719944806236160.0000 - mae: 1088139136.0000 - val_loss: 33805964938624106496.0000 - val_mae: 4993067008.0000\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1038137346110380834816.0000 - mae: 21347112960.0000 - val_loss: 14638214250228722171904.0000 - val_mae: 102341181440.0000\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 493841208332995207888896.0000 - mae: 468342996992.0000 - val_loss: 5777082133714080964280320.0000 - val_mae: 2047249612800.0000\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 154540070341207645742956544.0000 - mae: 7911337623552.0000 - val_loss: 1854135373471479316432814080.0000 - val_mae: 36794557005824.0000\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 51230309447422373922068234240.0000 - mae: 154188906496000.0000 - val_loss: 685308690626087024696712232960.0000 - val_mae: 703240295415808.0000\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 21414873283027313532611611066368.0000 - mae: 2971444669579264.0000 - val_loss: 162638976250637926122769726046208.0000 - val_mae: 10957016696619008.0000\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 1000us/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.1, model__n_hidden=1, model__n_neurons=25, model__optimizer=sgd; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 774, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 89, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 331, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 3375]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmpoi4rpagk\\assets\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 23ms/step - loss: 541824.9375 - mae: 511.4590 - val_loss: 4524845.0000 - val_mae: 1863.4033\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 75877912.0000 - mae: 5901.7593 - val_loss: 1098919680.0000 - val_mae: 29020.6602\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 29555884032.0000 - mae: 119535.3281 - val_loss: 258033123328.0000 - val_mae: 446365.2500\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6870784802816.0000 - mae: 1842748.3750 - val_loss: 70641935974400.0000 - val_mae: 7318149.5000\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2303662080655360.0000 - mae: 33847540.0000 - val_loss: 18013157263933440.0000 - val_mae: 116720176.0000\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 485891917939212288.0000 - mae: 466810496.0000 - val_loss: 4230460048310009856.0000 - val_mae: 1788246400.0000\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104817604560165011456.0000 - mae: 6924729344.0000 - val_loss: 1006271071415758225408.0000 - val_mae: 27575900160.0000\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 22440423633271023206400.0000 - mae: 106091298816.0000 - val_loss: 231585270974548761640960.0000 - val_mae: 424222031872.0000\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4962873402720413437394944.0000 - mae: 1531605680128.0000 - val_loss: 66196971211990042903838720.0000 - val_mae: 7047951155200.0000\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1849800831336015340832292864.0000 - mae: 29256115552256.0000 - val_loss: 18105053705066656284329115648.0000 - val_mae: 118232186880000.0000\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 501815020747225160858357202944.0000 - mae: 480273175150592.0000 - val_loss: 3979224972211242380796723462144.0000 - val_mae: 1750040930418688.0000\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.1, model__n_hidden=1, model__n_neurons=25, model__optimizer=sgd; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 774, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 89, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 331, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 3350]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmp70x8qp3m\\assets\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 30ms/step - loss: 2951184316706586624.0000 - mae: 437239328.0000 - val_loss: 5648401704799147393024.0000 - val_mae: 61630136320.0000\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 304233291840924542843055401708027904.0000 - mae: 143963756118933504.0000 - val_loss: inf - val_mae: 19643797776032071680.0000\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: inf - mae: 45362097815439997453467648.0000 - val_loss: inf - val_mae: 6493294644356676919521968128.0000\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: inf - mae: 15217753028747440499420778958159872.0000 - val_loss: inf - val_mae: 1916969442890983579047497888815906816.0000\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan    \n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.1, model__n_hidden=1, model__n_neurons=5, model__optimizer=nesterov; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 774, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 89, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 331, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 675]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmpxjp52aq8\\assets\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 31ms/step - loss: 1160804453222187008.0000 - mae: 272836608.0000 - val_loss: 1929806091864628002816.0000 - val_mae: 35182309376.0000\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 72348771259630450877254329935331328.0000 - mae: 67687877131108352.0000 - val_loss: inf - val_mae: 9243247908550082560.0000\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: inf - mae: 17683362463707229241475072.0000 - val_loss: inf - val_mae: 2267317353150633027641016320.0000\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: inf - mae: 4424321876578542872947632405217280.0000 - val_loss: inf - val_mae: 545269249500314708500400552131166208.0000\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan   \n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 1000us/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.1, model__n_hidden=1, model__n_neurons=5, model__optimizer=nesterov; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 774, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 89, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 331, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 675]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmp5c9qx0cl\\assets\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 21ms/step - loss: 1152290865968840704.0000 - mae: 248815216.0000 - val_loss: 1701539033689029083136.0000 - val_mae: 29180000256.0000\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 51391991343697990977795230930042880.0000 - mae: 50659847925923840.0000 - val_loss: inf - val_mae: 6671638645251768320.0000\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: inf - mae: 12154831759642310775668736.0000 - val_loss: inf - val_mae: 1495847509954775668276330496.0000\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: inf - mae: 2727786640254883653867058887655424.0000 - val_loss: inf - val_mae: 344117461904067838766683768202723328.0000\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan   \n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.1, model__n_hidden=1, model__n_neurons=5, model__optimizer=nesterov; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 774, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 89, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 331, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 670]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmp9nazjb1q\\assets\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 17ms/step - loss: 5119.0527 - mae: 54.9938 - val_loss: 4373.9790 - val_mae: 50.9973\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3908.9802 - mae: 48.1149 - val_loss: 3401.0901 - val_mae: 45.0215\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3070.0151 - mae: 42.7385 - val_loss: 2709.0549 - val_mae: 40.2224\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2468.1089 - mae: 38.3899 - val_loss: 2210.1853 - val_mae: 36.3633\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2028.2720 - mae: 34.8636 - val_loss: 1833.9850 - val_mae: 33.1894\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1695.2046 - mae: 31.9694 - val_loss: 1546.8123 - val_mae: 30.5408\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1439.0020 - mae: 29.5249 - val_loss: 1324.1907 - val_mae: 28.3034\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1239.6421 - mae: 27.4619 - val_loss: 1147.7495 - val_mae: 26.3687\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1081.2517 - mae: 25.6896 - val_loss: 1009.1743 - val_mae: 24.7202\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 955.6720 - mae: 24.1658 - val_loss: 896.0837 - val_mae: 23.2758\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 853.6116 - mae: 22.8360 - val_loss: 805.7362 - val_mae: 22.0309\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 771.0178 - mae: 21.6799 - val_loss: 729.7602 - val_mae: 20.9223\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 701.9655 - mae: 20.6645 - val_loss: 666.9004 - val_mae: 19.9439\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 644.7509 - mae: 19.7614 - val_loss: 614.5148 - val_mae: 19.0750\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 596.5964 - mae: 18.9734 - val_loss: 569.6074 - val_mae: 18.2966\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 555.7580 - mae: 18.2667 - val_loss: 531.3536 - val_mae: 17.6036\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 521.0897 - mae: 17.6465 - val_loss: 498.8350 - val_mae: 16.9874\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 491.3248 - mae: 17.0868 - val_loss: 471.1172 - val_mae: 16.4323\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 465.8022 - mae: 16.5881 - val_loss: 446.6024 - val_mae: 15.9297\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 443.5931 - mae: 16.1383 - val_loss: 425.4600 - val_mae: 15.4792\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 424.2205 - mae: 15.7312 - val_loss: 406.8847 - val_mae: 15.0764\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 407.3589 - mae: 15.3769 - val_loss: 390.3726 - val_mae: 14.7141\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 392.2963 - mae: 15.0544 - val_loss: 375.6983 - val_mae: 14.3874\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 378.9883 - mae: 14.7587 - val_loss: 362.7990 - val_mae: 14.0937\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 367.1956 - mae: 14.4972 - val_loss: 350.9387 - val_mae: 13.8306\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 356.6372 - mae: 14.2590 - val_loss: 340.2196 - val_mae: 13.5948\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 347.0577 - mae: 14.0469 - val_loss: 330.8969 - val_mae: 13.3826\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 338.5424 - mae: 13.8472 - val_loss: 322.2040 - val_mae: 13.1897\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 330.7454 - mae: 13.6720 - val_loss: 313.9168 - val_mae: 13.0150\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 323.3716 - mae: 13.5031 - val_loss: 306.4752 - val_mae: 12.8528\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 316.8860 - mae: 13.3545 - val_loss: 299.6788 - val_mae: 12.7021\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 310.8599 - mae: 13.2111 - val_loss: 293.4279 - val_mae: 12.5633\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 305.2895 - mae: 13.0855 - val_loss: 287.6731 - val_mae: 12.4341\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 300.0988 - mae: 12.9639 - val_loss: 282.2930 - val_mae: 12.3156\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 295.4076 - mae: 12.8515 - val_loss: 277.0634 - val_mae: 12.2039\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 290.8836 - mae: 12.7397 - val_loss: 271.7902 - val_mae: 12.0983\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 286.5301 - mae: 12.6543 - val_loss: 267.0479 - val_mae: 11.9968\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 282.5886 - mae: 12.5678 - val_loss: 262.6071 - val_mae: 11.8996\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 278.8017 - mae: 12.4799 - val_loss: 258.4593 - val_mae: 11.8112\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 275.2887 - mae: 12.4023 - val_loss: 254.4278 - val_mae: 11.7263\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 271.7556 - mae: 12.3224 - val_loss: 250.6040 - val_mae: 11.6447\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 268.5085 - mae: 12.2479 - val_loss: 246.8264 - val_mae: 11.5658\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 265.3788 - mae: 12.1785 - val_loss: 243.0800 - val_mae: 11.4890\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 262.4737 - mae: 12.1240 - val_loss: 239.7040 - val_mae: 11.4144\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 259.5491 - mae: 12.0527 - val_loss: 236.4925 - val_mae: 11.3434\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 256.7845 - mae: 11.9892 - val_loss: 233.2896 - val_mae: 11.2734\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 254.2164 - mae: 11.9287 - val_loss: 230.0088 - val_mae: 11.2057\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 251.5418 - mae: 11.8728 - val_loss: 227.1728 - val_mae: 11.1432\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 249.0894 - mae: 11.8148 - val_loss: 224.1902 - val_mae: 11.0835\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 246.6544 - mae: 11.7657 - val_loss: 221.4407 - val_mae: 11.0221\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 244.3748 - mae: 11.7132 - val_loss: 218.5815 - val_mae: 10.9624\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 242.1053 - mae: 11.6629 - val_loss: 215.9113 - val_mae: 10.9039\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 239.9044 - mae: 11.6131 - val_loss: 213.3135 - val_mae: 10.8472\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 237.8285 - mae: 11.5708 - val_loss: 210.5189 - val_mae: 10.7859\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 235.6512 - mae: 11.5194 - val_loss: 208.0416 - val_mae: 10.7320\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 233.7005 - mae: 11.4727 - val_loss: 205.6492 - val_mae: 10.6760\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 231.7244 - mae: 11.4248 - val_loss: 202.9604 - val_mae: 10.6202\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 229.6831 - mae: 11.3867 - val_loss: 200.8373 - val_mae: 10.5692\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 227.8646 - mae: 11.3384 - val_loss: 198.4957 - val_mae: 10.5129\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 225.9627 - mae: 11.2914 - val_loss: 196.2218 - val_mae: 10.4619\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 224.2064 - mae: 11.2503 - val_loss: 194.0397 - val_mae: 10.4099\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 222.4597 - mae: 11.2085 - val_loss: 191.8854 - val_mae: 10.3574\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 220.7546 - mae: 11.1658 - val_loss: 189.6510 - val_mae: 10.3075\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 218.9990 - mae: 11.1278 - val_loss: 187.7024 - val_mae: 10.2617\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 217.4059 - mae: 11.0866 - val_loss: 185.4896 - val_mae: 10.2121\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 215.7494 - mae: 11.0531 - val_loss: 183.4576 - val_mae: 10.1636\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 214.1390 - mae: 11.0122 - val_loss: 181.4827 - val_mae: 10.1173\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 212.5959 - mae: 10.9794 - val_loss: 179.7576 - val_mae: 10.0720\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 211.1025 - mae: 10.9356 - val_loss: 177.8854 - val_mae: 10.0274\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 209.5690 - mae: 10.8993 - val_loss: 176.0424 - val_mae: 9.9803\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 208.1030 - mae: 10.8646 - val_loss: 174.0541 - val_mae: 9.9313\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 206.6771 - mae: 10.8266 - val_loss: 172.4673 - val_mae: 9.8879\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 205.2685 - mae: 10.7882 - val_loss: 170.6425 - val_mae: 9.8427\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 203.9107 - mae: 10.7549 - val_loss: 169.0007 - val_mae: 9.8036\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 202.5545 - mae: 10.7223 - val_loss: 167.3376 - val_mae: 9.7603\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 201.2341 - mae: 10.6886 - val_loss: 165.5667 - val_mae: 9.7159\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 199.8526 - mae: 10.6559 - val_loss: 164.0141 - val_mae: 9.6748\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 198.5608 - mae: 10.6187 - val_loss: 162.4286 - val_mae: 9.6347\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 197.3039 - mae: 10.5881 - val_loss: 160.8599 - val_mae: 9.5932\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 196.0887 - mae: 10.5534 - val_loss: 159.3551 - val_mae: 9.5557\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 194.8999 - mae: 10.5280 - val_loss: 157.5559 - val_mae: 9.5137\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 193.5404 - mae: 10.4929 - val_loss: 156.1320 - val_mae: 9.4764\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 192.3373 - mae: 10.4634 - val_loss: 154.7384 - val_mae: 9.4386\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 191.1776 - mae: 10.4309 - val_loss: 153.3869 - val_mae: 9.4029\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 190.1250 - mae: 10.4006 - val_loss: 151.9940 - val_mae: 9.3657\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 188.9329 - mae: 10.3689 - val_loss: 150.7276 - val_mae: 9.3320\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 187.8147 - mae: 10.3420 - val_loss: 149.2750 - val_mae: 9.2928\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 186.7418 - mae: 10.3141 - val_loss: 147.9857 - val_mae: 9.2598\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 185.7003 - mae: 10.2876 - val_loss: 146.6786 - val_mae: 9.2233\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 184.5971 - mae: 10.2592 - val_loss: 145.3619 - val_mae: 9.1849\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 183.5810 - mae: 10.2290 - val_loss: 144.0530 - val_mae: 9.1504\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 182.5696 - mae: 10.2043 - val_loss: 142.6957 - val_mae: 9.1118\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 181.5351 - mae: 10.1718 - val_loss: 141.4358 - val_mae: 9.0755\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 180.5390 - mae: 10.1430 - val_loss: 140.2410 - val_mae: 9.0434\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 179.5592 - mae: 10.1159 - val_loss: 139.0145 - val_mae: 9.0103\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 178.5636 - mae: 10.0900 - val_loss: 137.7792 - val_mae: 8.9755\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 177.6333 - mae: 10.0641 - val_loss: 136.7131 - val_mae: 8.9449\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 176.7308 - mae: 10.0366 - val_loss: 135.4600 - val_mae: 8.9123\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 175.8225 - mae: 10.0166 - val_loss: 134.3967 - val_mae: 8.8799\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 174.9200 - mae: 9.9869 - val_loss: 133.3470 - val_mae: 8.8487\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.9, model__n_hidden=2, model__n_neurons=125, model__optimizer=sgd; total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 774, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 89, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 331, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 16875]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmpscxdn7vx\\assets\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 25ms/step - loss: 5033.9160 - mae: 55.6813 - val_loss: 4285.9795 - val_mae: 51.4294\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3953.6135 - mae: 49.4328 - val_loss: 3390.6392 - val_mae: 45.8052\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3182.9929 - mae: 44.4153 - val_loss: 2745.7556 - val_mae: 41.2669\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2619.9221 - mae: 40.3496 - val_loss: 2266.9292 - val_mae: 37.5561\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2196.6787 - mae: 37.0152 - val_loss: 1901.8705 - val_mae: 34.4579\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1870.8120 - mae: 34.1880 - val_loss: 1617.8013 - val_mae: 31.8313\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1614.0793 - mae: 31.7979 - val_loss: 1392.7706 - val_mae: 29.5722\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1409.3802 - mae: 29.7539 - val_loss: 1213.3967 - val_mae: 27.6345\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1244.4640 - mae: 27.9863 - val_loss: 1068.5514 - val_mae: 25.9591\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1109.9435 - mae: 26.4436 - val_loss: 949.1872 - val_mae: 24.4914\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 998.5894 - mae: 25.0893 - val_loss: 851.7690 - val_mae: 23.2052\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 906.5342 - mae: 23.9080 - val_loss: 769.3988 - val_mae: 22.0500\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 828.3046 - mae: 22.8370 - val_loss: 700.2678 - val_mae: 21.0199\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 762.1694 - mae: 21.8746 - val_loss: 641.7468 - val_mae: 20.0979\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 705.7076 - mae: 21.0222 - val_loss: 591.9691 - val_mae: 19.2663\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 657.1450 - mae: 20.2424 - val_loss: 549.1910 - val_mae: 18.5219\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 615.2894 - mae: 19.5583 - val_loss: 512.0281 - val_mae: 17.8482\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 578.6104 - mae: 18.9315 - val_loss: 479.8638 - val_mae: 17.2446\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 546.7886 - mae: 18.3708 - val_loss: 451.7414 - val_mae: 16.7014\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 518.7256 - mae: 17.8484 - val_loss: 427.0428 - val_mae: 16.2093\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 494.0789 - mae: 17.3841 - val_loss: 405.3123 - val_mae: 15.7606\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 472.1660 - mae: 16.9691 - val_loss: 386.0822 - val_mae: 15.3541\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 452.7328 - mae: 16.5847 - val_loss: 369.0016 - val_mae: 14.9826\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 435.3558 - mae: 16.2283 - val_loss: 354.0376 - val_mae: 14.6431\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 419.6823 - mae: 15.9060 - val_loss: 340.3186 - val_mae: 14.3361\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 405.7464 - mae: 15.6123 - val_loss: 328.0699 - val_mae: 14.0590\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 392.9868 - mae: 15.3398 - val_loss: 316.8409 - val_mae: 13.8051\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 381.6329 - mae: 15.0986 - val_loss: 306.9269 - val_mae: 13.5736\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 371.1604 - mae: 14.8676 - val_loss: 297.6722 - val_mae: 13.3587\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 361.5522 - mae: 14.6586 - val_loss: 289.5083 - val_mae: 13.1614\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 352.8789 - mae: 14.4602 - val_loss: 281.9095 - val_mae: 12.9776\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 344.9638 - mae: 14.2813 - val_loss: 274.9995 - val_mae: 12.8098\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 337.4122 - mae: 14.1106 - val_loss: 268.4123 - val_mae: 12.6552\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 330.4766 - mae: 13.9537 - val_loss: 262.1969 - val_mae: 12.5114\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 324.0453 - mae: 13.8131 - val_loss: 256.7982 - val_mae: 12.3767\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 318.0902 - mae: 13.6708 - val_loss: 251.5420 - val_mae: 12.2499\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 312.5298 - mae: 13.5459 - val_loss: 246.5427 - val_mae: 12.1292\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 307.3144 - mae: 13.4289 - val_loss: 241.8734 - val_mae: 12.0177\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 302.4549 - mae: 13.3186 - val_loss: 237.3785 - val_mae: 11.9117\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 297.7809 - mae: 13.2115 - val_loss: 233.1673 - val_mae: 11.8120\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 293.3374 - mae: 13.1124 - val_loss: 229.2735 - val_mae: 11.7166\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 289.1995 - mae: 13.0161 - val_loss: 225.5904 - val_mae: 11.6262\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 285.3386 - mae: 12.9275 - val_loss: 222.1012 - val_mae: 11.5414\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 281.7473 - mae: 12.8475 - val_loss: 218.7844 - val_mae: 11.4593\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 278.1945 - mae: 12.7648 - val_loss: 215.5320 - val_mae: 11.3792\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 274.7527 - mae: 12.6830 - val_loss: 212.3673 - val_mae: 11.3017\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 271.4943 - mae: 12.6065 - val_loss: 209.1825 - val_mae: 11.2251\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 268.4233 - mae: 12.5406 - val_loss: 206.3869 - val_mae: 11.1552\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 265.3682 - mae: 12.4698 - val_loss: 203.6117 - val_mae: 11.0904\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 262.3589 - mae: 12.4056 - val_loss: 200.6718 - val_mae: 11.0196\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 259.5527 - mae: 12.3426 - val_loss: 197.8477 - val_mae: 10.9518\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 256.8970 - mae: 12.2812 - val_loss: 195.2424 - val_mae: 10.8880\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 254.0468 - mae: 12.2208 - val_loss: 192.7467 - val_mae: 10.8244\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 251.6072 - mae: 12.1639 - val_loss: 190.1861 - val_mae: 10.7608\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 249.0789 - mae: 12.1049 - val_loss: 187.8891 - val_mae: 10.7017\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 246.7500 - mae: 12.0535 - val_loss: 185.7162 - val_mae: 10.6425\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 244.3979 - mae: 11.9944 - val_loss: 183.4943 - val_mae: 10.5844\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 242.0890 - mae: 11.9432 - val_loss: 181.2691 - val_mae: 10.5269\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 239.9575 - mae: 11.8926 - val_loss: 179.2875 - val_mae: 10.4718\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 237.8071 - mae: 11.8394 - val_loss: 177.2855 - val_mae: 10.4176\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 235.7603 - mae: 11.7907 - val_loss: 175.2629 - val_mae: 10.3623\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 233.7070 - mae: 11.7430 - val_loss: 173.1621 - val_mae: 10.3057\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 231.7037 - mae: 11.6944 - val_loss: 171.1844 - val_mae: 10.2518\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 229.7705 - mae: 11.6473 - val_loss: 169.1450 - val_mae: 10.1976\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 227.9023 - mae: 11.5991 - val_loss: 167.1930 - val_mae: 10.1461\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 225.9716 - mae: 11.5561 - val_loss: 165.4645 - val_mae: 10.0975\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 224.1684 - mae: 11.5117 - val_loss: 163.5730 - val_mae: 10.0455\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 222.4328 - mae: 11.4706 - val_loss: 161.8924 - val_mae: 9.9975\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 220.7042 - mae: 11.4255 - val_loss: 160.2068 - val_mae: 9.9500\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 219.0376 - mae: 11.3835 - val_loss: 158.5195 - val_mae: 9.9009\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 217.3118 - mae: 11.3437 - val_loss: 156.7600 - val_mae: 9.8507\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 215.7155 - mae: 11.3004 - val_loss: 155.2117 - val_mae: 9.8042\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 214.1397 - mae: 11.2596 - val_loss: 153.6056 - val_mae: 9.7577\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 212.5153 - mae: 11.2179 - val_loss: 152.0885 - val_mae: 9.7155\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 211.0183 - mae: 11.1820 - val_loss: 150.5313 - val_mae: 9.6704\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 209.5399 - mae: 11.1434 - val_loss: 148.9552 - val_mae: 9.6238\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 208.0126 - mae: 11.1075 - val_loss: 147.6313 - val_mae: 9.5834\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 206.5646 - mae: 11.0726 - val_loss: 145.9496 - val_mae: 9.5354\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 205.1046 - mae: 11.0321 - val_loss: 144.5698 - val_mae: 9.4929\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 203.8595 - mae: 10.9988 - val_loss: 143.2167 - val_mae: 9.4517\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 202.4483 - mae: 10.9647 - val_loss: 141.7315 - val_mae: 9.4066\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 201.0841 - mae: 10.9247 - val_loss: 140.3329 - val_mae: 9.3662\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 199.7218 - mae: 10.8915 - val_loss: 139.0731 - val_mae: 9.3270\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 198.3968 - mae: 10.8564 - val_loss: 137.6808 - val_mae: 9.2857\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 197.1206 - mae: 10.8217 - val_loss: 136.4037 - val_mae: 9.2459\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 195.8388 - mae: 10.7898 - val_loss: 135.0940 - val_mae: 9.2054\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 194.6381 - mae: 10.7586 - val_loss: 133.9378 - val_mae: 9.1673\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 193.4637 - mae: 10.7277 - val_loss: 132.8071 - val_mae: 9.1317\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 192.2802 - mae: 10.6988 - val_loss: 131.6162 - val_mae: 9.0916\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 191.1296 - mae: 10.6657 - val_loss: 130.2314 - val_mae: 9.0481\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 189.9586 - mae: 10.6310 - val_loss: 129.0780 - val_mae: 9.0107\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 188.8586 - mae: 10.6011 - val_loss: 127.9212 - val_mae: 8.9719\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 187.7134 - mae: 10.5679 - val_loss: 126.8957 - val_mae: 8.9372\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 186.6432 - mae: 10.5353 - val_loss: 125.7141 - val_mae: 8.9005\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 185.5327 - mae: 10.5103 - val_loss: 124.5309 - val_mae: 8.8619\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 184.4237 - mae: 10.4786 - val_loss: 123.3815 - val_mae: 8.8227\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 183.3935 - mae: 10.4471 - val_loss: 122.3612 - val_mae: 8.7894\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 182.4013 - mae: 10.4221 - val_loss: 121.1972 - val_mae: 8.7525\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 181.3777 - mae: 10.3935 - val_loss: 120.1700 - val_mae: 8.7159\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 180.3761 - mae: 10.3616 - val_loss: 119.0427 - val_mae: 8.6784\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.9, model__n_hidden=2, model__n_neurons=125, model__optimizer=sgd; total time=   5.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 774, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 89, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 331, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 16875]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmp1rclbay8\\assets\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 20ms/step - loss: 5297.9941 - mae: 56.5902 - val_loss: 4672.9976 - val_mae: 52.9595\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4142.0034 - mae: 49.9594 - val_loss: 3676.0020 - val_mae: 46.8790\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3320.1548 - mae: 44.5985 - val_loss: 2960.7078 - val_mae: 42.0218\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2721.6887 - mae: 40.3166 - val_loss: 2428.8005 - val_mae: 38.0487\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2272.3091 - mae: 36.7807 - val_loss: 2026.1385 - val_mae: 34.7552\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1928.0764 - mae: 33.8705 - val_loss: 1714.4452 - val_mae: 31.9917\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1659.1736 - mae: 31.4135 - val_loss: 1468.8560 - val_mae: 29.6413\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1445.2462 - mae: 29.2911 - val_loss: 1272.5474 - val_mae: 27.6219\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1272.8448 - mae: 27.4810 - val_loss: 1112.6107 - val_mae: 25.8595\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1130.9135 - mae: 25.8922 - val_loss: 982.7855 - val_mae: 24.3266\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1015.1371 - mae: 24.5141 - val_loss: 875.7768 - val_mae: 22.9857\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 918.5378 - mae: 23.2956 - val_loss: 785.6920 - val_mae: 21.7894\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 836.7333 - mae: 22.2062 - val_loss: 710.3364 - val_mae: 20.7278\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 767.5411 - mae: 21.2422 - val_loss: 646.7769 - val_mae: 19.7824\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 708.7349 - mae: 20.3824 - val_loss: 592.8953 - val_mae: 18.9409\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 658.2748 - mae: 19.6216 - val_loss: 546.1904 - val_mae: 18.1774\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 614.1863 - mae: 18.9165 - val_loss: 505.9113 - val_mae: 17.4841\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 575.9720 - mae: 18.2893 - val_loss: 471.0066 - val_mae: 16.8619\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 542.1581 - mae: 17.7223 - val_loss: 440.6135 - val_mae: 16.3017\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 512.4053 - mae: 17.2032 - val_loss: 414.3522 - val_mae: 15.7980\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 486.6358 - mae: 16.7340 - val_loss: 391.1724 - val_mae: 15.3395\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 463.4571 - mae: 16.3023 - val_loss: 370.8603 - val_mae: 14.9242\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 443.0297 - mae: 15.9128 - val_loss: 352.8879 - val_mae: 14.5412\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 424.7015 - mae: 15.5503 - val_loss: 336.9347 - val_mae: 14.1928\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 408.1366 - mae: 15.2176 - val_loss: 322.7755 - val_mae: 13.8740\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 393.1750 - mae: 14.9096 - val_loss: 309.9348 - val_mae: 13.5828\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 379.5232 - mae: 14.6335 - val_loss: 298.4193 - val_mae: 13.3144\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 367.2631 - mae: 14.3801 - val_loss: 288.2712 - val_mae: 13.0708\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 355.9407 - mae: 14.1345 - val_loss: 278.9699 - val_mae: 12.8453\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 345.8367 - mae: 13.9165 - val_loss: 270.5244 - val_mae: 12.6354\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 336.2516 - mae: 13.7112 - val_loss: 262.8951 - val_mae: 12.4407\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 327.3798 - mae: 13.5190 - val_loss: 255.9357 - val_mae: 12.2636\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 319.3540 - mae: 13.3399 - val_loss: 249.5460 - val_mae: 12.0988\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 311.8796 - mae: 13.1741 - val_loss: 243.7772 - val_mae: 11.9467\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 304.9151 - mae: 13.0190 - val_loss: 238.4671 - val_mae: 11.8062\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 298.5287 - mae: 12.8733 - val_loss: 233.4706 - val_mae: 11.6753\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 292.4238 - mae: 12.7368 - val_loss: 228.8566 - val_mae: 11.5543\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 286.8176 - mae: 12.6162 - val_loss: 224.5692 - val_mae: 11.4420\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 281.4824 - mae: 12.5004 - val_loss: 220.6427 - val_mae: 11.3352\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 276.3174 - mae: 12.3852 - val_loss: 216.9997 - val_mae: 11.2349\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 271.5785 - mae: 12.2739 - val_loss: 213.5733 - val_mae: 11.1400\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 267.1048 - mae: 12.1692 - val_loss: 210.4041 - val_mae: 11.0530\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 262.7611 - mae: 12.0762 - val_loss: 207.3817 - val_mae: 10.9696\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 258.7544 - mae: 11.9822 - val_loss: 204.5309 - val_mae: 10.8902\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 254.8411 - mae: 11.8920 - val_loss: 201.8796 - val_mae: 10.8178\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 251.2343 - mae: 11.8030 - val_loss: 199.3479 - val_mae: 10.7498\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 247.6948 - mae: 11.7289 - val_loss: 196.8981 - val_mae: 10.6829\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 244.3241 - mae: 11.6481 - val_loss: 194.6119 - val_mae: 10.6218\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 241.1230 - mae: 11.5723 - val_loss: 192.4315 - val_mae: 10.5643\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 238.0181 - mae: 11.4950 - val_loss: 190.3693 - val_mae: 10.5093\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 234.9913 - mae: 11.4267 - val_loss: 188.3547 - val_mae: 10.4549\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 232.2388 - mae: 11.3593 - val_loss: 186.4429 - val_mae: 10.4024\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 229.3535 - mae: 11.2925 - val_loss: 184.6046 - val_mae: 10.3524\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 226.5652 - mae: 11.2278 - val_loss: 182.8639 - val_mae: 10.3034\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 223.9439 - mae: 11.1624 - val_loss: 181.1670 - val_mae: 10.2555\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 221.4900 - mae: 11.1063 - val_loss: 179.4997 - val_mae: 10.2076\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 219.1010 - mae: 11.0431 - val_loss: 177.9303 - val_mae: 10.1627\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 216.8125 - mae: 10.9854 - val_loss: 176.4425 - val_mae: 10.1191\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 214.5452 - mae: 10.9251 - val_loss: 174.9750 - val_mae: 10.0774\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 212.3252 - mae: 10.8695 - val_loss: 173.5133 - val_mae: 10.0349\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 210.2119 - mae: 10.8195 - val_loss: 172.1787 - val_mae: 9.9946\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 208.1127 - mae: 10.7600 - val_loss: 170.8095 - val_mae: 9.9548\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 206.0444 - mae: 10.7079 - val_loss: 169.4430 - val_mae: 9.9155\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 204.0576 - mae: 10.6613 - val_loss: 168.1642 - val_mae: 9.8779\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 202.1155 - mae: 10.6090 - val_loss: 166.9080 - val_mae: 9.8414\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 200.1950 - mae: 10.5597 - val_loss: 165.7068 - val_mae: 9.8063\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 198.4278 - mae: 10.5125 - val_loss: 164.5550 - val_mae: 9.7728\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 196.5757 - mae: 10.4672 - val_loss: 163.3495 - val_mae: 9.7370\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 194.8936 - mae: 10.4195 - val_loss: 162.2709 - val_mae: 9.7047\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 193.1804 - mae: 10.3760 - val_loss: 161.1605 - val_mae: 9.6712\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 191.5173 - mae: 10.3295 - val_loss: 160.1294 - val_mae: 9.6397\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 189.8644 - mae: 10.2851 - val_loss: 159.0782 - val_mae: 9.6072\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 188.3462 - mae: 10.2413 - val_loss: 158.0554 - val_mae: 9.5770\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 186.7270 - mae: 10.2009 - val_loss: 157.0563 - val_mae: 9.5461\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 185.2155 - mae: 10.1631 - val_loss: 156.0798 - val_mae: 9.5156\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 183.7710 - mae: 10.1184 - val_loss: 155.1261 - val_mae: 9.4867\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 182.2891 - mae: 10.0802 - val_loss: 154.1685 - val_mae: 9.4568\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 180.8671 - mae: 10.0414 - val_loss: 153.2776 - val_mae: 9.4285\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 179.4448 - mae: 10.0034 - val_loss: 152.2897 - val_mae: 9.3969\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 178.0426 - mae: 9.9648 - val_loss: 151.3691 - val_mae: 9.3669\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 176.7373 - mae: 9.9289 - val_loss: 150.5539 - val_mae: 9.3413\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 175.4500 - mae: 9.8902 - val_loss: 149.7163 - val_mae: 9.3152\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 174.1615 - mae: 9.8528 - val_loss: 148.9349 - val_mae: 9.2898\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 172.8993 - mae: 9.8176 - val_loss: 148.1117 - val_mae: 9.2629\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 171.7268 - mae: 9.7829 - val_loss: 147.2530 - val_mae: 9.2342\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 170.4874 - mae: 9.7469 - val_loss: 146.3992 - val_mae: 9.2054\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 169.3005 - mae: 9.7097 - val_loss: 145.6274 - val_mae: 9.1791\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 168.0997 - mae: 9.6752 - val_loss: 144.8277 - val_mae: 9.1523\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 166.9688 - mae: 9.6428 - val_loss: 144.0766 - val_mae: 9.1274\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 165.9110 - mae: 9.6117 - val_loss: 143.3721 - val_mae: 9.1044\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 164.6873 - mae: 9.5802 - val_loss: 142.6854 - val_mae: 9.0809\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 163.6485 - mae: 9.5502 - val_loss: 142.0377 - val_mae: 9.0593\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 162.5826 - mae: 9.5192 - val_loss: 141.3366 - val_mae: 9.0347\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 161.5996 - mae: 9.4876 - val_loss: 140.5800 - val_mae: 9.0085\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 160.5596 - mae: 9.4572 - val_loss: 139.9133 - val_mae: 8.9860\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 159.5537 - mae: 9.4238 - val_loss: 139.2372 - val_mae: 8.9628\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 158.5352 - mae: 9.4000 - val_loss: 138.5688 - val_mae: 8.9392\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 157.5913 - mae: 9.3661 - val_loss: 137.9200 - val_mae: 8.9169\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 156.6575 - mae: 9.3354 - val_loss: 137.2968 - val_mae: 8.8947\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 155.7551 - mae: 9.3076 - val_loss: 136.6406 - val_mae: 8.8713\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.9, model__n_hidden=2, model__n_neurons=125, model__optimizer=sgd; total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 774, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 89, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 331, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 16750]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmp7q2rwndz\\assets\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 15ms/step - loss: 2223.2178 - mae: 34.8126 - val_loss: 636.8282 - val_mae: 20.1217\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 557.2213 - mae: 18.7135 - val_loss: 364.8311 - val_mae: 15.0832\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 362.3791 - mae: 14.8774 - val_loss: 247.8846 - val_mae: 12.2570\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 273.6063 - mae: 12.6930 - val_loss: 190.7096 - val_mae: 10.6254\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 221.9419 - mae: 11.3112 - val_loss: 153.0448 - val_mae: 9.5089\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 192.4744 - mae: 10.4781 - val_loss: 128.9644 - val_mae: 8.7368\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 172.5340 - mae: 9.8621 - val_loss: 113.5626 - val_mae: 8.2620\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 159.4596 - mae: 9.4797 - val_loss: 103.4197 - val_mae: 7.9176\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 149.2720 - mae: 9.1584 - val_loss: 96.9449 - val_mae: 7.7031\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 142.0206 - mae: 8.9541 - val_loss: 88.6488 - val_mae: 7.3959\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 136.5197 - mae: 8.7634 - val_loss: 83.8866 - val_mae: 7.1906\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 132.1941 - mae: 8.6123 - val_loss: 78.3254 - val_mae: 6.9596\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 127.9764 - mae: 8.4435 - val_loss: 76.6192 - val_mae: 6.9327\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 126.1031 - mae: 8.4392 - val_loss: 71.0285 - val_mae: 6.6270\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 121.7466 - mae: 8.2327 - val_loss: 67.4991 - val_mae: 6.4677\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 119.9024 - mae: 8.1584 - val_loss: 64.8268 - val_mae: 6.3423\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 117.8771 - mae: 8.0521 - val_loss: 63.3014 - val_mae: 6.2996\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 115.5831 - mae: 7.9864 - val_loss: 62.3143 - val_mae: 6.2664\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 113.5023 - mae: 7.8857 - val_loss: 62.1527 - val_mae: 6.2816\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 112.7373 - mae: 7.8956 - val_loss: 59.5476 - val_mae: 6.1351\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 110.7120 - mae: 7.8677 - val_loss: 56.4909 - val_mae: 5.9528\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.7615 - mae: 7.7559 - val_loss: 55.0114 - val_mae: 5.8827\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.0290 - mae: 7.6669 - val_loss: 55.8872 - val_mae: 5.9479\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.2372 - mae: 7.6943 - val_loss: 53.5624 - val_mae: 5.7928\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.0967 - mae: 7.6566 - val_loss: 52.1496 - val_mae: 5.7279\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.9677 - mae: 7.5766 - val_loss: 51.8602 - val_mae: 5.7193\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.4052 - mae: 7.5708 - val_loss: 50.3221 - val_mae: 5.6133\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.1903 - mae: 7.5593 - val_loss: 48.7920 - val_mae: 5.5137\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.8484 - mae: 7.4390 - val_loss: 50.3647 - val_mae: 5.6368\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.8914 - mae: 7.5258 - val_loss: 47.2296 - val_mae: 5.4276\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.3059 - mae: 7.4291 - val_loss: 46.1375 - val_mae: 5.3461\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 100.7028 - mae: 7.3241 - val_loss: 47.3940 - val_mae: 5.4595\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.3300 - mae: 7.3966 - val_loss: 47.1673 - val_mae: 5.4468\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 99.4206 - mae: 7.3729 - val_loss: 46.5742 - val_mae: 5.4087\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.0691 - mae: 7.3444 - val_loss: 45.4397 - val_mae: 5.3375\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 99.0652 - mae: 7.3584 - val_loss: 43.7731 - val_mae: 5.2257\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 98.0318 - mae: 7.2661 - val_loss: 43.7169 - val_mae: 5.2292\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 98.0490 - mae: 7.2939 - val_loss: 42.5341 - val_mae: 5.1381\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 97.0853 - mae: 7.1842 - val_loss: 43.9700 - val_mae: 5.2569\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 97.2989 - mae: 7.2519 - val_loss: 44.3956 - val_mae: 5.2801\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 96.5228 - mae: 7.3195 - val_loss: 41.8617 - val_mae: 5.1111\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.9201 - mae: 7.2130 - val_loss: 41.5870 - val_mae: 5.0983\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.8228 - mae: 7.2197 - val_loss: 40.7899 - val_mae: 5.0445\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.2477 - mae: 7.1732 - val_loss: 40.8231 - val_mae: 5.0557\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 94.9091 - mae: 7.2239 - val_loss: 40.0016 - val_mae: 4.9908\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.5832 - mae: 7.1468 - val_loss: 39.6849 - val_mae: 4.9764\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 95.1760 - mae: 7.1277 - val_loss: 40.6124 - val_mae: 5.0405\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.2541 - mae: 7.1695 - val_loss: 40.1056 - val_mae: 5.0085\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.7245 - mae: 7.1133 - val_loss: 41.2631 - val_mae: 5.0778\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 93.5367 - mae: 7.1462 - val_loss: 39.4889 - val_mae: 4.9729\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 93.1440 - mae: 7.0804 - val_loss: 39.7775 - val_mae: 4.9854\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.3689 - mae: 7.1381 - val_loss: 38.9483 - val_mae: 4.9364\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 92.8747 - mae: 7.0694 - val_loss: 39.3670 - val_mae: 4.9587\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 92.5437 - mae: 7.1627 - val_loss: 37.6826 - val_mae: 4.8492\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 92.8310 - mae: 6.9959 - val_loss: 38.7459 - val_mae: 4.9297\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 92.0485 - mae: 7.0737 - val_loss: 37.7529 - val_mae: 4.8577\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 91.6153 - mae: 7.0062 - val_loss: 38.0757 - val_mae: 4.8824\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.0394 - mae: 7.0488 - val_loss: 38.3803 - val_mae: 4.9040\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.6195 - mae: 7.0939 - val_loss: 36.6731 - val_mae: 4.7970\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.3902 - mae: 6.9665 - val_loss: 37.4160 - val_mae: 4.8358\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 91.9320 - mae: 7.0223 - val_loss: 36.8971 - val_mae: 4.8041\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 90.7878 - mae: 7.0314 - val_loss: 36.0242 - val_mae: 4.7529\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 91.1447 - mae: 6.9722 - val_loss: 36.1979 - val_mae: 4.7655\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 90.7649 - mae: 6.9780 - val_loss: 36.7159 - val_mae: 4.7993\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 90.7271 - mae: 6.9739 - val_loss: 36.1612 - val_mae: 4.7602\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 90.5734 - mae: 6.9707 - val_loss: 35.8142 - val_mae: 4.7453\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 90.5055 - mae: 6.9454 - val_loss: 36.3979 - val_mae: 4.7758\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 89.9733 - mae: 6.9839 - val_loss: 36.0307 - val_mae: 4.7550\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 89.9167 - mae: 6.9777 - val_loss: 35.7497 - val_mae: 4.7427\n",
      "Epoch 69: early stopping\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.5, model__n_hidden=3, model__n_neurons=125, model__optimizer=sgd; total time=   3.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 774, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 89, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 331, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 16875]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmpujka14j0\\assets\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 15ms/step - loss: 1896.8033 - mae: 32.0304 - val_loss: 556.0311 - val_mae: 18.4076\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 526.2079 - mae: 17.6964 - val_loss: 313.1650 - val_mae: 13.5974\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 350.9313 - mae: 14.2967 - val_loss: 218.8511 - val_mae: 11.2418\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 268.4823 - mae: 12.4014 - val_loss: 167.5453 - val_mae: 9.8300\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 222.8453 - mae: 11.2955 - val_loss: 135.2349 - val_mae: 8.9011\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 195.3308 - mae: 10.6086 - val_loss: 113.5736 - val_mae: 8.1958\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 175.9044 - mae: 10.0708 - val_loss: 100.2522 - val_mae: 7.7931\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 163.0523 - mae: 9.7195 - val_loss: 92.8251 - val_mae: 7.5058\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 152.3939 - mae: 9.4319 - val_loss: 85.6832 - val_mae: 7.2514\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 145.4018 - mae: 9.2279 - val_loss: 80.2791 - val_mae: 7.0523\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 139.8715 - mae: 9.0837 - val_loss: 72.9960 - val_mae: 6.7197\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 135.2658 - mae: 8.8776 - val_loss: 70.8140 - val_mae: 6.6408\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 131.4709 - mae: 8.7847 - val_loss: 67.9471 - val_mae: 6.5172\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 129.1585 - mae: 8.7214 - val_loss: 63.9747 - val_mae: 6.3135\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 125.7215 - mae: 8.5660 - val_loss: 62.0874 - val_mae: 6.2133\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 123.3195 - mae: 8.5326 - val_loss: 58.1589 - val_mae: 6.0343\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 121.7514 - mae: 8.4057 - val_loss: 58.4907 - val_mae: 6.0465\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 120.1651 - mae: 8.3715 - val_loss: 57.4368 - val_mae: 6.0039\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 118.3200 - mae: 8.3007 - val_loss: 56.2132 - val_mae: 5.9350\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 117.5835 - mae: 8.3165 - val_loss: 53.0890 - val_mae: 5.7681\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 115.5805 - mae: 8.2631 - val_loss: 49.8063 - val_mae: 5.5878\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 115.0430 - mae: 8.1358 - val_loss: 49.4495 - val_mae: 5.5757\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 113.4493 - mae: 8.0938 - val_loss: 50.2747 - val_mae: 5.6135\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 113.1464 - mae: 8.1451 - val_loss: 49.4318 - val_mae: 5.5333\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.9220 - mae: 8.0932 - val_loss: 47.9917 - val_mae: 5.4967\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.5816 - mae: 8.0582 - val_loss: 48.2656 - val_mae: 5.4937\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 110.7721 - mae: 8.0424 - val_loss: 44.9519 - val_mae: 5.3068\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 110.8474 - mae: 8.0184 - val_loss: 44.5515 - val_mae: 5.2861\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.2807 - mae: 7.9346 - val_loss: 45.3447 - val_mae: 5.3335\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.5829 - mae: 7.9277 - val_loss: 45.5496 - val_mae: 5.3427\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 108.8147 - mae: 7.9828 - val_loss: 42.4919 - val_mae: 5.1676\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.4450 - mae: 7.8681 - val_loss: 47.3453 - val_mae: 5.4321\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.5203 - mae: 7.9482 - val_loss: 45.3638 - val_mae: 5.3224\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.8558 - mae: 7.9119 - val_loss: 45.6894 - val_mae: 5.3423\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.3025 - mae: 7.8974 - val_loss: 44.3399 - val_mae: 5.2681\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.0437 - mae: 7.9228 - val_loss: 41.6946 - val_mae: 5.1026\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.2943 - mae: 7.8564 - val_loss: 41.5870 - val_mae: 5.1005\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.6128 - mae: 7.8342 - val_loss: 40.8864 - val_mae: 5.0639\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.9378 - mae: 7.8307 - val_loss: 41.0319 - val_mae: 5.0767\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 104.4380 - mae: 7.7589 - val_loss: 43.8112 - val_mae: 5.2304\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.4519 - mae: 7.9080 - val_loss: 39.0436 - val_mae: 4.9525\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.9266 - mae: 7.7912 - val_loss: 38.4719 - val_mae: 4.9235\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.6902 - mae: 7.7492 - val_loss: 39.1807 - val_mae: 4.9552\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.4551 - mae: 7.7664 - val_loss: 39.3251 - val_mae: 4.9662\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.4145 - mae: 7.8969 - val_loss: 36.9784 - val_mae: 4.8379\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.4242 - mae: 7.6983 - val_loss: 37.6263 - val_mae: 4.8657\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.9518 - mae: 7.7073 - val_loss: 38.8437 - val_mae: 4.9397\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.7344 - mae: 7.7475 - val_loss: 39.1670 - val_mae: 4.9588\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.3224 - mae: 7.6711 - val_loss: 45.2987 - val_mae: 5.2764\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.4907 - mae: 7.8305 - val_loss: 37.7615 - val_mae: 4.8775\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.0640 - mae: 7.7320 - val_loss: 37.8742 - val_mae: 4.8698\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.7828 - mae: 7.7511 - val_loss: 38.6646 - val_mae: 4.9096\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.2709 - mae: 7.7200 - val_loss: 37.3509 - val_mae: 4.8401\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.4614 - mae: 7.7347 - val_loss: 35.8333 - val_mae: 4.7687\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.0200 - mae: 7.6243 - val_loss: 38.4893 - val_mae: 4.8943\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.4547 - mae: 7.7268 - val_loss: 37.4319 - val_mae: 4.8409\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.6319 - mae: 7.6665 - val_loss: 37.9095 - val_mae: 4.8597\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.2603 - mae: 7.6801 - val_loss: 37.2590 - val_mae: 4.8300\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.4723 - mae: 7.6477 - val_loss: 37.8050 - val_mae: 4.8503\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.5959 - mae: 7.6750 - val_loss: 37.7274 - val_mae: 4.8438\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 100.4036 - mae: 7.6999 - val_loss: 36.0878 - val_mae: 4.7481\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.6288 - mae: 7.6654 - val_loss: 34.8527 - val_mae: 4.6977\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.5940 - mae: 7.6493 - val_loss: 34.4955 - val_mae: 4.6707\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.4337 - mae: 7.6115 - val_loss: 34.6303 - val_mae: 4.6828\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 99.5651 - mae: 7.5244 - val_loss: 36.8504 - val_mae: 4.7689\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.2051 - mae: 7.6113 - val_loss: 37.6922 - val_mae: 4.8317\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.9758 - mae: 7.6718 - val_loss: 34.5620 - val_mae: 4.6739\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.0997 - mae: 7.5864 - val_loss: 35.8701 - val_mae: 4.7279\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.9867 - mae: 7.6371 - val_loss: 35.3995 - val_mae: 4.7114\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.6292 - mae: 7.5729 - val_loss: 35.4457 - val_mae: 4.7045\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.4289 - mae: 7.6555 - val_loss: 33.2035 - val_mae: 4.6025\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.9741 - mae: 7.5335 - val_loss: 34.7043 - val_mae: 4.6523\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.6108 - mae: 7.5957 - val_loss: 34.7888 - val_mae: 4.6643\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.0054 - mae: 7.5643 - val_loss: 36.5150 - val_mae: 4.7448\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.5500 - mae: 7.6242 - val_loss: 35.6311 - val_mae: 4.7043\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.2690 - mae: 7.5446 - val_loss: 36.0098 - val_mae: 4.7164\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.7576 - mae: 7.5819 - val_loss: 36.9541 - val_mae: 4.7696\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.2742 - mae: 7.6758 - val_loss: 32.5404 - val_mae: 4.5546\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.5938 - mae: 7.5129 - val_loss: 33.5987 - val_mae: 4.5953\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.7134 - mae: 7.5474 - val_loss: 34.1188 - val_mae: 4.6150\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.6469 - mae: 7.5795 - val_loss: 32.5639 - val_mae: 4.5388\n",
      "Epoch 81: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.5, model__n_hidden=3, model__n_neurons=125, model__optimizer=sgd; total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 774, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 89, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 331, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 16875]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmpq1cbznsa\\assets\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 16ms/step - loss: 1882.1138 - mae: 32.9330 - val_loss: 601.3470 - val_mae: 19.4803\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 539.6557 - mae: 18.0675 - val_loss: 352.4849 - val_mae: 14.5726\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 353.5938 - mae: 14.3818 - val_loss: 257.6026 - val_mae: 12.3019\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 264.8889 - mae: 12.3214 - val_loss: 208.0653 - val_mae: 10.9626\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 215.5968 - mae: 11.0510 - val_loss: 178.5908 - val_mae: 10.0652\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 184.8495 - mae: 10.1879 - val_loss: 159.9949 - val_mae: 9.4642\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 165.2734 - mae: 9.6186 - val_loss: 148.6964 - val_mae: 9.1540\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 150.7437 - mae: 9.2360 - val_loss: 137.5431 - val_mae: 8.7236\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 140.2683 - mae: 8.8093 - val_loss: 131.8670 - val_mae: 8.5471\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 132.2147 - mae: 8.6011 - val_loss: 125.9377 - val_mae: 8.3329\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 126.4618 - mae: 8.3585 - val_loss: 122.2671 - val_mae: 8.2732\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 122.5303 - mae: 8.2659 - val_loss: 117.5792 - val_mae: 8.0612\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 118.0351 - mae: 8.0617 - val_loss: 115.7958 - val_mae: 8.0380\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 115.5754 - mae: 7.9958 - val_loss: 113.4459 - val_mae: 7.9525\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 112.5342 - mae: 7.9050 - val_loss: 110.4340 - val_mae: 7.7981\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 110.4065 - mae: 7.8042 - val_loss: 109.0953 - val_mae: 7.7653\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.1397 - mae: 7.7661 - val_loss: 105.6211 - val_mae: 7.5325\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.2535 - mae: 7.6487 - val_loss: 104.6460 - val_mae: 7.5617\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.2777 - mae: 7.5922 - val_loss: 104.2901 - val_mae: 7.5814\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.7141 - mae: 7.5658 - val_loss: 102.2100 - val_mae: 7.4508\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.9109 - mae: 7.4982 - val_loss: 100.8855 - val_mae: 7.4273\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.3191 - mae: 7.4480 - val_loss: 100.6846 - val_mae: 7.4369\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.6336 - mae: 7.4334 - val_loss: 99.5835 - val_mae: 7.4144\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.5670 - mae: 7.3926 - val_loss: 100.2439 - val_mae: 7.4716\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.9913 - mae: 7.3971 - val_loss: 97.0781 - val_mae: 7.2874\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.8356 - mae: 7.3298 - val_loss: 98.4968 - val_mae: 7.3859\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.4961 - mae: 7.3500 - val_loss: 94.6909 - val_mae: 7.1849\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.8038 - mae: 7.2907 - val_loss: 95.1880 - val_mae: 7.2102\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.1235 - mae: 7.2675 - val_loss: 93.4814 - val_mae: 7.1177\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.6302 - mae: 7.2563 - val_loss: 93.1993 - val_mae: 7.1051\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.9820 - mae: 7.2228 - val_loss: 92.5639 - val_mae: 7.1039\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.3161 - mae: 7.1699 - val_loss: 94.5184 - val_mae: 7.2563\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.3714 - mae: 7.2356 - val_loss: 90.6817 - val_mae: 6.9764\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.7472 - mae: 7.1723 - val_loss: 90.5531 - val_mae: 6.9715\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.8480 - mae: 7.1251 - val_loss: 90.3365 - val_mae: 7.0073\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.2945 - mae: 7.1648 - val_loss: 89.0814 - val_mae: 6.9233\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.3229 - mae: 7.1572 - val_loss: 87.6826 - val_mae: 6.8037\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.0342 - mae: 7.1257 - val_loss: 87.1749 - val_mae: 6.8012\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.7034 - mae: 7.0993 - val_loss: 88.2917 - val_mae: 6.9019\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.0831 - mae: 7.0708 - val_loss: 88.5796 - val_mae: 6.9373\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.4564 - mae: 7.1020 - val_loss: 87.0073 - val_mae: 6.8265\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.6087 - mae: 7.0165 - val_loss: 92.3224 - val_mae: 7.2284\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.8141 - mae: 7.1290 - val_loss: 86.3129 - val_mae: 6.8330\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.6136 - mae: 7.0608 - val_loss: 85.1531 - val_mae: 6.7511\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.7621 - mae: 7.0099 - val_loss: 85.9315 - val_mae: 6.8338\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.1418 - mae: 7.0097 - val_loss: 85.9242 - val_mae: 6.8172\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.8469 - mae: 7.0501 - val_loss: 83.6387 - val_mae: 6.6360\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.9585 - mae: 6.9647 - val_loss: 83.7032 - val_mae: 6.6893\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.7521 - mae: 6.9705 - val_loss: 84.9566 - val_mae: 6.7978\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.9269 - mae: 7.0103 - val_loss: 85.2933 - val_mae: 6.7906\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.2868 - mae: 6.9846 - val_loss: 82.7813 - val_mae: 6.6257\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.3541 - mae: 6.9506 - val_loss: 82.8604 - val_mae: 6.6474\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.6380 - mae: 6.9046 - val_loss: 86.0314 - val_mae: 6.9035\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.6015 - mae: 6.9772 - val_loss: 84.6997 - val_mae: 6.8189\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.8954 - mae: 6.9781 - val_loss: 82.9621 - val_mae: 6.6833\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 87.0994 - mae: 6.9494 - val_loss: 80.8428 - val_mae: 6.5463\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 87.0073 - mae: 6.8895 - val_loss: 81.2695 - val_mae: 6.6011\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 87.1216 - mae: 6.9281 - val_loss: 81.8773 - val_mae: 6.6332\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 86.6135 - mae: 6.8895 - val_loss: 81.7655 - val_mae: 6.6757\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 86.3891 - mae: 6.9290 - val_loss: 80.4248 - val_mae: 6.5406\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 86.2321 - mae: 6.8773 - val_loss: 81.7080 - val_mae: 6.6491\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 85.8520 - mae: 6.8978 - val_loss: 80.3309 - val_mae: 6.5641\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 86.1711 - mae: 6.9064 - val_loss: 79.1023 - val_mae: 6.4665\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 85.5912 - mae: 6.8245 - val_loss: 80.7173 - val_mae: 6.6034\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 85.3786 - mae: 6.9003 - val_loss: 79.3066 - val_mae: 6.4709\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 85.7464 - mae: 6.8461 - val_loss: 80.1338 - val_mae: 6.5627\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.5252 - mae: 6.8640 - val_loss: 80.6089 - val_mae: 6.6098\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.2448 - mae: 6.8844 - val_loss: 77.9750 - val_mae: 6.4043\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.1136 - mae: 6.8142 - val_loss: 79.5182 - val_mae: 6.5591\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.8342 - mae: 6.8543 - val_loss: 78.2839 - val_mae: 6.4489\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.4337 - mae: 6.7866 - val_loss: 79.9402 - val_mae: 6.5763\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.2515 - mae: 6.8234 - val_loss: 77.9401 - val_mae: 6.4349\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.0909 - mae: 6.7493 - val_loss: 80.6466 - val_mae: 6.6468\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 84.3083 - mae: 6.8393 - val_loss: 78.6509 - val_mae: 6.4874\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.9301 - mae: 6.7970 - val_loss: 78.0947 - val_mae: 6.4323\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.0704 - mae: 6.7625 - val_loss: 79.6856 - val_mae: 6.5969\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 83.9514 - mae: 6.8282 - val_loss: 77.2953 - val_mae: 6.4112\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.0105 - mae: 6.7956 - val_loss: 78.2141 - val_mae: 6.4916\n",
      "Epoch 78: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.5, model__n_hidden=3, model__n_neurons=125, model__optimizer=sgd; total time=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 774, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 89, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 331, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 16750]\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmpxnrjza8y\\assets\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\Pawel\\AppData\\Local\\Temp\\tmpocfnkz_7\\assets\n",
      "Epoch 1/100\n",
      " 1/12 [=>............................] - ETA: 1s - loss: 25907.6699 - mae: 71.7324"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pawel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 8ms/step - loss: 23378.0195 - mae: 72.6294 - val_loss: 22248.2461 - val_mae: 69.9812\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 23378.0195 - mae: 72.6294 - val_loss: 22248.2461 - val_mae: 69.9812\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 23378.0195 - mae: 72.6294 - val_loss: 22248.2461 - val_mae: 69.9812\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 23378.0215 - mae: 72.6294 - val_loss: 22248.2461 - val_mae: 69.9812\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 23378.0195 - mae: 72.6294 - val_loss: 22248.2461 - val_mae: 69.9812\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 23378.0195 - mae: 72.6294 - val_loss: 22248.2461 - val_mae: 69.9812\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 23378.0215 - mae: 72.6294 - val_loss: 22248.2461 - val_mae: 69.9812\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 23378.0195 - mae: 72.6294 - val_loss: 22248.2461 - val_mae: 69.9812\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 23378.0215 - mae: 72.6294 - val_loss: 22248.2461 - val_mae: 69.9812\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 23378.0195 - mae: 72.6294 - val_loss: 22248.2461 - val_mae: 69.9812\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 23378.0195 - mae: 72.6294 - val_loss: 22248.2461 - val_mae: 69.9812\n",
      "Epoch 11: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=KerasRegressor(callbacks=[<keras.callbacks.EarlyStopping object at 0x000001D39B44D580>], model=<function build_model at 0x000001D3A2FF59D0>),\n",
       "                   n_iter=20,\n",
       "                   param_distributions={'model__learning_rate': [1e-06, 1e-05,\n",
       "                                                                 0.0001],\n",
       "                                        'model__momentum': [0.1, 0.5, 0.9],\n",
       "                                        'model__n_hidden': [0, 1, 2, 3],\n",
       "                                        'model__n_neurons': [5, 25, 125],\n",
       "                                        'model__optimizer': ['sgd', 'nesterov',\n",
       "                                                             'momentum',\n",
       "                                                             'adam']},\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv = RandomizedSearchCV(keras_reg,param_distribs,n_iter=20,cv=3,verbose=2)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=100, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cc4d980e-4b5b-42a2-b87b-2121263c7004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__optimizer': 'adam',\n",
       " 'model__n_neurons': 125,\n",
       " 'model__n_hidden': 0,\n",
       " 'model__momentum': 0.9,\n",
       " 'model__learning_rate': 1e-06}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87532508-d7ae-4bca-b138-f8c2f5eec359",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
